//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-19324607
// Cuda compilation tools, release 7.0, V7.0.27
// Based on LLVM 3.4svn
//

.version 4.2
.target sm_50
.address_size 64

	// .weak	cudaMalloc
.extern .func  (.param .b32 func_retval0) _Z8functioniii
(
	.param .b32 _Z8functioniii_param_0,
	.param .b32 _Z8functioniii_param_1,
	.param .b32 _Z8functioniii_param_2
)
;

.weak .func  (.param .b32 func_retval0) cudaMalloc(
	.param .b64 cudaMalloc_param_0,
	.param .b64 cudaMalloc_param_1
)
{
	.reg .s32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaFuncGetAttributes
.weak .func  (.param .b32 func_retval0) cudaFuncGetAttributes(
	.param .b64 cudaFuncGetAttributes_param_0,
	.param .b64 cudaFuncGetAttributes_param_1
)
{
	.reg .s32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaDeviceGetAttribute
.weak .func  (.param .b32 func_retval0) cudaDeviceGetAttribute(
	.param .b64 cudaDeviceGetAttribute_param_0,
	.param .b32 cudaDeviceGetAttribute_param_1,
	.param .b32 cudaDeviceGetAttribute_param_2
)
{
	.reg .s32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaGetDevice
.weak .func  (.param .b32 func_retval0) cudaGetDevice(
	.param .b64 cudaGetDevice_param_0
)
{
	.reg .s32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaOccupancyMaxActiveBlocksPerMultiprocessor
.weak .func  (.param .b32 func_retval0) cudaOccupancyMaxActiveBlocksPerMultiprocessor(
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_0,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_1,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_2,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_3
)
{
	.reg .s32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
.weak .func  (.param .b32 func_retval0) cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_0,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_1,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_2,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_3,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_4
)
{
	.reg .s32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	_Z7vecInitPfi
.visible .entry _Z7vecInitPfi(
	.param .u64 _Z7vecInitPfi_param_0,
	.param .u32 _Z7vecInitPfi_param_1
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .s32 	%r<6>;
	.reg .s64 	%rd<5>;


	ld.param.u64 	%rd1, [_Z7vecInitPfi_param_0];
	ld.param.u32 	%r2, [_Z7vecInitPfi_param_1];
	mov.u32 	%r3, %tid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %ntid.x;
	mad.lo.s32 	%r1, %r4, %r5, %r3;
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB6_2;

	cvta.to.global.u64 	%rd2, %rd1;
	mul.wide.s32 	%rd3, %r1, 4;
	add.s64 	%rd4, %rd2, %rd3;
	cvt.rn.f32.s32	%f1, %r1;
	st.global.f32 	[%rd4], %f1;

BB6_2:
	ret;
}

	// .globl	_Z6vecAddPfS_S_i
.visible .entry _Z6vecAddPfS_S_i(
	.param .u64 _Z6vecAddPfS_S_i_param_0,
	.param .u64 _Z6vecAddPfS_S_i_param_1,
	.param .u64 _Z6vecAddPfS_S_i_param_2,
	.param .u32 _Z6vecAddPfS_S_i_param_3
)
{
	.reg .s32 	%r<5>;


	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b32 param0;
	st.param.b32	[param0+0], %r1;
	.param .b32 param1;
	st.param.b32	[param1+0], %r2;
	.param .b32 param2;
	st.param.b32	[param2+0], %r3;
	.param .b32 retval0;
	call.uni (retval0), 
	_Z8functioniii, 
	(
	param0, 
	param1, 
	param2
	);
	ld.param.b32	%r4, [retval0+0];
	
	//{
	}// Callseq End 0
	ret;
}


