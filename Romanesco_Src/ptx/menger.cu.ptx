//
// Generated by NVIDIA NVVM Compiler
// Compiler built on Fri Aug  1 03:29:38 2014 (1406860178)
// Cuda compilation tools, release 6.5, V6.5.14
//

.version 4.1
.target sm_20
.address_size 64

.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd
(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
;
.global .align 4 .b8 eye[12];
.global .align 16 .b8 c4[16];
.global .align 4 .f32 alpha;
.global .align 4 .f32 delta;
.global .align 4 .f32 DEL;
.global .align 4 .f32 color_t;
.global .align 4 .u32 max_iterations;
.global .align 4 .b8 particle[12];
.global .align 4 .b8 center[12];
.global .align 4 .f32 global_t;
.global .align 8 .b8 ray[36];
.global .align 8 .b8 normal[12];
.global .align 4 .b8 shading_normal[12];
.global .align 4 .b8 shading_normal2[12];
.global .align 8 .b8 top_object[4];
.global .align 4 .f32 isect_t;
.global .align 8 .b8 prd_radiance[52];
.global .align 8 .b8 prd_shadow[12];
.global .texref envmap;
.global .align 8 .u64 _ZN21rti_internal_register20reg_bitness_detectorE;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail0E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail1E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail2E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail3E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail4E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail5E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail6E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail7E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail8E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail9E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail0E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail1E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail2E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail3E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail4E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail5E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail6E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail7E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail8E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail9E;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_xE;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_yE;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_zE;
.global .align 4 .b8 _ZN21rti_internal_typeinfo3eyeE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo2c4E[8] = {82, 97, 121, 0, 16, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo5alphaE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo5deltaE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo3DELE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo7color_tE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo14max_iterationsE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo8particleE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo6centerE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo8global_tE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo3rayE[8] = {82, 97, 121, 0, 36, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo6normalE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo14shading_normalE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo15shading_normal2E[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo10top_objectE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo7isect_tE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo12prd_radianceE[8] = {82, 97, 121, 0, 52, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo10prd_shadowE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 1 .b8 _ZN21rti_internal_typename3eyeE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename2c4E[7] = {102, 108, 111, 97, 116, 52, 0};
.global .align 1 .b8 _ZN21rti_internal_typename5alphaE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename5deltaE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename3DELE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename7color_tE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename14max_iterationsE[5] = {117, 105, 110, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename8particleE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename6centerE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename8global_tE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename3rayE[11] = {111, 112, 116, 105, 120, 58, 58, 82, 97, 121, 0};
.global .align 1 .b8 _ZN21rti_internal_typename6normalE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename14shading_normalE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename15shading_normal2E[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename10top_objectE[9] = {114, 116, 79, 98, 106, 101, 99, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename7isect_tE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename12prd_radianceE[20] = {80, 101, 114, 82, 97, 121, 68, 97, 116, 97, 95, 114, 97, 100, 105, 97, 110, 99, 101, 0};
.global .align 1 .b8 _ZN21rti_internal_typename10prd_shadowE[18] = {80, 101, 114, 82, 97, 121, 68, 97, 116, 97, 95, 115, 104, 97, 100, 111, 119, 0};
.global .align 4 .u32 _ZN21rti_internal_typeenum3eyeE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum2c4E = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum5alphaE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum5deltaE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum3DELE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum7color_tE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum14max_iterationsE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum8particleE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum6centerE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum8global_tE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum3rayE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum6normalE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum14shading_normalE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum15shading_normal2E = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum10top_objectE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum7isect_tE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum12prd_radianceE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum10prd_shadowE = 4919;
.global .align 1 .b8 _ZN21rti_internal_semantic3eyeE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic2c4E[1];
.global .align 1 .b8 _ZN21rti_internal_semantic5alphaE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic5deltaE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic3DELE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic7color_tE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic14max_iterationsE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic8particleE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic6centerE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic8global_tE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic3rayE[13] = {114, 116, 67, 117, 114, 114, 101, 110, 116, 82, 97, 121, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic6normalE[17] = {97, 116, 116, 114, 105, 98, 117, 116, 101, 32, 110, 111, 114, 109, 97, 108, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic14shading_normalE[25] = {97, 116, 116, 114, 105, 98, 117, 116, 101, 32, 115, 104, 97, 100, 105, 110, 103, 95, 110, 111, 114, 109, 97, 108, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic15shading_normal2E[26] = {97, 116, 116, 114, 105, 98, 117, 116, 101, 32, 115, 104, 97, 100, 105, 110, 103, 95, 110, 111, 114, 109, 97, 108, 50, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic10top_objectE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic7isect_tE[23] = {114, 116, 73, 110, 116, 101, 114, 115, 101, 99, 116, 105, 111, 110, 68, 105, 115, 116, 97, 110, 99, 101, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic12prd_radianceE[10] = {114, 116, 80, 97, 121, 108, 111, 97, 100, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic10prd_shadowE[10] = {114, 116, 80, 97, 121, 108, 111, 97, 100, 0};
.global .align 1 .b8 _ZN23rti_internal_annotation3eyeE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation2c4E[1];
.global .align 1 .b8 _ZN23rti_internal_annotation5alphaE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation5deltaE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation3DELE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation7color_tE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation14max_iterationsE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation8particleE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation6centerE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation8global_tE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation3rayE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation6normalE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation14shading_normalE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation15shading_normal2E[1];
.global .align 1 .b8 _ZN23rti_internal_annotation10top_objectE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation7isect_tE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation12prd_radianceE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation10prd_shadowE[1];
.const .align 8 .b8 __cudart_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};
.const .align 8 .b8 __cudart_sin_cos_coeffs[128] = {186, 94, 120, 249, 101, 219, 229, 61, 70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};

.visible .func  (.param .b32 func_retval0) _Z5udBox6float3S_(
	.param .align 4 .b8 _Z5udBox6float3S__param_0[12],
	.param .align 4 .b8 _Z5udBox6float3S__param_1[12]
)
{
	.reg .f32 	%f<20>;
	.reg .f64 	%fd<8>;


	ld.param.f32 	%f1, [_Z5udBox6float3S__param_0+8];
	ld.param.f32 	%f2, [_Z5udBox6float3S__param_0+4];
	ld.param.f32 	%f3, [_Z5udBox6float3S__param_0];
	ld.param.f32 	%f4, [_Z5udBox6float3S__param_1+8];
	ld.param.f32 	%f5, [_Z5udBox6float3S__param_1+4];
	ld.param.f32 	%f6, [_Z5udBox6float3S__param_1];
	abs.ftz.f32 	%f7, %f3;
	sub.ftz.f32 	%f8, %f7, %f6;
	cvt.ftz.f64.f32	%fd1, %f8;
	mov.f64 	%fd2, 0d0000000000000000;
	max.f64 	%fd3, %fd1, %fd2;
	cvt.rn.ftz.f32.f64	%f9, %fd3;
	abs.ftz.f32 	%f10, %f2;
	sub.ftz.f32 	%f11, %f10, %f5;
	cvt.ftz.f64.f32	%fd4, %f11;
	max.f64 	%fd5, %fd4, %fd2;
	cvt.rn.ftz.f32.f64	%f12, %fd5;
	abs.ftz.f32 	%f13, %f1;
	sub.ftz.f32 	%f14, %f13, %f4;
	cvt.ftz.f64.f32	%fd6, %f14;
	max.f64 	%fd7, %fd6, %fd2;
	cvt.rn.ftz.f32.f64	%f15, %fd7;
	mul.ftz.f32 	%f16, %f12, %f12;
	fma.rn.ftz.f32 	%f17, %f9, %f9, %f16;
	fma.rn.ftz.f32 	%f18, %f15, %f15, %f17;
	sqrt.approx.ftz.f32 	%f19, %f18;
	st.param.f32	[func_retval0+0], %f19;
	ret;
}

.visible .func  (.param .align 4 .b8 func_retval0[12]) _Z3max6float3f(
	.param .align 4 .b8 _Z3max6float3f_param_0[12],
	.param .b32 _Z3max6float3f_param_1
)
{
	.reg .f32 	%f<8>;


	ld.param.f32 	%f1, [_Z3max6float3f_param_0+8];
	ld.param.f32 	%f2, [_Z3max6float3f_param_0+4];
	ld.param.f32 	%f3, [_Z3max6float3f_param_0];
	ld.param.f32 	%f4, [_Z3max6float3f_param_1];
	max.ftz.f32 	%f5, %f3, %f4;
	max.ftz.f32 	%f6, %f2, %f4;
	max.ftz.f32 	%f7, %f1, %f4;
	st.param.f32	[func_retval0+0], %f5;
	st.param.f32	[func_retval0+4], %f6;
	st.param.f32	[func_retval0+8], %f7;
	ret;
}

.visible .func  (.param .align 4 .b8 func_retval0[12]) _Z3min6float3f(
	.param .align 4 .b8 _Z3min6float3f_param_0[12],
	.param .b32 _Z3min6float3f_param_1
)
{
	.reg .f32 	%f<8>;


	ld.param.f32 	%f1, [_Z3min6float3f_param_0+8];
	ld.param.f32 	%f2, [_Z3min6float3f_param_0+4];
	ld.param.f32 	%f3, [_Z3min6float3f_param_0];
	ld.param.f32 	%f4, [_Z3min6float3f_param_1];
	min.ftz.f32 	%f5, %f3, %f4;
	min.ftz.f32 	%f6, %f2, %f4;
	min.ftz.f32 	%f7, %f1, %f4;
	st.param.f32	[func_retval0+0], %f5;
	st.param.f32	[func_retval0+4], %f6;
	st.param.f32	[func_retval0+8], %f7;
	ret;
}

.visible .func  (.param .align 4 .b8 func_retval0[12]) _Z6myfabs6float3(
	.param .align 4 .b8 _Z6myfabs6float3_param_0[12]
)
{
	.reg .f32 	%f<7>;


	ld.param.f32 	%f1, [_Z6myfabs6float3_param_0+8];
	ld.param.f32 	%f2, [_Z6myfabs6float3_param_0+4];
	ld.param.f32 	%f3, [_Z6myfabs6float3_param_0];
	abs.ftz.f32 	%f4, %f3;
	abs.ftz.f32 	%f5, %f2;
	abs.ftz.f32 	%f6, %f1;
	st.param.f32	[func_retval0+0], %f4;
	st.param.f32	[func_retval0+4], %f5;
	st.param.f32	[func_retval0+8], %f6;
	ret;
}

.visible .func  (.param .b32 func_retval0) _Z5sdBox6float3S_(
	.param .align 4 .b8 _Z5sdBox6float3S__param_0[12],
	.param .align 4 .b8 _Z5sdBox6float3S__param_1[12]
)
{
	.reg .f32 	%f<25>;


	ld.param.f32 	%f1, [_Z5sdBox6float3S__param_0+8];
	ld.param.f32 	%f2, [_Z5sdBox6float3S__param_0+4];
	ld.param.f32 	%f3, [_Z5sdBox6float3S__param_0];
	ld.param.f32 	%f4, [_Z5sdBox6float3S__param_1+8];
	ld.param.f32 	%f5, [_Z5sdBox6float3S__param_1+4];
	ld.param.f32 	%f6, [_Z5sdBox6float3S__param_1];
	abs.ftz.f32 	%f7, %f3;
	abs.ftz.f32 	%f8, %f2;
	abs.ftz.f32 	%f9, %f1;
	sub.ftz.f32 	%f10, %f7, %f6;
	sub.ftz.f32 	%f11, %f8, %f5;
	sub.ftz.f32 	%f12, %f9, %f4;
	max.ftz.f32 	%f13, %f11, %f12;
	max.ftz.f32 	%f14, %f10, %f13;
	mov.f32 	%f15, 0f00000000;
	min.ftz.f32 	%f16, %f14, %f15;
	max.ftz.f32 	%f17, %f10, %f15;
	max.ftz.f32 	%f18, %f11, %f15;
	max.ftz.f32 	%f19, %f12, %f15;
	mul.ftz.f32 	%f20, %f18, %f18;
	fma.rn.ftz.f32 	%f21, %f17, %f17, %f20;
	fma.rn.ftz.f32 	%f22, %f19, %f19, %f21;
	sqrt.approx.ftz.f32 	%f23, %f22;
	add.ftz.f32 	%f24, %f16, %f23;
	st.param.f32	[func_retval0+0], %f24;
	ret;
}

.visible .func  (.param .b32 func_retval0) _Z8sdSphere6float3f(
	.param .align 4 .b8 _Z8sdSphere6float3f_param_0[12],
	.param .b32 _Z8sdSphere6float3f_param_1
)
{
	.reg .f32 	%f<10>;


	ld.param.f32 	%f1, [_Z8sdSphere6float3f_param_0+8];
	ld.param.f32 	%f2, [_Z8sdSphere6float3f_param_0];
	ld.param.f32 	%f3, [_Z8sdSphere6float3f_param_0+4];
	ld.param.f32 	%f4, [_Z8sdSphere6float3f_param_1];
	mul.ftz.f32 	%f5, %f3, %f3;
	fma.rn.ftz.f32 	%f6, %f2, %f2, %f5;
	fma.rn.ftz.f32 	%f7, %f1, %f1, %f6;
	sqrt.approx.ftz.f32 	%f8, %f7;
	sub.ftz.f32 	%f9, %f8, %f4;
	st.param.f32	[func_retval0+0], %f9;
	ret;
}

.visible .func  (.param .b32 func_retval0) _Z4sminfff(
	.param .b32 _Z4sminfff_param_0,
	.param .b32 _Z4sminfff_param_1,
	.param .b32 _Z4sminfff_param_2
)
{
	.reg .f32 	%f<16>;
	.reg .f64 	%fd<8>;


	ld.param.f32 	%f1, [_Z4sminfff_param_0];
	ld.param.f32 	%f2, [_Z4sminfff_param_1];
	ld.param.f32 	%f3, [_Z4sminfff_param_2];
	sub.ftz.f32 	%f4, %f2, %f1;
	mul.ftz.f32 	%f5, %f4, 0f3F000000;
	div.approx.ftz.f32 	%f6, %f5, %f3;
	add.ftz.f32 	%f7, %f6, 0f3F000000;
	mov.f32 	%f8, 0f3F800000;
	min.ftz.f32 	%f9, %f7, %f8;
	mov.f32 	%f10, 0f00000000;
	max.ftz.f32 	%f11, %f10, %f9;
	sub.ftz.f32 	%f12, %f1, %f2;
	fma.rn.ftz.f32 	%f13, %f11, %f12, %f2;
	cvt.ftz.f64.f32	%fd1, %f13;
	mul.ftz.f32 	%f14, %f11, %f3;
	cvt.ftz.f64.f32	%fd2, %f14;
	cvt.ftz.f64.f32	%fd3, %f11;
	mov.f64 	%fd4, 0d3FF0000000000000;
	sub.f64 	%fd5, %fd4, %fd3;
	mul.f64 	%fd6, %fd2, %fd5;
	sub.f64 	%fd7, %fd1, %fd6;
	cvt.rn.ftz.f32.f64	%f15, %fd7;
	st.param.f32	[func_retval0+0], %f15;
	ret;
}

.visible .func  (.param .b32 func_retval0) _Z7maxcomp6float3(
	.param .align 4 .b8 _Z7maxcomp6float3_param_0[12]
)
{
	.reg .f32 	%f<6>;


	ld.param.f32 	%f1, [_Z7maxcomp6float3_param_0];
	ld.param.f32 	%f2, [_Z7maxcomp6float3_param_0+8];
	ld.param.f32 	%f3, [_Z7maxcomp6float3_param_0+4];
	max.ftz.f32 	%f4, %f3, %f2;
	max.ftz.f32 	%f5, %f1, %f4;
	st.param.f32	[func_retval0+0], %f5;
	ret;
}

.visible .func  (.param .b32 func_retval0) _Z7sdCross6float3(
	.param .align 4 .b8 _Z7sdCross6float3_param_0[12]
)
{
	.reg .f32 	%f<46>;


	ld.param.f32 	%f1, [_Z7sdCross6float3_param_0+8];
	ld.param.f32 	%f2, [_Z7sdCross6float3_param_0+4];
	ld.param.f32 	%f3, [_Z7sdCross6float3_param_0];
	abs.ftz.f32 	%f4, %f3;
	abs.ftz.f32 	%f5, %f2;
	abs.ftz.f32 	%f6, %f1;
	add.ftz.f32 	%f7, %f4, 0fCB189680;
	add.ftz.f32 	%f8, %f5, 0fBF800000;
	add.ftz.f32 	%f9, %f6, 0fBF800000;
	max.ftz.f32 	%f10, %f8, %f9;
	max.ftz.f32 	%f11, %f7, %f10;
	mov.f32 	%f12, 0f00000000;
	min.ftz.f32 	%f13, %f11, %f12;
	max.ftz.f32 	%f14, %f7, %f12;
	max.ftz.f32 	%f15, %f8, %f12;
	max.ftz.f32 	%f16, %f9, %f12;
	mul.ftz.f32 	%f17, %f15, %f15;
	fma.rn.ftz.f32 	%f18, %f14, %f14, %f17;
	fma.rn.ftz.f32 	%f19, %f16, %f16, %f18;
	sqrt.approx.ftz.f32 	%f20, %f19;
	add.ftz.f32 	%f21, %f13, %f20;
	add.ftz.f32 	%f22, %f6, 0fCB189680;
	add.ftz.f32 	%f23, %f4, 0fBF800000;
	max.ftz.f32 	%f24, %f22, %f23;
	max.ftz.f32 	%f25, %f8, %f24;
	min.ftz.f32 	%f26, %f25, %f12;
	max.ftz.f32 	%f27, %f22, %f12;
	max.ftz.f32 	%f28, %f23, %f12;
	mul.ftz.f32 	%f29, %f27, %f27;
	fma.rn.ftz.f32 	%f30, %f15, %f15, %f29;
	mul.ftz.f32 	%f31, %f28, %f28;
	add.ftz.f32 	%f32, %f30, %f31;
	sqrt.approx.ftz.f32 	%f33, %f32;
	add.ftz.f32 	%f34, %f26, %f33;
	add.ftz.f32 	%f35, %f5, 0fCB189680;
	max.ftz.f32 	%f36, %f23, %f35;
	max.ftz.f32 	%f37, %f9, %f36;
	min.ftz.f32 	%f38, %f37, %f12;
	max.ftz.f32 	%f39, %f35, %f12;
	fma.rn.ftz.f32 	%f40, %f16, %f16, %f31;
	fma.rn.ftz.f32 	%f41, %f39, %f39, %f40;
	sqrt.approx.ftz.f32 	%f42, %f41;
	add.ftz.f32 	%f43, %f38, %f42;
	min.ftz.f32 	%f44, %f34, %f43;
	min.ftz.f32 	%f45, %f21, %f44;
	st.param.f32	[func_retval0+0], %f45;
	ret;
}

.visible .func  (.param .align 4 .b8 func_retval0[12]) _Z6myfmod6float3f(
	.param .align 4 .b8 _Z6myfmod6float3f_param_0[12],
	.param .b32 _Z6myfmod6float3f_param_1
)
{
	.reg .pred 	%p<31>;
	.reg .s32 	%r<28>;
	.reg .f32 	%f<69>;


	ld.param.f32 	%f37, [_Z6myfmod6float3f_param_0+8];
	ld.param.f32 	%f36, [_Z6myfmod6float3f_param_0+4];
	ld.param.f32 	%f1, [_Z6myfmod6float3f_param_0];
	ld.param.f32 	%f38, [_Z6myfmod6float3f_param_1];
	abs.ftz.f32 	%f61, %f1;
	setp.eq.ftz.f32	%p1, %f61, 0f7F800000;
	abs.ftz.f32 	%f3, %f38;
	setp.eq.ftz.f32	%p2, %f3, 0f00000000;
	or.pred  	%p3, %p1, %p2;
	@!%p3 bra 	BB9_2;
	bra.uni 	BB9_1;

BB9_1:
	mov.f32 	%f62, 0f7FFFFFFF;
	bra.uni 	BB9_7;

BB9_2:
	setp.ltu.ftz.f32	%p4, %f61, %f3;
	@%p4 bra 	BB9_6;

	mov.b32 	 %r1, %f3;
	and.b32  	%r2, %r1, 8388607;
	mov.b32 	 %r3, %f61;
	and.b32  	%r4, %r3, 2139095040;
	or.b32  	%r5, %r2, %r4;
	mov.b32 	 %f39, %r5;
	setp.gt.ftz.f32	%p5, %f39, %f61;
	mul.ftz.f32 	%f40, %f39, 0f3F000000;
	selp.f32	%f60, %f40, %f39, %p5;
	setp.ltu.ftz.f32	%p6, %f60, %f3;
	@%p6 bra 	BB9_5;

BB9_4:
	sub.ftz.f32 	%f41, %f61, %f60;
	setp.ltu.ftz.f32	%p7, %f61, %f60;
	selp.f32	%f61, %f61, %f41, %p7;
	mul.ftz.f32 	%f60, %f60, 0f3F000000;
	setp.ge.ftz.f32	%p8, %f60, %f3;
	@%p8 bra 	BB9_4;

BB9_5:
	mov.b32 	 %r6, %f1;
	and.b32  	%r7, %r6, -2147483648;
	mov.b32 	 %r8, %f61;
	or.b32  	%r9, %r8, %r7;
	mov.b32 	 %f62, %r9;
	bra.uni 	BB9_7;

BB9_6:
	setp.gtu.ftz.f32	%p9, %f3, 0f7F800000;
	add.ftz.f32 	%f42, %f1, %f38;
	selp.f32	%f43, %f42, %f1, %p9;
	add.ftz.f32 	%f44, %f43, %f1;
	setp.leu.ftz.f32	%p10, %f61, 0f00000000;
	selp.f32	%f62, %f44, %f43, %p10;

BB9_7:
	abs.ftz.f32 	%f64, %f36;
	setp.eq.ftz.f32	%p11, %f64, 0f7F800000;
	or.pred  	%p13, %p11, %p2;
	@!%p13 bra 	BB9_9;
	bra.uni 	BB9_8;

BB9_8:
	mov.f32 	%f65, 0f7FFFFFFF;
	bra.uni 	BB9_14;

BB9_9:
	setp.ltu.ftz.f32	%p14, %f64, %f3;
	@%p14 bra 	BB9_13;

	mov.b32 	 %r10, %f3;
	and.b32  	%r11, %r10, 8388607;
	mov.b32 	 %r12, %f64;
	and.b32  	%r13, %r12, 2139095040;
	or.b32  	%r14, %r11, %r13;
	mov.b32 	 %f46, %r14;
	setp.gt.ftz.f32	%p15, %f46, %f64;
	mul.ftz.f32 	%f47, %f46, 0f3F000000;
	selp.f32	%f63, %f47, %f46, %p15;
	setp.ltu.ftz.f32	%p16, %f63, %f3;
	@%p16 bra 	BB9_12;

BB9_11:
	sub.ftz.f32 	%f48, %f64, %f63;
	setp.ltu.ftz.f32	%p17, %f64, %f63;
	selp.f32	%f64, %f64, %f48, %p17;
	mul.ftz.f32 	%f63, %f63, 0f3F000000;
	setp.ge.ftz.f32	%p18, %f63, %f3;
	@%p18 bra 	BB9_11;

BB9_12:
	mov.b32 	 %r15, %f36;
	and.b32  	%r16, %r15, -2147483648;
	mov.b32 	 %r17, %f64;
	or.b32  	%r18, %r17, %r16;
	mov.b32 	 %f65, %r18;
	bra.uni 	BB9_14;

BB9_13:
	setp.gtu.ftz.f32	%p19, %f3, 0f7F800000;
	add.ftz.f32 	%f49, %f36, %f38;
	selp.f32	%f50, %f49, %f36, %p19;
	add.ftz.f32 	%f51, %f50, %f36;
	setp.leu.ftz.f32	%p20, %f64, 0f00000000;
	selp.f32	%f65, %f51, %f50, %p20;

BB9_14:
	abs.ftz.f32 	%f67, %f37;
	setp.eq.ftz.f32	%p21, %f67, 0f7F800000;
	or.pred  	%p23, %p21, %p2;
	@!%p23 bra 	BB9_16;
	bra.uni 	BB9_15;

BB9_15:
	mov.f32 	%f68, 0f7FFFFFFF;
	bra.uni 	BB9_21;

BB9_16:
	setp.ltu.ftz.f32	%p24, %f67, %f3;
	@%p24 bra 	BB9_20;

	mov.b32 	 %r19, %f3;
	and.b32  	%r20, %r19, 8388607;
	mov.b32 	 %r21, %f67;
	and.b32  	%r22, %r21, 2139095040;
	or.b32  	%r23, %r20, %r22;
	mov.b32 	 %f53, %r23;
	setp.gt.ftz.f32	%p25, %f53, %f67;
	mul.ftz.f32 	%f54, %f53, 0f3F000000;
	selp.f32	%f66, %f54, %f53, %p25;
	setp.ltu.ftz.f32	%p26, %f66, %f3;
	@%p26 bra 	BB9_19;

BB9_18:
	sub.ftz.f32 	%f55, %f67, %f66;
	setp.ltu.ftz.f32	%p27, %f67, %f66;
	selp.f32	%f67, %f67, %f55, %p27;
	mul.ftz.f32 	%f66, %f66, 0f3F000000;
	setp.ge.ftz.f32	%p28, %f66, %f3;
	@%p28 bra 	BB9_18;

BB9_19:
	mov.b32 	 %r24, %f37;
	and.b32  	%r25, %r24, -2147483648;
	mov.b32 	 %r26, %f67;
	or.b32  	%r27, %r26, %r25;
	mov.b32 	 %f68, %r27;
	bra.uni 	BB9_21;

BB9_20:
	setp.gtu.ftz.f32	%p29, %f3, 0f7F800000;
	add.ftz.f32 	%f56, %f37, %f38;
	selp.f32	%f57, %f56, %f37, %p29;
	add.ftz.f32 	%f58, %f57, %f37;
	setp.leu.ftz.f32	%p30, %f67, 0f00000000;
	selp.f32	%f68, %f58, %f57, %p30;

BB9_21:
	st.param.f32	[func_retval0+0], %f62;
	st.param.f32	[func_retval0+4], %f65;
	st.param.f32	[func_retval0+8], %f68;
	ret;
}

.visible .func  (.param .align 4 .b8 func_retval0[12]) _Z4pMod6float3f(
	.param .align 4 .b8 _Z4pMod6float3f_param_0[12],
	.param .b32 _Z4pMod6float3f_param_1
)
{
	.reg .pred 	%p<31>;
	.reg .s32 	%r<28>;
	.reg .f32 	%f<73>;


	ld.param.f32 	%f37, [_Z4pMod6float3f_param_0+8];
	ld.param.f32 	%f38, [_Z4pMod6float3f_param_0+4];
	ld.param.f32 	%f39, [_Z4pMod6float3f_param_0];
	ld.param.f32 	%f36, [_Z4pMod6float3f_param_1];
	add.ftz.f32 	%f1, %f39, %f36;
	add.ftz.f32 	%f2, %f38, %f36;
	add.ftz.f32 	%f3, %f37, %f36;
	abs.ftz.f32 	%f65, %f1;
	add.ftz.f32 	%f5, %f36, %f36;
	abs.ftz.f32 	%f6, %f5;
	setp.eq.ftz.f32	%p1, %f65, 0f7F800000;
	setp.eq.ftz.f32	%p2, %f6, 0f00000000;
	or.pred  	%p3, %p1, %p2;
	@!%p3 bra 	BB10_2;
	bra.uni 	BB10_1;

BB10_1:
	mov.f32 	%f66, 0f7FFFFFFF;
	bra.uni 	BB10_7;

BB10_2:
	setp.ltu.ftz.f32	%p4, %f65, %f6;
	@%p4 bra 	BB10_6;

	mov.b32 	 %r1, %f6;
	and.b32  	%r2, %r1, 8388607;
	mov.b32 	 %r3, %f65;
	and.b32  	%r4, %r3, 2139095040;
	or.b32  	%r5, %r2, %r4;
	mov.b32 	 %f40, %r5;
	setp.gt.ftz.f32	%p5, %f40, %f65;
	mul.ftz.f32 	%f41, %f40, 0f3F000000;
	selp.f32	%f64, %f41, %f40, %p5;
	setp.ltu.ftz.f32	%p6, %f64, %f6;
	@%p6 bra 	BB10_5;

BB10_4:
	sub.ftz.f32 	%f42, %f65, %f64;
	setp.ltu.ftz.f32	%p7, %f65, %f64;
	selp.f32	%f65, %f65, %f42, %p7;
	mul.ftz.f32 	%f64, %f64, 0f3F000000;
	setp.ge.ftz.f32	%p8, %f64, %f6;
	@%p8 bra 	BB10_4;

BB10_5:
	mov.b32 	 %r6, %f1;
	and.b32  	%r7, %r6, -2147483648;
	mov.b32 	 %r8, %f65;
	or.b32  	%r9, %r8, %r7;
	mov.b32 	 %f66, %r9;
	bra.uni 	BB10_7;

BB10_6:
	setp.gtu.ftz.f32	%p9, %f6, 0f7F800000;
	add.ftz.f32 	%f43, %f1, %f5;
	selp.f32	%f44, %f43, %f1, %p9;
	add.ftz.f32 	%f45, %f44, %f1;
	setp.leu.ftz.f32	%p10, %f65, 0f00000000;
	selp.f32	%f66, %f45, %f44, %p10;

BB10_7:
	abs.ftz.f32 	%f68, %f2;
	setp.eq.ftz.f32	%p11, %f68, 0f7F800000;
	or.pred  	%p13, %p11, %p2;
	@!%p13 bra 	BB10_9;
	bra.uni 	BB10_8;

BB10_8:
	mov.f32 	%f69, 0f7FFFFFFF;
	bra.uni 	BB10_14;

BB10_9:
	setp.ltu.ftz.f32	%p14, %f68, %f6;
	@%p14 bra 	BB10_13;

	mov.b32 	 %r10, %f6;
	and.b32  	%r11, %r10, 8388607;
	mov.b32 	 %r12, %f68;
	and.b32  	%r13, %r12, 2139095040;
	or.b32  	%r14, %r13, %r11;
	mov.b32 	 %f47, %r14;
	setp.gt.ftz.f32	%p15, %f47, %f68;
	mul.ftz.f32 	%f48, %f47, 0f3F000000;
	selp.f32	%f67, %f48, %f47, %p15;
	setp.ltu.ftz.f32	%p16, %f67, %f6;
	@%p16 bra 	BB10_12;

BB10_11:
	sub.ftz.f32 	%f49, %f68, %f67;
	setp.ltu.ftz.f32	%p17, %f68, %f67;
	selp.f32	%f68, %f68, %f49, %p17;
	mul.ftz.f32 	%f67, %f67, 0f3F000000;
	setp.ge.ftz.f32	%p18, %f67, %f6;
	@%p18 bra 	BB10_11;

BB10_12:
	mov.b32 	 %r15, %f2;
	and.b32  	%r16, %r15, -2147483648;
	mov.b32 	 %r17, %f68;
	or.b32  	%r18, %r17, %r16;
	mov.b32 	 %f69, %r18;
	bra.uni 	BB10_14;

BB10_13:
	setp.gtu.ftz.f32	%p19, %f6, 0f7F800000;
	add.ftz.f32 	%f50, %f2, %f5;
	selp.f32	%f51, %f50, %f2, %p19;
	add.ftz.f32 	%f52, %f51, %f2;
	setp.leu.ftz.f32	%p20, %f68, 0f00000000;
	selp.f32	%f69, %f52, %f51, %p20;

BB10_14:
	abs.ftz.f32 	%f71, %f3;
	setp.eq.ftz.f32	%p21, %f71, 0f7F800000;
	or.pred  	%p23, %p21, %p2;
	@!%p23 bra 	BB10_16;
	bra.uni 	BB10_15;

BB10_15:
	mov.f32 	%f72, 0f7FFFFFFF;
	bra.uni 	BB10_21;

BB10_16:
	setp.ltu.ftz.f32	%p24, %f71, %f6;
	@%p24 bra 	BB10_20;

	mov.b32 	 %r19, %f6;
	and.b32  	%r20, %r19, 8388607;
	mov.b32 	 %r21, %f71;
	and.b32  	%r22, %r21, 2139095040;
	or.b32  	%r23, %r22, %r20;
	mov.b32 	 %f54, %r23;
	setp.gt.ftz.f32	%p25, %f54, %f71;
	mul.ftz.f32 	%f55, %f54, 0f3F000000;
	selp.f32	%f70, %f55, %f54, %p25;
	setp.ltu.ftz.f32	%p26, %f70, %f6;
	@%p26 bra 	BB10_19;

BB10_18:
	sub.ftz.f32 	%f56, %f71, %f70;
	setp.ltu.ftz.f32	%p27, %f71, %f70;
	selp.f32	%f71, %f71, %f56, %p27;
	mul.ftz.f32 	%f70, %f70, 0f3F000000;
	setp.ge.ftz.f32	%p28, %f70, %f6;
	@%p28 bra 	BB10_18;

BB10_19:
	mov.b32 	 %r24, %f3;
	and.b32  	%r25, %r24, -2147483648;
	mov.b32 	 %r26, %f71;
	or.b32  	%r27, %r26, %r25;
	mov.b32 	 %f72, %r27;
	bra.uni 	BB10_21;

BB10_20:
	setp.gtu.ftz.f32	%p29, %f6, 0f7F800000;
	add.ftz.f32 	%f57, %f3, %f5;
	selp.f32	%f58, %f57, %f3, %p29;
	add.ftz.f32 	%f59, %f58, %f3;
	setp.leu.ftz.f32	%p30, %f71, 0f00000000;
	selp.f32	%f72, %f59, %f58, %p30;

BB10_21:
	sub.ftz.f32 	%f61, %f66, %f36;
	sub.ftz.f32 	%f62, %f69, %f36;
	sub.ftz.f32 	%f63, %f72, %f36;
	st.param.f32	[func_retval0+0], %f61;
	st.param.f32	[func_retval0+4], %f62;
	st.param.f32	[func_retval0+8], %f63;
	ret;
}

.visible .func  (.param .b32 func_retval0) _Z3map6float3(
	.param .align 4 .b8 _Z3map6float3_param_0[12]
)
{
	.reg .pred 	%p<32>;
	.reg .s32 	%r<28>;
	.reg .f32 	%f<151>;


	ld.param.f32 	%f1, [_Z3map6float3_param_0+8];
	ld.param.f32 	%f42, [_Z3map6float3_param_0+4];
	ld.param.f32 	%f41, [_Z3map6float3_param_0];
	abs.ftz.f32 	%f45, %f41;
	abs.ftz.f32 	%f46, %f42;
	abs.ftz.f32 	%f47, %f1;
	add.ftz.f32 	%f48, %f45, 0fBF800000;
	add.ftz.f32 	%f49, %f46, 0fBF800000;
	add.ftz.f32 	%f50, %f47, 0fBF800000;
	max.ftz.f32 	%f51, %f49, %f50;
	max.ftz.f32 	%f52, %f48, %f51;
	mov.f32 	%f53, 0f00000000;
	min.ftz.f32 	%f54, %f52, %f53;
	max.ftz.f32 	%f55, %f48, %f53;
	max.ftz.f32 	%f56, %f49, %f53;
	max.ftz.f32 	%f57, %f50, %f53;
	mul.ftz.f32 	%f58, %f56, %f56;
	fma.rn.ftz.f32 	%f59, %f55, %f55, %f58;
	fma.rn.ftz.f32 	%f60, %f57, %f57, %f59;
	sqrt.approx.ftz.f32 	%f61, %f60;
	add.ftz.f32 	%f141, %f54, %f61;
	mov.f32 	%f62, 0f40000000;
	abs.ftz.f32 	%f3, %f62;
	mov.b32 	 %r5, %f3;
	and.b32  	%r1, %r5, 8388607;
	mov.f32 	%f140, 0f3F800000;
	mov.u32 	%r27, 0;

BB11_1:
	mul.ftz.f32 	%f6, %f41, %f140;
	mul.ftz.f32 	%f7, %f42, %f140;
	mul.ftz.f32 	%f8, %f1, %f140;
	abs.ftz.f32 	%f143, %f6;
	setp.eq.ftz.f32	%p1, %f143, 0f7F800000;
	setp.eq.ftz.f32	%p2, %f3, 0f00000000;
	or.pred  	%p3, %p1, %p2;
	@!%p3 bra 	BB11_3;
	bra.uni 	BB11_2;

BB11_2:
	mov.f32 	%f144, 0f7FFFFFFF;
	bra.uni 	BB11_8;

BB11_3:
	setp.ltu.ftz.f32	%p4, %f143, %f3;
	@%p4 bra 	BB11_7;

	mov.b32 	 %r6, %f143;
	and.b32  	%r7, %r6, 2139095040;
	or.b32  	%r8, %r1, %r7;
	mov.b32 	 %f63, %r8;
	setp.gt.ftz.f32	%p5, %f63, %f143;
	mul.ftz.f32 	%f64, %f63, 0f3F000000;
	selp.f32	%f142, %f64, %f63, %p5;
	setp.ltu.ftz.f32	%p6, %f142, %f3;
	@%p6 bra 	BB11_6;

BB11_5:
	sub.ftz.f32 	%f65, %f143, %f142;
	setp.ltu.ftz.f32	%p7, %f143, %f142;
	selp.f32	%f143, %f143, %f65, %p7;
	mul.ftz.f32 	%f142, %f142, 0f3F000000;
	setp.ge.ftz.f32	%p8, %f142, %f3;
	@%p8 bra 	BB11_5;

BB11_6:
	mov.b32 	 %r9, %f6;
	and.b32  	%r10, %r9, -2147483648;
	mov.b32 	 %r11, %f143;
	or.b32  	%r12, %r11, %r10;
	mov.b32 	 %f144, %r12;
	bra.uni 	BB11_8;

BB11_7:
	setp.gtu.ftz.f32	%p9, %f3, 0f7F800000;
	add.ftz.f32 	%f66, %f6, 0f40000000;
	selp.f32	%f67, %f66, %f6, %p9;
	add.ftz.f32 	%f68, %f67, %f6;
	setp.leu.ftz.f32	%p10, %f143, 0f00000000;
	selp.f32	%f144, %f68, %f67, %p10;

BB11_8:
	abs.ftz.f32 	%f146, %f7;
	setp.eq.ftz.f32	%p11, %f146, 0f7F800000;
	or.pred  	%p13, %p11, %p2;
	@!%p13 bra 	BB11_10;
	bra.uni 	BB11_9;

BB11_9:
	mov.f32 	%f147, 0f7FFFFFFF;
	bra.uni 	BB11_15;

BB11_10:
	setp.ltu.ftz.f32	%p14, %f146, %f3;
	@%p14 bra 	BB11_14;

	mov.b32 	 %r13, %f146;
	and.b32  	%r14, %r13, 2139095040;
	or.b32  	%r15, %r14, %r1;
	mov.b32 	 %f70, %r15;
	setp.gt.ftz.f32	%p15, %f70, %f146;
	mul.ftz.f32 	%f71, %f70, 0f3F000000;
	selp.f32	%f145, %f71, %f70, %p15;
	setp.ltu.ftz.f32	%p16, %f145, %f3;
	@%p16 bra 	BB11_13;

BB11_12:
	sub.ftz.f32 	%f72, %f146, %f145;
	setp.ltu.ftz.f32	%p17, %f146, %f145;
	selp.f32	%f146, %f146, %f72, %p17;
	mul.ftz.f32 	%f145, %f145, 0f3F000000;
	setp.ge.ftz.f32	%p18, %f145, %f3;
	@%p18 bra 	BB11_12;

BB11_13:
	mov.b32 	 %r16, %f7;
	and.b32  	%r17, %r16, -2147483648;
	mov.b32 	 %r18, %f146;
	or.b32  	%r19, %r18, %r17;
	mov.b32 	 %f147, %r19;
	bra.uni 	BB11_15;

BB11_14:
	setp.gtu.ftz.f32	%p19, %f3, 0f7F800000;
	add.ftz.f32 	%f73, %f7, 0f40000000;
	selp.f32	%f74, %f73, %f7, %p19;
	add.ftz.f32 	%f75, %f74, %f7;
	setp.leu.ftz.f32	%p20, %f146, 0f00000000;
	selp.f32	%f147, %f75, %f74, %p20;

BB11_15:
	abs.ftz.f32 	%f149, %f8;
	setp.eq.ftz.f32	%p21, %f149, 0f7F800000;
	or.pred  	%p23, %p21, %p2;
	@!%p23 bra 	BB11_17;
	bra.uni 	BB11_16;

BB11_16:
	mov.f32 	%f150, 0f7FFFFFFF;
	bra.uni 	BB11_22;

BB11_17:
	setp.ltu.ftz.f32	%p24, %f149, %f3;
	@%p24 bra 	BB11_21;

	mov.b32 	 %r20, %f149;
	and.b32  	%r21, %r20, 2139095040;
	or.b32  	%r22, %r21, %r1;
	mov.b32 	 %f77, %r22;
	setp.gt.ftz.f32	%p25, %f77, %f149;
	mul.ftz.f32 	%f78, %f77, 0f3F000000;
	selp.f32	%f148, %f78, %f77, %p25;
	setp.ltu.ftz.f32	%p26, %f148, %f3;
	@%p26 bra 	BB11_20;

BB11_19:
	sub.ftz.f32 	%f79, %f149, %f148;
	setp.ltu.ftz.f32	%p27, %f149, %f148;
	selp.f32	%f149, %f149, %f79, %p27;
	mul.ftz.f32 	%f148, %f148, 0f3F000000;
	setp.ge.ftz.f32	%p28, %f148, %f3;
	@%p28 bra 	BB11_19;

BB11_20:
	mov.b32 	 %r23, %f8;
	and.b32  	%r24, %r23, -2147483648;
	mov.b32 	 %r25, %f149;
	or.b32  	%r26, %r25, %r24;
	mov.b32 	 %f150, %r26;
	bra.uni 	BB11_22;

BB11_21:
	setp.gtu.ftz.f32	%p29, %f3, 0f7F800000;
	add.ftz.f32 	%f80, %f8, 0f40000000;
	selp.f32	%f81, %f80, %f8, %p29;
	add.ftz.f32 	%f82, %f81, %f8;
	setp.leu.ftz.f32	%p30, %f149, 0f00000000;
	selp.f32	%f150, %f82, %f81, %p30;

BB11_22:
	add.ftz.f32 	%f84, %f144, 0fBF800000;
	abs.ftz.f32 	%f85, %f84;
	add.ftz.f32 	%f86, %f147, 0fBF800000;
	abs.ftz.f32 	%f87, %f86;
	add.ftz.f32 	%f88, %f150, 0fBF800000;
	abs.ftz.f32 	%f89, %f88;
	mul.ftz.f32 	%f90, %f85, 0f40400000;
	mul.ftz.f32 	%f91, %f87, 0f40400000;
	mul.ftz.f32 	%f92, %f89, 0f40400000;
	mov.f32 	%f93, 0f3F800000;
	sub.ftz.f32 	%f94, %f93, %f90;
	sub.ftz.f32 	%f95, %f93, %f91;
	sub.ftz.f32 	%f96, %f93, %f92;
	abs.ftz.f32 	%f97, %f94;
	abs.ftz.f32 	%f98, %f95;
	abs.ftz.f32 	%f99, %f96;
	add.ftz.f32 	%f100, %f97, 0fCB189680;
	add.ftz.f32 	%f101, %f98, 0fBF800000;
	add.ftz.f32 	%f102, %f99, 0fBF800000;
	max.ftz.f32 	%f103, %f101, %f102;
	max.ftz.f32 	%f104, %f100, %f103;
	min.ftz.f32 	%f106, %f104, %f53;
	max.ftz.f32 	%f107, %f100, %f53;
	max.ftz.f32 	%f108, %f101, %f53;
	max.ftz.f32 	%f109, %f102, %f53;
	mul.ftz.f32 	%f110, %f108, %f108;
	fma.rn.ftz.f32 	%f111, %f107, %f107, %f110;
	fma.rn.ftz.f32 	%f112, %f109, %f109, %f111;
	sqrt.approx.ftz.f32 	%f113, %f112;
	add.ftz.f32 	%f114, %f106, %f113;
	add.ftz.f32 	%f115, %f99, 0fCB189680;
	add.ftz.f32 	%f116, %f97, 0fBF800000;
	max.ftz.f32 	%f117, %f115, %f116;
	max.ftz.f32 	%f118, %f101, %f117;
	min.ftz.f32 	%f119, %f118, %f53;
	max.ftz.f32 	%f120, %f115, %f53;
	max.ftz.f32 	%f121, %f116, %f53;
	mul.ftz.f32 	%f122, %f120, %f120;
	fma.rn.ftz.f32 	%f123, %f108, %f108, %f122;
	mul.ftz.f32 	%f124, %f121, %f121;
	add.ftz.f32 	%f125, %f123, %f124;
	sqrt.approx.ftz.f32 	%f126, %f125;
	add.ftz.f32 	%f127, %f119, %f126;
	add.ftz.f32 	%f128, %f98, 0fCB189680;
	max.ftz.f32 	%f129, %f116, %f128;
	max.ftz.f32 	%f130, %f102, %f129;
	min.ftz.f32 	%f131, %f130, %f53;
	max.ftz.f32 	%f132, %f128, %f53;
	fma.rn.ftz.f32 	%f133, %f109, %f109, %f124;
	fma.rn.ftz.f32 	%f134, %f132, %f132, %f133;
	sqrt.approx.ftz.f32 	%f135, %f134;
	add.ftz.f32 	%f136, %f131, %f135;
	min.ftz.f32 	%f137, %f127, %f136;
	min.ftz.f32 	%f138, %f114, %f137;
	mul.ftz.f32 	%f140, %f140, 0f40400000;
	div.approx.ftz.f32 	%f139, %f138, %f140;
	max.ftz.f32 	%f141, %f141, %f139;
	add.s32 	%r27, %r27, 1;
	setp.lt.s32	%p31, %r27, 4;
	@%p31 bra 	BB11_1;

	st.param.f32	[func_retval0+0], %f141;
	ret;
}

.visible .func  (.param .b32 func_retval0) _Z5fracff(
	.param .b32 _Z5fracff_param_0
)
{
	.reg .f32 	%f<4>;


	ld.param.f32 	%f1, [_Z5fracff_param_0];
	cvt.rmi.ftz.f32.f32	%f2, %f1;
	sub.ftz.f32 	%f3, %f1, %f2;
	st.param.f32	[func_retval0+0], %f3;
	ret;
}

.visible .func  (.param .align 4 .b8 func_retval0[12]) _Z5fracf6float3(
	.param .align 4 .b8 _Z5fracf6float3_param_0[12]
)
{
	.reg .f32 	%f<10>;


	ld.param.f32 	%f1, [_Z5fracf6float3_param_0+8];
	ld.param.f32 	%f2, [_Z5fracf6float3_param_0+4];
	ld.param.f32 	%f3, [_Z5fracf6float3_param_0];
	cvt.rmi.ftz.f32.f32	%f4, %f3;
	sub.ftz.f32 	%f5, %f3, %f4;
	cvt.rmi.ftz.f32.f32	%f6, %f2;
	sub.ftz.f32 	%f7, %f3, %f6;
	cvt.rmi.ftz.f32.f32	%f8, %f1;
	sub.ftz.f32 	%f9, %f1, %f8;
	st.param.f32	[func_retval0+0], %f5;
	st.param.f32	[func_retval0+4], %f7;
	st.param.f32	[func_retval0+8], %f9;
	ret;
}

.visible .entry _Z9intersecti(
	.param .u32 _Z9intersecti_param_0
)
{
	.local .align 4 .b8 	__local_depot14[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<424>;
	.reg .s32 	%r<384>;
	.reg .f32 	%f<967>;
	.reg .s64 	%rd<50>;
	.reg .f64 	%fd<302>;


	mov.u64 	%SPL, __local_depot14;
	cvta.local.u64 	%SP, %SPL;
	mov.u32 	%r369, 0;
	st.global.u32 	[normal+8], %r369;
	mov.f32 	%f845, 0f00000000;
	st.global.v2.f32 	[normal], {%f845, %f845};
	ld.global.v2.f32 	{%f370, %f371}, [ray+8];
	ld.global.v2.f32 	{%f372, %f373}, [ray+16];
	ld.global.v2.f32 	{%f374, %f375}, [ray];
	mul.ftz.f32 	%f377, %f375, %f372;
	fma.rn.ftz.f32 	%f379, %f374, %f371, %f377;
	fma.rn.ftz.f32 	%f7, %f370, %f373, %f379;
	mul.ftz.f32 	%f381, %f375, %f375;
	fma.rn.ftz.f32 	%f382, %f374, %f374, %f381;
	fma.rn.ftz.f32 	%f383, %f370, %f370, %f382;
	add.ftz.f32 	%f384, %f383, 0fC1000000;
	mul.ftz.f32 	%f385, %f7, %f7;
	sub.ftz.f32 	%f8, %f385, %f384;
	setp.gt.ftz.f32	%p3, %f8, 0f00000000;
	@%p3 bra 	BB14_2;

	mov.pred 	%p4, 0;
	mov.f32 	%f387, 0f00000000;
	mov.f32 	%f966, %f387;
	mov.f32 	%f844, %f387;
	@!%p4 bra 	BB14_301;
	bra.uni 	BB14_3;

BB14_2:
	sqrt.approx.ftz.f32 	%f388, %f8;
	neg.ftz.f32 	%f389, %f7;
	sub.ftz.f32 	%f9, %f389, %f388;
	sub.ftz.f32 	%f390, %f388, %f7;
	setp.gt.ftz.f32	%p6, %f9, %f390;
	selp.f32	%f966, %f9, %f390, %p6;
	mov.pred 	%p5, -1;
	mov.f32 	%f844, %f9;
	@!%p5 bra 	BB14_301;
	bra.uni 	BB14_3;

BB14_3:
	ld.global.v2.f32 	{%f392, %f393}, [ray];
	fma.rn.ftz.f32 	%f841, %f371, %f844, %f392;
	fma.rn.ftz.f32 	%f842, %f372, %f844, %f393;
	ld.global.f32 	%f396, [ray+8];
	fma.rn.ftz.f32 	%f843, %f373, %f844, %f396;

BB14_4:
	setp.gt.u32	%p7, %r369, 799;
	@%p7 bra 	BB14_46;

	mov.f32 	%f398, 0f40000000;
	abs.ftz.f32 	%f21, %f398;
	mov.f32 	%f828, 0f3F800000;
	mov.u32 	%r370, 0;

BB14_6:
	mul.ftz.f32 	%f399, %f841, %f828;
	abs.ftz.f32 	%f23, %f399;
	setp.eq.ftz.f32	%p8, %f23, 0f7F800000;
	setp.eq.ftz.f32	%p9, %f21, 0f00000000;
	or.pred  	%p10, %p8, %p9;
	setp.ltu.ftz.f32	%p11, %f23, %f21;
	or.pred  	%p12, %p10, %p11;
	@%p12 bra 	BB14_9;

	mov.b32 	 %r42, %f23;
	and.b32  	%r43, %r42, 2139095040;
	mov.b32 	 %r44, %f21;
	and.b32  	%r45, %r44, 8388607;
	or.b32  	%r46, %r45, %r43;
	mov.b32 	 %f400, %r46;
	setp.gt.ftz.f32	%p13, %f400, %f23;
	mul.ftz.f32 	%f401, %f400, 0f3F000000;
	selp.f32	%f829, %f401, %f400, %p13;
	setp.ltu.ftz.f32	%p14, %f829, %f21;
	@%p14 bra 	BB14_9;

BB14_8:
	mul.ftz.f32 	%f829, %f829, 0f3F000000;
	setp.ge.ftz.f32	%p15, %f829, %f21;
	@%p15 bra 	BB14_8;

BB14_9:
	mul.ftz.f32 	%f402, %f842, %f828;
	abs.ftz.f32 	%f27, %f402;
	setp.eq.ftz.f32	%p17, %f27, 0f7F800000;
	or.pred  	%p18, %p17, %p9;
	setp.ltu.ftz.f32	%p19, %f27, %f21;
	or.pred  	%p20, %p18, %p19;
	@%p20 bra 	BB14_12;

	mov.b32 	 %r47, %f27;
	and.b32  	%r48, %r47, 2139095040;
	mov.b32 	 %r49, %f21;
	and.b32  	%r50, %r49, 8388607;
	or.b32  	%r51, %r48, %r50;
	mov.b32 	 %f403, %r51;
	setp.gt.ftz.f32	%p21, %f403, %f27;
	mul.ftz.f32 	%f404, %f403, 0f3F000000;
	selp.f32	%f830, %f404, %f403, %p21;
	setp.ltu.ftz.f32	%p22, %f830, %f21;
	@%p22 bra 	BB14_12;

BB14_11:
	mul.ftz.f32 	%f830, %f830, 0f3F000000;
	setp.ge.ftz.f32	%p23, %f830, %f21;
	@%p23 bra 	BB14_11;

BB14_12:
	mul.ftz.f32 	%f405, %f843, %f828;
	abs.ftz.f32 	%f31, %f405;
	setp.eq.ftz.f32	%p25, %f31, 0f7F800000;
	or.pred  	%p26, %p25, %p9;
	setp.ltu.ftz.f32	%p27, %f31, %f21;
	or.pred  	%p28, %p26, %p27;
	@%p28 bra 	BB14_15;

	mov.b32 	 %r52, %f31;
	and.b32  	%r53, %r52, 2139095040;
	mov.b32 	 %r54, %f21;
	and.b32  	%r55, %r54, 8388607;
	or.b32  	%r56, %r53, %r55;
	mov.b32 	 %f406, %r56;
	setp.gt.ftz.f32	%p29, %f406, %f31;
	mul.ftz.f32 	%f407, %f406, 0f3F000000;
	selp.f32	%f831, %f407, %f406, %p29;
	setp.ltu.ftz.f32	%p30, %f831, %f21;
	@%p30 bra 	BB14_15;

BB14_14:
	mul.ftz.f32 	%f831, %f831, 0f3F000000;
	setp.ge.ftz.f32	%p31, %f831, %f21;
	@%p31 bra 	BB14_14;

BB14_15:
	mul.ftz.f32 	%f828, %f828, 0f40400000;
	add.s32 	%r370, %r370, 1;
	setp.lt.s32	%p32, %r370, 4;
	@%p32 bra 	BB14_6;

	add.ftz.f32 	%f36, %f841, 0f3E4CCCCD;
	add.ftz.f32 	%f37, %f842, 0f3E4CCCCD;
	add.ftz.f32 	%f38, %f843, 0f3E4CCCCD;
	abs.ftz.f32 	%f833, %f36;
	setp.eq.ftz.f32	%p33, %f833, 0f7F800000;
	mov.f32 	%f408, 0f3ECCCCCD;
	abs.ftz.f32 	%f40, %f408;
	setp.eq.ftz.f32	%p34, %f40, 0f00000000;
	or.pred  	%p35, %p33, %p34;
	@!%p35 bra 	BB14_18;
	bra.uni 	BB14_17;

BB14_17:
	mov.f32 	%f834, 0f7FFFFFFF;
	bra.uni 	BB14_23;

BB14_18:
	setp.ltu.ftz.f32	%p36, %f833, %f40;
	@%p36 bra 	BB14_22;

	mov.b32 	 %r57, %f40;
	and.b32  	%r58, %r57, 8388607;
	mov.b32 	 %r59, %f833;
	and.b32  	%r60, %r59, 2139095040;
	or.b32  	%r61, %r58, %r60;
	mov.b32 	 %f409, %r61;
	setp.gt.ftz.f32	%p37, %f409, %f833;
	mul.ftz.f32 	%f410, %f409, 0f3F000000;
	selp.f32	%f832, %f410, %f409, %p37;
	setp.ltu.ftz.f32	%p38, %f832, %f40;
	@%p38 bra 	BB14_21;

BB14_20:
	sub.ftz.f32 	%f411, %f833, %f832;
	setp.ltu.ftz.f32	%p39, %f833, %f832;
	selp.f32	%f833, %f833, %f411, %p39;
	mul.ftz.f32 	%f832, %f832, 0f3F000000;
	setp.ge.ftz.f32	%p40, %f832, %f40;
	@%p40 bra 	BB14_20;

BB14_21:
	mov.b32 	 %r62, %f36;
	and.b32  	%r63, %r62, -2147483648;
	mov.b32 	 %r64, %f833;
	or.b32  	%r65, %r64, %r63;
	mov.b32 	 %f834, %r65;
	bra.uni 	BB14_23;

BB14_22:
	setp.gtu.ftz.f32	%p41, %f40, 0f7F800000;
	add.ftz.f32 	%f412, %f36, 0f3ECCCCCD;
	selp.f32	%f413, %f412, %f36, %p41;
	add.ftz.f32 	%f414, %f413, %f36;
	setp.leu.ftz.f32	%p42, %f833, 0f00000000;
	selp.f32	%f834, %f414, %f413, %p42;

BB14_23:
	abs.ftz.f32 	%f836, %f37;
	setp.eq.ftz.f32	%p43, %f836, 0f7F800000;
	or.pred  	%p45, %p43, %p34;
	@!%p45 bra 	BB14_25;
	bra.uni 	BB14_24;

BB14_24:
	mov.f32 	%f837, 0f7FFFFFFF;
	bra.uni 	BB14_30;

BB14_25:
	setp.ltu.ftz.f32	%p46, %f836, %f40;
	@%p46 bra 	BB14_29;

	mov.b32 	 %r66, %f40;
	and.b32  	%r67, %r66, 8388607;
	mov.b32 	 %r68, %f836;
	and.b32  	%r69, %r68, 2139095040;
	or.b32  	%r70, %r69, %r67;
	mov.b32 	 %f416, %r70;
	setp.gt.ftz.f32	%p47, %f416, %f836;
	mul.ftz.f32 	%f417, %f416, 0f3F000000;
	selp.f32	%f835, %f417, %f416, %p47;
	setp.ltu.ftz.f32	%p48, %f835, %f40;
	@%p48 bra 	BB14_28;

BB14_27:
	sub.ftz.f32 	%f418, %f836, %f835;
	setp.ltu.ftz.f32	%p49, %f836, %f835;
	selp.f32	%f836, %f836, %f418, %p49;
	mul.ftz.f32 	%f835, %f835, 0f3F000000;
	setp.ge.ftz.f32	%p50, %f835, %f40;
	@%p50 bra 	BB14_27;

BB14_28:
	mov.b32 	 %r71, %f37;
	and.b32  	%r72, %r71, -2147483648;
	mov.b32 	 %r73, %f836;
	or.b32  	%r74, %r73, %r72;
	mov.b32 	 %f837, %r74;
	bra.uni 	BB14_30;

BB14_29:
	setp.gtu.ftz.f32	%p51, %f40, 0f7F800000;
	add.ftz.f32 	%f419, %f37, 0f3ECCCCCD;
	selp.f32	%f420, %f419, %f37, %p51;
	add.ftz.f32 	%f421, %f420, %f37;
	setp.leu.ftz.f32	%p52, %f836, 0f00000000;
	selp.f32	%f837, %f421, %f420, %p52;

BB14_30:
	abs.ftz.f32 	%f839, %f38;
	setp.eq.ftz.f32	%p53, %f839, 0f7F800000;
	or.pred  	%p55, %p53, %p34;
	@!%p55 bra 	BB14_32;
	bra.uni 	BB14_31;

BB14_31:
	mov.f32 	%f840, 0f7FFFFFFF;
	bra.uni 	BB14_37;

BB14_32:
	setp.ltu.ftz.f32	%p56, %f839, %f40;
	@%p56 bra 	BB14_36;

	mov.b32 	 %r75, %f40;
	and.b32  	%r76, %r75, 8388607;
	mov.b32 	 %r77, %f839;
	and.b32  	%r78, %r77, 2139095040;
	or.b32  	%r79, %r78, %r76;
	mov.b32 	 %f423, %r79;
	setp.gt.ftz.f32	%p57, %f423, %f839;
	mul.ftz.f32 	%f424, %f423, 0f3F000000;
	selp.f32	%f838, %f424, %f423, %p57;
	setp.ltu.ftz.f32	%p58, %f838, %f40;
	@%p58 bra 	BB14_35;

BB14_34:
	sub.ftz.f32 	%f425, %f839, %f838;
	setp.ltu.ftz.f32	%p59, %f839, %f838;
	selp.f32	%f839, %f839, %f425, %p59;
	mul.ftz.f32 	%f838, %f838, 0f3F000000;
	setp.ge.ftz.f32	%p60, %f838, %f40;
	@%p60 bra 	BB14_34;

BB14_35:
	mov.b32 	 %r80, %f38;
	and.b32  	%r81, %r80, -2147483648;
	mov.b32 	 %r82, %f839;
	or.b32  	%r83, %r82, %r81;
	mov.b32 	 %f840, %r83;
	bra.uni 	BB14_37;

BB14_36:
	setp.gtu.ftz.f32	%p61, %f40, 0f7F800000;
	add.ftz.f32 	%f426, %f38, 0f3ECCCCCD;
	selp.f32	%f427, %f426, %f38, %p61;
	add.ftz.f32 	%f428, %f427, %f38;
	setp.leu.ftz.f32	%p62, %f839, 0f00000000;
	selp.f32	%f840, %f428, %f427, %p62;

BB14_37:
	ld.global.f32 	%f430, [global_t];
	cvt.ftz.f64.f32	%fd92, %f430;
	mul.f64 	%fd281, %fd92, 0d3FB0000000000000;
	abs.f64 	%fd93, %fd281;
	setp.neu.f64	%p63, %fd93, 0d7FF0000000000000;
	@%p63 bra 	BB14_39;

	mov.f64 	%fd94, 0d0000000000000000;
	mul.rn.f64 	%fd281, %fd281, %fd94;

BB14_39:
	add.u64 	%rd1, %SP, 24;
	mul.f64 	%fd95, %fd281, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r371, %fd95;
	cvta.to.local.u64 	%rd2, %rd1;
	st.local.u32 	[%rd2], %r371;
	cvt.rn.f64.s32	%fd96, %r371;
	neg.f64 	%fd97, %fd96;
	mov.f64 	%fd98, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd99, %fd97, %fd98, %fd281;
	mov.f64 	%fd100, 0d3C91A62633145C00;
	fma.rn.f64 	%fd101, %fd97, %fd100, %fd99;
	mov.f64 	%fd102, 0d397B839A252049C0;
	fma.rn.f64 	%fd282, %fd97, %fd102, %fd101;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r84}, %fd281;
	}
	and.b32  	%r85, %r84, 2145386496;
	setp.lt.u32	%p64, %r85, 1105199104;
	@%p64 bra 	BB14_41;

	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64	[param0+0], %fd281;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd1;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd282, [retval0+0];
	}
	// Callseq End 0
	ld.local.u32 	%r371, [%rd2];

BB14_41:
	and.b32  	%r86, %r371, 1;
	shl.b32 	%r87, %r86, 3;
	setp.eq.s32	%p65, %r86, 0;
	selp.f64	%fd103, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p65;
	mul.wide.u32 	%rd5, %r87, 8;
	mov.u64 	%rd6, __cudart_sin_cos_coeffs;
	add.s64 	%rd7, %rd5, %rd6;
	ld.const.f64 	%fd104, [%rd7+8];
	mul.rn.f64 	%fd7, %fd282, %fd282;
	fma.rn.f64 	%fd105, %fd103, %fd7, %fd104;
	ld.const.f64 	%fd106, [%rd7+16];
	fma.rn.f64 	%fd107, %fd105, %fd7, %fd106;
	ld.const.f64 	%fd108, [%rd7+24];
	fma.rn.f64 	%fd109, %fd107, %fd7, %fd108;
	ld.const.f64 	%fd110, [%rd7+32];
	fma.rn.f64 	%fd111, %fd109, %fd7, %fd110;
	ld.const.f64 	%fd112, [%rd7+40];
	fma.rn.f64 	%fd113, %fd111, %fd7, %fd112;
	ld.const.f64 	%fd114, [%rd7+48];
	fma.rn.f64 	%fd8, %fd113, %fd7, %fd114;
	fma.rn.f64 	%fd283, %fd8, %fd282, %fd282;
	@%p65 bra 	BB14_43;

	mov.f64 	%fd115, 0d3FF0000000000000;
	fma.rn.f64 	%fd283, %fd8, %fd7, %fd115;

BB14_43:
	and.b32  	%r88, %r371, 2;
	setp.eq.s32	%p66, %r88, 0;
	@%p66 bra 	BB14_45;

	mov.f64 	%fd116, 0d0000000000000000;
	mov.f64 	%fd117, 0dBFF0000000000000;
	fma.rn.f64 	%fd283, %fd283, %fd117, %fd116;

BB14_45:
	add.ftz.f32 	%f431, %f834, 0fBE4CCCCD;
	add.ftz.f32 	%f432, %f837, 0fBE4CCCCD;
	add.ftz.f32 	%f433, %f840, 0fBE4CCCCD;
	mul.f64 	%fd118, %fd283, 0d3FB99999A0000000;
	cvt.rn.ftz.f32.f64	%f434, %fd118;
	sub.ftz.f32 	%f435, %f431, %f434;
	sub.ftz.f32 	%f436, %f432, %f434;
	sub.ftz.f32 	%f437, %f433, %f434;
	abs.ftz.f32 	%f438, %f435;
	abs.ftz.f32 	%f439, %f436;
	abs.ftz.f32 	%f440, %f437;
	add.ftz.f32 	%f441, %f438, 0fBDCCCCCD;
	add.ftz.f32 	%f442, %f439, 0fBDCCCCCD;
	add.ftz.f32 	%f443, %f440, 0fBDCCCCCD;
	max.ftz.f32 	%f444, %f442, %f443;
	max.ftz.f32 	%f445, %f441, %f444;
	mov.f32 	%f446, 0f00000000;
	min.ftz.f32 	%f447, %f445, %f446;
	max.ftz.f32 	%f448, %f441, %f446;
	max.ftz.f32 	%f449, %f442, %f446;
	max.ftz.f32 	%f450, %f443, %f446;
	mul.ftz.f32 	%f451, %f449, %f449;
	fma.rn.ftz.f32 	%f452, %f448, %f448, %f451;
	fma.rn.ftz.f32 	%f453, %f450, %f450, %f452;
	sqrt.approx.ftz.f32 	%f454, %f453;
	add.ftz.f32 	%f845, %f447, %f454;
	fma.rn.ftz.f32 	%f841, %f371, %f845, %f841;
	fma.rn.ftz.f32 	%f842, %f372, %f845, %f842;
	fma.rn.ftz.f32 	%f843, %f373, %f845, %f843;
	add.ftz.f32 	%f844, %f844, %f845;
	setp.lt.ftz.f32	%p67, %f845, 0f3A83126F;
	setp.gt.ftz.f32	%p68, %f844, %f966;
	or.pred  	%p69, %p67, %p68;
	add.s32 	%r369, %r369, 1;
	@!%p69 bra 	BB14_4;
	bra.uni 	BB14_46;

BB14_46:
	setp.geu.ftz.f32	%p70, %f845, 0f3A83126F;
	@%p70 bra 	BB14_301;

	// inline asm
	call (%r89), _rt_potential_intersection, (%f844);
	// inline asm
	setp.eq.s32	%p71, %r89, 0;
	@%p71 bra 	BB14_301;

	ld.global.f32 	%f80, [DEL];
	add.ftz.f32 	%f81, %f841, %f80;
	add.ftz.f32 	%f82, %f842, 0f00000000;
	add.ftz.f32 	%f83, %f843, 0f00000000;
	mov.f32 	%f457, 0f40000000;
	abs.ftz.f32 	%f84, %f457;
	mov.b32 	 %r91, %f84;
	and.b32  	%r8, %r91, 8388607;
	mov.f32 	%f846, 0f3F800000;
	mov.u32 	%r372, 0;

BB14_49:
	mul.ftz.f32 	%f458, %f81, %f846;
	abs.ftz.f32 	%f86, %f458;
	setp.eq.ftz.f32	%p72, %f86, 0f7F800000;
	setp.eq.ftz.f32	%p73, %f84, 0f00000000;
	or.pred  	%p74, %p72, %p73;
	setp.ltu.ftz.f32	%p75, %f86, %f84;
	or.pred  	%p76, %p74, %p75;
	@%p76 bra 	BB14_52;

	mov.b32 	 %r92, %f86;
	and.b32  	%r93, %r92, 2139095040;
	or.b32  	%r94, %r8, %r93;
	mov.b32 	 %f459, %r94;
	setp.gt.ftz.f32	%p77, %f459, %f86;
	mul.ftz.f32 	%f460, %f459, 0f3F000000;
	selp.f32	%f847, %f460, %f459, %p77;
	setp.ltu.ftz.f32	%p78, %f847, %f84;
	@%p78 bra 	BB14_52;

BB14_51:
	mul.ftz.f32 	%f847, %f847, 0f3F000000;
	setp.ge.ftz.f32	%p79, %f847, %f84;
	@%p79 bra 	BB14_51;

BB14_52:
	mul.ftz.f32 	%f461, %f82, %f846;
	abs.ftz.f32 	%f90, %f461;
	setp.eq.ftz.f32	%p81, %f90, 0f7F800000;
	or.pred  	%p82, %p81, %p73;
	setp.ltu.ftz.f32	%p83, %f90, %f84;
	or.pred  	%p84, %p82, %p83;
	@%p84 bra 	BB14_55;

	mov.b32 	 %r95, %f90;
	and.b32  	%r96, %r95, 2139095040;
	or.b32  	%r97, %r96, %r8;
	mov.b32 	 %f462, %r97;
	setp.gt.ftz.f32	%p85, %f462, %f90;
	mul.ftz.f32 	%f463, %f462, 0f3F000000;
	selp.f32	%f848, %f463, %f462, %p85;
	setp.ltu.ftz.f32	%p86, %f848, %f84;
	@%p86 bra 	BB14_55;

BB14_54:
	mul.ftz.f32 	%f848, %f848, 0f3F000000;
	setp.ge.ftz.f32	%p87, %f848, %f84;
	@%p87 bra 	BB14_54;

BB14_55:
	mul.ftz.f32 	%f464, %f83, %f846;
	abs.ftz.f32 	%f94, %f464;
	setp.eq.ftz.f32	%p89, %f94, 0f7F800000;
	or.pred  	%p90, %p89, %p73;
	setp.ltu.ftz.f32	%p91, %f94, %f84;
	or.pred  	%p92, %p90, %p91;
	@%p92 bra 	BB14_58;

	mov.b32 	 %r98, %f94;
	and.b32  	%r99, %r98, 2139095040;
	or.b32  	%r100, %r99, %r8;
	mov.b32 	 %f465, %r100;
	setp.gt.ftz.f32	%p93, %f465, %f94;
	mul.ftz.f32 	%f466, %f465, 0f3F000000;
	selp.f32	%f849, %f466, %f465, %p93;
	setp.ltu.ftz.f32	%p94, %f849, %f84;
	@%p94 bra 	BB14_58;

BB14_57:
	mul.ftz.f32 	%f849, %f849, 0f3F000000;
	setp.ge.ftz.f32	%p95, %f849, %f84;
	@%p95 bra 	BB14_57;

BB14_58:
	mul.ftz.f32 	%f846, %f846, 0f40400000;
	add.s32 	%r372, %r372, 1;
	setp.lt.s32	%p96, %r372, 4;
	@%p96 bra 	BB14_49;

	add.ftz.f32 	%f99, %f81, 0f3E4CCCCD;
	add.ftz.f32 	%f100, %f82, 0f3E4CCCCD;
	add.ftz.f32 	%f101, %f83, 0f3E4CCCCD;
	abs.ftz.f32 	%f851, %f99;
	setp.eq.ftz.f32	%p97, %f851, 0f7F800000;
	mov.f32 	%f467, 0f3ECCCCCD;
	abs.ftz.f32 	%f103, %f467;
	setp.eq.ftz.f32	%p98, %f103, 0f00000000;
	or.pred  	%p99, %p97, %p98;
	@!%p99 bra 	BB14_61;
	bra.uni 	BB14_60;

BB14_60:
	mov.f32 	%f852, 0f7FFFFFFF;
	bra.uni 	BB14_66;

BB14_61:
	setp.ltu.ftz.f32	%p100, %f851, %f103;
	@%p100 bra 	BB14_65;

	mov.b32 	 %r101, %f103;
	and.b32  	%r102, %r101, 8388607;
	mov.b32 	 %r103, %f851;
	and.b32  	%r104, %r103, 2139095040;
	or.b32  	%r105, %r102, %r104;
	mov.b32 	 %f468, %r105;
	setp.gt.ftz.f32	%p101, %f468, %f851;
	mul.ftz.f32 	%f469, %f468, 0f3F000000;
	selp.f32	%f850, %f469, %f468, %p101;
	setp.ltu.ftz.f32	%p102, %f850, %f103;
	@%p102 bra 	BB14_64;

BB14_63:
	sub.ftz.f32 	%f470, %f851, %f850;
	setp.ltu.ftz.f32	%p103, %f851, %f850;
	selp.f32	%f851, %f851, %f470, %p103;
	mul.ftz.f32 	%f850, %f850, 0f3F000000;
	setp.ge.ftz.f32	%p104, %f850, %f103;
	@%p104 bra 	BB14_63;

BB14_64:
	mov.b32 	 %r106, %f99;
	and.b32  	%r107, %r106, -2147483648;
	mov.b32 	 %r108, %f851;
	or.b32  	%r109, %r108, %r107;
	mov.b32 	 %f852, %r109;
	bra.uni 	BB14_66;

BB14_65:
	setp.gtu.ftz.f32	%p105, %f103, 0f7F800000;
	add.ftz.f32 	%f471, %f99, 0f3ECCCCCD;
	selp.f32	%f472, %f471, %f99, %p105;
	add.ftz.f32 	%f473, %f472, %f99;
	setp.leu.ftz.f32	%p106, %f851, 0f00000000;
	selp.f32	%f852, %f473, %f472, %p106;

BB14_66:
	abs.ftz.f32 	%f113, %f100;
	setp.eq.ftz.f32	%p107, %f113, 0f7F800000;
	or.pred  	%p109, %p107, %p98;
	@!%p109 bra 	BB14_68;
	bra.uni 	BB14_67;

BB14_67:
	mov.f32 	%f854, 0f7FFFFFFF;
	bra.uni 	BB14_74;

BB14_68:
	setp.ltu.ftz.f32	%p110, %f113, %f103;
	@%p110 bra 	BB14_73;

	mov.b32 	 %r110, %f103;
	and.b32  	%r111, %r110, 8388607;
	mov.b32 	 %r112, %f113;
	and.b32  	%r113, %r112, 2139095040;
	or.b32  	%r114, %r113, %r111;
	mov.b32 	 %f475, %r114;
	setp.gt.ftz.f32	%p111, %f475, %f113;
	mul.ftz.f32 	%f476, %f475, 0f3F000000;
	selp.f32	%f853, %f476, %f475, %p111;
	setp.ltu.ftz.f32	%p112, %f853, %f103;
	mov.f32 	%f931, %f113;
	@%p112 bra 	BB14_72;

	mov.f32 	%f932, %f113;

BB14_71:
	sub.ftz.f32 	%f477, %f932, %f853;
	setp.ltu.ftz.f32	%p113, %f932, %f853;
	selp.f32	%f117, %f932, %f477, %p113;
	mul.ftz.f32 	%f853, %f853, 0f3F000000;
	setp.ge.ftz.f32	%p114, %f853, %f103;
	mov.f32 	%f932, %f117;
	mov.f32 	%f931, %f117;
	@%p114 bra 	BB14_71;

BB14_72:
	mov.f32 	%f119, %f931;
	mov.b32 	 %r115, %f100;
	and.b32  	%r116, %r115, -2147483648;
	mov.b32 	 %r117, %f119;
	or.b32  	%r118, %r117, %r116;
	mov.b32 	 %f854, %r118;
	bra.uni 	BB14_74;

BB14_73:
	setp.gtu.ftz.f32	%p115, %f103, 0f7F800000;
	add.ftz.f32 	%f478, %f100, 0f3ECCCCCD;
	selp.f32	%f479, %f478, %f100, %p115;
	add.ftz.f32 	%f480, %f479, %f100;
	setp.leu.ftz.f32	%p116, %f113, 0f00000000;
	selp.f32	%f854, %f480, %f479, %p116;

BB14_74:
	abs.ftz.f32 	%f123, %f101;
	setp.eq.ftz.f32	%p117, %f123, 0f7F800000;
	or.pred  	%p119, %p117, %p98;
	@!%p119 bra 	BB14_76;
	bra.uni 	BB14_75;

BB14_75:
	mov.f32 	%f856, 0f7FFFFFFF;
	bra.uni 	BB14_82;

BB14_76:
	setp.ltu.ftz.f32	%p120, %f123, %f103;
	@%p120 bra 	BB14_81;

	mov.b32 	 %r119, %f103;
	and.b32  	%r120, %r119, 8388607;
	mov.b32 	 %r121, %f123;
	and.b32  	%r122, %r121, 2139095040;
	or.b32  	%r123, %r122, %r120;
	mov.b32 	 %f482, %r123;
	setp.gt.ftz.f32	%p121, %f482, %f123;
	mul.ftz.f32 	%f483, %f482, 0f3F000000;
	selp.f32	%f855, %f483, %f482, %p121;
	setp.ltu.ftz.f32	%p122, %f855, %f103;
	mov.f32 	%f885, %f123;
	@%p122 bra 	BB14_80;

	mov.f32 	%f886, %f123;

BB14_79:
	sub.ftz.f32 	%f484, %f886, %f855;
	setp.ltu.ftz.f32	%p123, %f886, %f855;
	selp.f32	%f127, %f886, %f484, %p123;
	mul.ftz.f32 	%f855, %f855, 0f3F000000;
	setp.ge.ftz.f32	%p124, %f855, %f103;
	mov.f32 	%f886, %f127;
	mov.f32 	%f885, %f127;
	@%p124 bra 	BB14_79;

BB14_80:
	mov.f32 	%f129, %f885;
	mov.b32 	 %r124, %f101;
	and.b32  	%r125, %r124, -2147483648;
	mov.b32 	 %r126, %f129;
	or.b32  	%r127, %r126, %r125;
	mov.b32 	 %f856, %r127;
	bra.uni 	BB14_82;

BB14_81:
	setp.gtu.ftz.f32	%p125, %f103, 0f7F800000;
	add.ftz.f32 	%f485, %f101, 0f3ECCCCCD;
	selp.f32	%f486, %f485, %f101, %p125;
	add.ftz.f32 	%f487, %f486, %f101;
	setp.leu.ftz.f32	%p126, %f123, 0f00000000;
	selp.f32	%f856, %f487, %f486, %p126;

BB14_82:
	ld.global.f32 	%f489, [global_t];
	cvt.ftz.f64.f32	%fd119, %f489;
	mul.f64 	%fd284, %fd119, 0d3FB0000000000000;
	abs.f64 	%fd120, %fd284;
	setp.neu.f64	%p127, %fd120, 0d7FF0000000000000;
	@%p127 bra 	BB14_84;

	mov.f64 	%fd121, 0d0000000000000000;
	mul.rn.f64 	%fd284, %fd284, %fd121;

BB14_84:
	add.u64 	%rd8, %SP, 20;
	mul.f64 	%fd122, %fd284, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r373, %fd122;
	cvta.to.local.u64 	%rd9, %rd8;
	st.local.u32 	[%rd9], %r373;
	cvt.rn.f64.s32	%fd123, %r373;
	neg.f64 	%fd124, %fd123;
	mov.f64 	%fd125, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd126, %fd124, %fd125, %fd284;
	mov.f64 	%fd127, 0d3C91A62633145C00;
	fma.rn.f64 	%fd128, %fd124, %fd127, %fd126;
	mov.f64 	%fd129, 0d397B839A252049C0;
	fma.rn.f64 	%fd285, %fd124, %fd129, %fd128;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r128}, %fd284;
	}
	and.b32  	%r129, %r128, 2145386496;
	setp.lt.u32	%p128, %r129, 1105199104;
	@%p128 bra 	BB14_86;

	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64	[param0+0], %fd284;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd8;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd285, [retval0+0];
	}
	// Callseq End 1
	ld.local.u32 	%r373, [%rd9];

BB14_86:
	and.b32  	%r130, %r373, 1;
	shl.b32 	%r131, %r130, 3;
	setp.eq.s32	%p129, %r130, 0;
	selp.f64	%fd130, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p129;
	mul.wide.u32 	%rd12, %r131, 8;
	mov.u64 	%rd13, __cudart_sin_cos_coeffs;
	add.s64 	%rd14, %rd12, %rd13;
	ld.const.f64 	%fd131, [%rd14+8];
	mul.rn.f64 	%fd20, %fd285, %fd285;
	fma.rn.f64 	%fd132, %fd130, %fd20, %fd131;
	ld.const.f64 	%fd133, [%rd14+16];
	fma.rn.f64 	%fd134, %fd132, %fd20, %fd133;
	ld.const.f64 	%fd135, [%rd14+24];
	fma.rn.f64 	%fd136, %fd134, %fd20, %fd135;
	ld.const.f64 	%fd137, [%rd14+32];
	fma.rn.f64 	%fd138, %fd136, %fd20, %fd137;
	ld.const.f64 	%fd139, [%rd14+40];
	fma.rn.f64 	%fd140, %fd138, %fd20, %fd139;
	ld.const.f64 	%fd141, [%rd14+48];
	fma.rn.f64 	%fd21, %fd140, %fd20, %fd141;
	fma.rn.f64 	%fd286, %fd21, %fd285, %fd285;
	@%p129 bra 	BB14_88;

	mov.f64 	%fd142, 0d3FF0000000000000;
	fma.rn.f64 	%fd286, %fd21, %fd20, %fd142;

BB14_88:
	and.b32  	%r132, %r373, 2;
	setp.eq.s32	%p130, %r132, 0;
	@%p130 bra 	BB14_90;

	mov.f64 	%fd143, 0d0000000000000000;
	mov.f64 	%fd144, 0dBFF0000000000000;
	fma.rn.f64 	%fd286, %fd286, %fd144, %fd143;

BB14_90:
	add.ftz.f32 	%f491, %f852, 0fBE4CCCCD;
	add.ftz.f32 	%f492, %f854, 0fBE4CCCCD;
	add.ftz.f32 	%f493, %f856, 0fBE4CCCCD;
	mul.f64 	%fd145, %fd286, 0d3FB99999A0000000;
	cvt.rn.ftz.f32.f64	%f494, %fd145;
	sub.ftz.f32 	%f495, %f491, %f494;
	sub.ftz.f32 	%f496, %f492, %f494;
	sub.ftz.f32 	%f497, %f493, %f494;
	abs.ftz.f32 	%f498, %f495;
	abs.ftz.f32 	%f499, %f496;
	abs.ftz.f32 	%f500, %f497;
	add.ftz.f32 	%f501, %f498, 0fBDCCCCCD;
	add.ftz.f32 	%f502, %f499, 0fBDCCCCCD;
	add.ftz.f32 	%f503, %f500, 0fBDCCCCCD;
	max.ftz.f32 	%f504, %f502, %f503;
	max.ftz.f32 	%f505, %f501, %f504;
	mov.f32 	%f506, 0f00000000;
	min.ftz.f32 	%f507, %f505, %f506;
	max.ftz.f32 	%f508, %f501, %f506;
	max.ftz.f32 	%f509, %f502, %f506;
	max.ftz.f32 	%f510, %f503, %f506;
	mul.ftz.f32 	%f511, %f509, %f509;
	fma.rn.ftz.f32 	%f512, %f508, %f508, %f511;
	fma.rn.ftz.f32 	%f513, %f510, %f510, %f512;
	sqrt.approx.ftz.f32 	%f514, %f513;
	add.ftz.f32 	%f133, %f507, %f514;
	sub.ftz.f32 	%f134, %f841, %f80;
	add.ftz.f32 	%f135, %f842, 0f80000000;
	mov.f32 	%f857, 0f3F800000;
	mov.u32 	%r374, 0;

BB14_91:
	mul.ftz.f32 	%f515, %f134, %f857;
	abs.ftz.f32 	%f137, %f515;
	setp.eq.ftz.f32	%p131, %f137, 0f7F800000;
	or.pred  	%p133, %p131, %p73;
	setp.ltu.ftz.f32	%p134, %f137, %f84;
	or.pred  	%p135, %p133, %p134;
	@%p135 bra 	BB14_94;

	mov.b32 	 %r134, %f137;
	and.b32  	%r135, %r134, 2139095040;
	or.b32  	%r136, %r8, %r135;
	mov.b32 	 %f516, %r136;
	setp.gt.ftz.f32	%p136, %f516, %f137;
	mul.ftz.f32 	%f517, %f516, 0f3F000000;
	selp.f32	%f858, %f517, %f516, %p136;
	setp.ltu.ftz.f32	%p137, %f858, %f84;
	@%p137 bra 	BB14_94;

BB14_93:
	mul.ftz.f32 	%f858, %f858, 0f3F000000;
	setp.ge.ftz.f32	%p138, %f858, %f84;
	@%p138 bra 	BB14_93;

BB14_94:
	mul.ftz.f32 	%f518, %f135, %f857;
	abs.ftz.f32 	%f141, %f518;
	setp.eq.ftz.f32	%p140, %f141, 0f7F800000;
	or.pred  	%p141, %p140, %p73;
	setp.ltu.ftz.f32	%p142, %f141, %f84;
	or.pred  	%p143, %p141, %p142;
	@%p143 bra 	BB14_97;

	mov.b32 	 %r137, %f141;
	and.b32  	%r138, %r137, 2139095040;
	or.b32  	%r139, %r138, %r8;
	mov.b32 	 %f519, %r139;
	setp.gt.ftz.f32	%p144, %f519, %f141;
	mul.ftz.f32 	%f520, %f519, 0f3F000000;
	selp.f32	%f859, %f520, %f519, %p144;
	setp.ltu.ftz.f32	%p145, %f859, %f84;
	@%p145 bra 	BB14_97;

BB14_96:
	mul.ftz.f32 	%f859, %f859, 0f3F000000;
	setp.ge.ftz.f32	%p146, %f859, %f84;
	@%p146 bra 	BB14_96;

BB14_97:
	add.ftz.f32 	%f521, %f843, 0f80000000;
	mul.ftz.f32 	%f522, %f521, %f857;
	abs.ftz.f32 	%f145, %f522;
	setp.eq.ftz.f32	%p148, %f145, 0f7F800000;
	or.pred  	%p149, %p148, %p73;
	setp.ltu.ftz.f32	%p150, %f145, %f84;
	or.pred  	%p151, %p149, %p150;
	@%p151 bra 	BB14_100;

	mov.b32 	 %r140, %f145;
	and.b32  	%r141, %r140, 2139095040;
	or.b32  	%r142, %r141, %r8;
	mov.b32 	 %f523, %r142;
	setp.gt.ftz.f32	%p152, %f523, %f145;
	mul.ftz.f32 	%f524, %f523, 0f3F000000;
	selp.f32	%f860, %f524, %f523, %p152;
	setp.ltu.ftz.f32	%p153, %f860, %f84;
	@%p153 bra 	BB14_100;

BB14_99:
	mul.ftz.f32 	%f860, %f860, 0f3F000000;
	setp.ge.ftz.f32	%p154, %f860, %f84;
	@%p154 bra 	BB14_99;

BB14_100:
	mul.ftz.f32 	%f857, %f857, 0f40400000;
	add.s32 	%r374, %r374, 1;
	setp.lt.s32	%p155, %r374, 4;
	@%p155 bra 	BB14_91;

	add.ftz.f32 	%f150, %f135, 0f3E4CCCCD;
	add.ftz.f32 	%f151, %f134, 0f3E4CCCCD;
	abs.ftz.f32 	%f862, %f151;
	setp.eq.ftz.f32	%p157, %f862, 0f7F800000;
	or.pred  	%p158, %p157, %p98;
	@!%p158 bra 	BB14_103;
	bra.uni 	BB14_102;

BB14_102:
	mov.f32 	%f863, 0f7FFFFFFF;
	bra.uni 	BB14_108;

BB14_103:
	setp.ltu.ftz.f32	%p159, %f862, %f103;
	@%p159 bra 	BB14_107;

	mov.b32 	 %r143, %f103;
	and.b32  	%r144, %r143, 8388607;
	mov.b32 	 %r145, %f862;
	and.b32  	%r146, %r145, 2139095040;
	or.b32  	%r147, %r144, %r146;
	mov.b32 	 %f525, %r147;
	setp.gt.ftz.f32	%p160, %f525, %f862;
	mul.ftz.f32 	%f526, %f525, 0f3F000000;
	selp.f32	%f861, %f526, %f525, %p160;
	setp.ltu.ftz.f32	%p161, %f861, %f103;
	@%p161 bra 	BB14_106;

BB14_105:
	sub.ftz.f32 	%f527, %f862, %f861;
	setp.ltu.ftz.f32	%p162, %f862, %f861;
	selp.f32	%f862, %f862, %f527, %p162;
	mul.ftz.f32 	%f861, %f861, 0f3F000000;
	setp.ge.ftz.f32	%p163, %f861, %f103;
	@%p163 bra 	BB14_105;

BB14_106:
	mov.b32 	 %r148, %f151;
	and.b32  	%r149, %r148, -2147483648;
	mov.b32 	 %r150, %f862;
	or.b32  	%r151, %r150, %r149;
	mov.b32 	 %f863, %r151;
	bra.uni 	BB14_108;

BB14_107:
	setp.gtu.ftz.f32	%p164, %f103, 0f7F800000;
	add.ftz.f32 	%f528, %f151, 0f3ECCCCCD;
	selp.f32	%f529, %f528, %f151, %p164;
	add.ftz.f32 	%f530, %f529, %f151;
	setp.leu.ftz.f32	%p165, %f862, 0f00000000;
	selp.f32	%f863, %f530, %f529, %p165;

BB14_108:
	abs.ftz.f32 	%f162, %f150;
	setp.eq.ftz.f32	%p166, %f162, 0f7F800000;
	or.pred  	%p168, %p166, %p98;
	@!%p168 bra 	BB14_110;
	bra.uni 	BB14_109;

BB14_109:
	mov.f32 	%f865, 0f7FFFFFFF;
	bra.uni 	BB14_116;

BB14_110:
	setp.ltu.ftz.f32	%p169, %f162, %f103;
	@%p169 bra 	BB14_115;

	mov.b32 	 %r152, %f103;
	and.b32  	%r153, %r152, 8388607;
	mov.b32 	 %r154, %f162;
	and.b32  	%r155, %r154, 2139095040;
	or.b32  	%r156, %r155, %r153;
	mov.b32 	 %f532, %r156;
	setp.gt.ftz.f32	%p170, %f532, %f162;
	mul.ftz.f32 	%f533, %f532, 0f3F000000;
	selp.f32	%f864, %f533, %f532, %p170;
	setp.ltu.ftz.f32	%p171, %f864, %f103;
	mov.f32 	%f960, %f162;
	@%p171 bra 	BB14_114;

	mov.f32 	%f961, %f162;

BB14_113:
	sub.ftz.f32 	%f534, %f961, %f864;
	setp.ltu.ftz.f32	%p172, %f961, %f864;
	selp.f32	%f166, %f961, %f534, %p172;
	mul.ftz.f32 	%f864, %f864, 0f3F000000;
	setp.ge.ftz.f32	%p173, %f864, %f103;
	mov.f32 	%f961, %f166;
	mov.f32 	%f960, %f166;
	@%p173 bra 	BB14_113;

BB14_114:
	mov.f32 	%f168, %f960;
	mov.b32 	 %r157, %f150;
	and.b32  	%r158, %r157, -2147483648;
	mov.b32 	 %r159, %f168;
	or.b32  	%r160, %r159, %r158;
	mov.b32 	 %f865, %r160;
	bra.uni 	BB14_116;

BB14_115:
	setp.gtu.ftz.f32	%p174, %f103, 0f7F800000;
	add.ftz.f32 	%f535, %f150, 0f3ECCCCCD;
	selp.f32	%f536, %f535, %f150, %p174;
	add.ftz.f32 	%f537, %f536, %f150;
	setp.leu.ftz.f32	%p175, %f162, 0f00000000;
	selp.f32	%f865, %f537, %f536, %p175;

BB14_116:
	add.ftz.f32 	%f540, %f521, 0f3E4CCCCD;
	abs.ftz.f32 	%f172, %f540;
	setp.eq.ftz.f32	%p176, %f172, 0f7F800000;
	or.pred  	%p178, %p176, %p98;
	@!%p178 bra 	BB14_118;
	bra.uni 	BB14_117;

BB14_117:
	mov.f32 	%f867, 0f7FFFFFFF;
	bra.uni 	BB14_124;

BB14_118:
	setp.ltu.ftz.f32	%p179, %f172, %f103;
	@%p179 bra 	BB14_123;

	mov.b32 	 %r161, %f103;
	and.b32  	%r162, %r161, 8388607;
	mov.b32 	 %r163, %f172;
	and.b32  	%r164, %r163, 2139095040;
	or.b32  	%r165, %r164, %r162;
	mov.b32 	 %f541, %r165;
	setp.gt.ftz.f32	%p180, %f541, %f172;
	mul.ftz.f32 	%f542, %f541, 0f3F000000;
	selp.f32	%f866, %f542, %f541, %p180;
	setp.ltu.ftz.f32	%p181, %f866, %f103;
	mov.f32 	%f905, %f172;
	@%p181 bra 	BB14_122;

	mov.f32 	%f906, %f172;

BB14_121:
	sub.ftz.f32 	%f543, %f906, %f866;
	setp.ltu.ftz.f32	%p182, %f906, %f866;
	selp.f32	%f176, %f906, %f543, %p182;
	mul.ftz.f32 	%f866, %f866, 0f3F000000;
	setp.ge.ftz.f32	%p183, %f866, %f103;
	mov.f32 	%f906, %f176;
	mov.f32 	%f905, %f176;
	@%p183 bra 	BB14_121;

BB14_122:
	mov.f32 	%f178, %f905;
	mov.b32 	 %r166, %f540;
	and.b32  	%r167, %r166, -2147483648;
	mov.b32 	 %r168, %f178;
	or.b32  	%r169, %r168, %r167;
	mov.b32 	 %f867, %r169;
	bra.uni 	BB14_124;

BB14_123:
	setp.gtu.ftz.f32	%p184, %f103, 0f7F800000;
	add.ftz.f32 	%f548, %f540, 0f3ECCCCCD;
	selp.f32	%f549, %f548, %f540, %p184;
	add.ftz.f32 	%f550, %f549, %f540;
	setp.leu.ftz.f32	%p185, %f172, 0f00000000;
	selp.f32	%f867, %f550, %f549, %p185;

BB14_124:
	ld.global.f32 	%f552, [global_t];
	cvt.ftz.f64.f32	%fd146, %f552;
	mul.f64 	%fd287, %fd146, 0d3FB0000000000000;
	abs.f64 	%fd147, %fd287;
	setp.neu.f64	%p186, %fd147, 0d7FF0000000000000;
	@%p186 bra 	BB14_126;

	mov.f64 	%fd148, 0d0000000000000000;
	mul.rn.f64 	%fd287, %fd287, %fd148;

BB14_126:
	add.u64 	%rd15, %SP, 16;
	mul.f64 	%fd149, %fd287, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r375, %fd149;
	cvta.to.local.u64 	%rd16, %rd15;
	st.local.u32 	[%rd16], %r375;
	cvt.rn.f64.s32	%fd150, %r375;
	neg.f64 	%fd151, %fd150;
	fma.rn.f64 	%fd153, %fd151, %fd125, %fd287;
	fma.rn.f64 	%fd155, %fd151, %fd127, %fd153;
	fma.rn.f64 	%fd288, %fd151, %fd129, %fd155;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r170}, %fd287;
	}
	and.b32  	%r171, %r170, 2145386496;
	setp.lt.u32	%p187, %r171, 1105199104;
	@%p187 bra 	BB14_128;

	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64	[param0+0], %fd287;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd288, [retval0+0];
	}
	// Callseq End 2
	ld.local.u32 	%r375, [%rd16];

BB14_128:
	and.b32  	%r172, %r375, 1;
	shl.b32 	%r173, %r172, 3;
	setp.eq.s32	%p188, %r172, 0;
	selp.f64	%fd157, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p188;
	mul.wide.u32 	%rd19, %r173, 8;
	add.s64 	%rd21, %rd19, %rd13;
	ld.const.f64 	%fd158, [%rd21+8];
	mul.rn.f64 	%fd33, %fd288, %fd288;
	fma.rn.f64 	%fd159, %fd157, %fd33, %fd158;
	ld.const.f64 	%fd160, [%rd21+16];
	fma.rn.f64 	%fd161, %fd159, %fd33, %fd160;
	ld.const.f64 	%fd162, [%rd21+24];
	fma.rn.f64 	%fd163, %fd161, %fd33, %fd162;
	ld.const.f64 	%fd164, [%rd21+32];
	fma.rn.f64 	%fd165, %fd163, %fd33, %fd164;
	ld.const.f64 	%fd166, [%rd21+40];
	fma.rn.f64 	%fd167, %fd165, %fd33, %fd166;
	ld.const.f64 	%fd168, [%rd21+48];
	fma.rn.f64 	%fd34, %fd167, %fd33, %fd168;
	fma.rn.f64 	%fd289, %fd34, %fd288, %fd288;
	@%p188 bra 	BB14_130;

	mov.f64 	%fd169, 0d3FF0000000000000;
	fma.rn.f64 	%fd289, %fd34, %fd33, %fd169;

BB14_130:
	and.b32  	%r174, %r375, 2;
	setp.eq.s32	%p189, %r174, 0;
	@%p189 bra 	BB14_132;

	mov.f64 	%fd170, 0d0000000000000000;
	mov.f64 	%fd171, 0dBFF0000000000000;
	fma.rn.f64 	%fd289, %fd289, %fd171, %fd170;

BB14_132:
	add.ftz.f32 	%f554, %f863, 0fBE4CCCCD;
	add.ftz.f32 	%f555, %f865, 0fBE4CCCCD;
	add.ftz.f32 	%f556, %f867, 0fBE4CCCCD;
	mul.f64 	%fd172, %fd289, 0d3FB99999A0000000;
	cvt.rn.ftz.f32.f64	%f557, %fd172;
	sub.ftz.f32 	%f558, %f554, %f557;
	sub.ftz.f32 	%f559, %f555, %f557;
	sub.ftz.f32 	%f560, %f556, %f557;
	abs.ftz.f32 	%f561, %f558;
	abs.ftz.f32 	%f562, %f559;
	abs.ftz.f32 	%f563, %f560;
	add.ftz.f32 	%f564, %f561, 0fBDCCCCCD;
	add.ftz.f32 	%f565, %f562, 0fBDCCCCCD;
	add.ftz.f32 	%f566, %f563, 0fBDCCCCCD;
	max.ftz.f32 	%f567, %f565, %f566;
	max.ftz.f32 	%f568, %f564, %f567;
	min.ftz.f32 	%f570, %f568, %f506;
	max.ftz.f32 	%f571, %f564, %f506;
	max.ftz.f32 	%f572, %f565, %f506;
	max.ftz.f32 	%f573, %f566, %f506;
	mul.ftz.f32 	%f574, %f572, %f572;
	fma.rn.ftz.f32 	%f575, %f571, %f571, %f574;
	fma.rn.ftz.f32 	%f576, %f573, %f573, %f575;
	sqrt.approx.ftz.f32 	%f577, %f576;
	add.ftz.f32 	%f578, %f570, %f577;
	sub.ftz.f32 	%f182, %f133, %f578;
	add.ftz.f32 	%f183, %f841, 0f00000000;
	add.ftz.f32 	%f184, %f842, %f80;
	mov.f32 	%f868, 0f3F800000;
	mov.u32 	%r376, 0;

BB14_133:
	mul.ftz.f32 	%f579, %f183, %f868;
	abs.ftz.f32 	%f186, %f579;
	setp.eq.ftz.f32	%p190, %f186, 0f7F800000;
	or.pred  	%p192, %p190, %p73;
	setp.ltu.ftz.f32	%p193, %f186, %f84;
	or.pred  	%p194, %p192, %p193;
	@%p194 bra 	BB14_136;

	mov.b32 	 %r176, %f186;
	and.b32  	%r177, %r176, 2139095040;
	or.b32  	%r180, %r8, %r177;
	mov.b32 	 %f580, %r180;
	setp.gt.ftz.f32	%p195, %f580, %f186;
	mul.ftz.f32 	%f581, %f580, 0f3F000000;
	selp.f32	%f869, %f581, %f580, %p195;
	setp.ltu.ftz.f32	%p196, %f869, %f84;
	@%p196 bra 	BB14_136;

BB14_135:
	mul.ftz.f32 	%f869, %f869, 0f3F000000;
	setp.ge.ftz.f32	%p197, %f869, %f84;
	@%p197 bra 	BB14_135;

BB14_136:
	mul.ftz.f32 	%f582, %f184, %f868;
	abs.ftz.f32 	%f190, %f582;
	setp.eq.ftz.f32	%p199, %f190, 0f7F800000;
	or.pred  	%p200, %p199, %p73;
	setp.ltu.ftz.f32	%p201, %f190, %f84;
	or.pred  	%p202, %p200, %p201;
	@%p202 bra 	BB14_139;

	mov.b32 	 %r181, %f190;
	and.b32  	%r182, %r181, 2139095040;
	or.b32  	%r185, %r182, %r8;
	mov.b32 	 %f583, %r185;
	setp.gt.ftz.f32	%p203, %f583, %f190;
	mul.ftz.f32 	%f584, %f583, 0f3F000000;
	selp.f32	%f870, %f584, %f583, %p203;
	setp.ltu.ftz.f32	%p204, %f870, %f84;
	@%p204 bra 	BB14_139;

BB14_138:
	mul.ftz.f32 	%f870, %f870, 0f3F000000;
	setp.ge.ftz.f32	%p205, %f870, %f84;
	@%p205 bra 	BB14_138;

BB14_139:
	mul.ftz.f32 	%f586, %f83, %f868;
	abs.ftz.f32 	%f194, %f586;
	setp.eq.ftz.f32	%p207, %f194, 0f7F800000;
	or.pred  	%p208, %p207, %p73;
	setp.ltu.ftz.f32	%p209, %f194, %f84;
	or.pred  	%p210, %p208, %p209;
	@%p210 bra 	BB14_142;

	mov.b32 	 %r186, %f194;
	and.b32  	%r187, %r186, 2139095040;
	or.b32  	%r190, %r187, %r8;
	mov.b32 	 %f587, %r190;
	setp.gt.ftz.f32	%p211, %f587, %f194;
	mul.ftz.f32 	%f588, %f587, 0f3F000000;
	selp.f32	%f871, %f588, %f587, %p211;
	setp.ltu.ftz.f32	%p212, %f871, %f84;
	@%p212 bra 	BB14_142;

BB14_141:
	mul.ftz.f32 	%f871, %f871, 0f3F000000;
	setp.ge.ftz.f32	%p213, %f871, %f84;
	@%p213 bra 	BB14_141;

BB14_142:
	mul.ftz.f32 	%f868, %f868, 0f40400000;
	add.s32 	%r376, %r376, 1;
	setp.lt.s32	%p214, %r376, 4;
	@%p214 bra 	BB14_133;

	add.ftz.f32 	%f199, %f184, 0f3E4CCCCD;
	add.ftz.f32 	%f200, %f183, 0f3E4CCCCD;
	abs.ftz.f32 	%f201, %f200;
	setp.eq.ftz.f32	%p216, %f201, 0f7F800000;
	or.pred  	%p217, %p216, %p98;
	@!%p217 bra 	BB14_145;
	bra.uni 	BB14_144;

BB14_144:
	mov.f32 	%f873, 0f7FFFFFFF;
	bra.uni 	BB14_151;

BB14_145:
	setp.ltu.ftz.f32	%p218, %f201, %f103;
	@%p218 bra 	BB14_150;

	mov.b32 	 %r191, %f103;
	and.b32  	%r192, %r191, 8388607;
	mov.b32 	 %r193, %f201;
	and.b32  	%r194, %r193, 2139095040;
	or.b32  	%r195, %r192, %r194;
	mov.b32 	 %f589, %r195;
	setp.gt.ftz.f32	%p219, %f589, %f201;
	mul.ftz.f32 	%f590, %f589, 0f3F000000;
	selp.f32	%f872, %f590, %f589, %p219;
	setp.ltu.ftz.f32	%p220, %f872, %f103;
	mov.f32 	%f920, %f201;
	@%p220 bra 	BB14_149;

	mov.f32 	%f921, %f201;

BB14_148:
	sub.ftz.f32 	%f591, %f921, %f872;
	setp.ltu.ftz.f32	%p221, %f921, %f872;
	selp.f32	%f205, %f921, %f591, %p221;
	mul.ftz.f32 	%f872, %f872, 0f3F000000;
	setp.ge.ftz.f32	%p222, %f872, %f103;
	mov.f32 	%f921, %f205;
	mov.f32 	%f920, %f205;
	@%p222 bra 	BB14_148;

BB14_149:
	mov.f32 	%f207, %f920;
	mov.b32 	 %r196, %f200;
	and.b32  	%r197, %r196, -2147483648;
	mov.b32 	 %r198, %f207;
	or.b32  	%r199, %r198, %r197;
	mov.b32 	 %f873, %r199;
	bra.uni 	BB14_151;

BB14_150:
	setp.gtu.ftz.f32	%p223, %f103, 0f7F800000;
	add.ftz.f32 	%f592, %f200, 0f3ECCCCCD;
	selp.f32	%f593, %f592, %f200, %p223;
	add.ftz.f32 	%f594, %f593, %f200;
	setp.leu.ftz.f32	%p224, %f201, 0f00000000;
	selp.f32	%f873, %f594, %f593, %p224;

BB14_151:
	abs.ftz.f32 	%f875, %f199;
	setp.eq.ftz.f32	%p225, %f875, 0f7F800000;
	or.pred  	%p227, %p225, %p98;
	@!%p227 bra 	BB14_153;
	bra.uni 	BB14_152;

BB14_152:
	mov.f32 	%f876, 0f7FFFFFFF;
	bra.uni 	BB14_158;

BB14_153:
	setp.ltu.ftz.f32	%p228, %f875, %f103;
	@%p228 bra 	BB14_157;

	mov.b32 	 %r200, %f103;
	and.b32  	%r201, %r200, 8388607;
	mov.b32 	 %r202, %f875;
	and.b32  	%r203, %r202, 2139095040;
	or.b32  	%r204, %r203, %r201;
	mov.b32 	 %f596, %r204;
	setp.gt.ftz.f32	%p229, %f596, %f875;
	mul.ftz.f32 	%f597, %f596, 0f3F000000;
	selp.f32	%f874, %f597, %f596, %p229;
	setp.ltu.ftz.f32	%p230, %f874, %f103;
	@%p230 bra 	BB14_156;

BB14_155:
	sub.ftz.f32 	%f598, %f875, %f874;
	setp.ltu.ftz.f32	%p231, %f875, %f874;
	selp.f32	%f875, %f875, %f598, %p231;
	mul.ftz.f32 	%f874, %f874, 0f3F000000;
	setp.ge.ftz.f32	%p232, %f874, %f103;
	@%p232 bra 	BB14_155;

BB14_156:
	mov.b32 	 %r205, %f199;
	and.b32  	%r206, %r205, -2147483648;
	mov.b32 	 %r207, %f875;
	or.b32  	%r208, %r207, %r206;
	mov.b32 	 %f876, %r208;
	bra.uni 	BB14_158;

BB14_157:
	setp.gtu.ftz.f32	%p233, %f103, 0f7F800000;
	add.ftz.f32 	%f599, %f199, 0f3ECCCCCD;
	selp.f32	%f600, %f599, %f199, %p233;
	add.ftz.f32 	%f601, %f600, %f199;
	setp.leu.ftz.f32	%p234, %f875, 0f00000000;
	selp.f32	%f876, %f601, %f600, %p234;

BB14_158:
	@!%p119 bra 	BB14_160;
	bra.uni 	BB14_159;

BB14_159:
	mov.f32 	%f887, 0f7FFFFFFF;
	bra.uni 	BB14_166;

BB14_160:
	setp.ltu.ftz.f32	%p238, %f123, %f103;
	@%p238 bra 	BB14_165;

	mov.b32 	 %r209, %f103;
	and.b32  	%r210, %r209, 8388607;
	mov.b32 	 %r211, %f123;
	and.b32  	%r212, %r211, 2139095040;
	or.b32  	%r213, %r212, %r210;
	mov.b32 	 %f603, %r213;
	setp.gt.ftz.f32	%p239, %f603, %f123;
	mul.ftz.f32 	%f604, %f603, 0f3F000000;
	selp.f32	%f877, %f604, %f603, %p239;
	setp.ltu.ftz.f32	%p240, %f877, %f103;
	mov.f32 	%f883, %f123;
	@%p240 bra 	BB14_164;

	mov.f32 	%f884, %f123;

BB14_163:
	sub.ftz.f32 	%f605, %f884, %f877;
	setp.ltu.ftz.f32	%p241, %f884, %f877;
	selp.f32	%f883, %f884, %f605, %p241;
	mul.ftz.f32 	%f877, %f877, 0f3F000000;
	setp.ge.ftz.f32	%p242, %f877, %f103;
	mov.f32 	%f884, %f883;
	@%p242 bra 	BB14_163;

BB14_164:
	mov.b32 	 %r214, %f101;
	and.b32  	%r215, %r214, -2147483648;
	mov.b32 	 %r216, %f883;
	or.b32  	%r217, %r216, %r215;
	mov.b32 	 %f887, %r217;
	bra.uni 	BB14_166;

BB14_165:
	setp.gtu.ftz.f32	%p243, %f103, 0f7F800000;
	add.ftz.f32 	%f610, %f101, 0f3ECCCCCD;
	selp.f32	%f611, %f610, %f101, %p243;
	add.ftz.f32 	%f612, %f611, %f101;
	setp.leu.ftz.f32	%p244, %f123, 0f00000000;
	selp.f32	%f887, %f612, %f611, %p244;

BB14_166:
	ld.global.f32 	%f614, [global_t];
	cvt.ftz.f64.f32	%fd173, %f614;
	mul.f64 	%fd290, %fd173, 0d3FB0000000000000;
	abs.f64 	%fd174, %fd290;
	setp.neu.f64	%p245, %fd174, 0d7FF0000000000000;
	@%p245 bra 	BB14_168;

	mov.f64 	%fd175, 0d0000000000000000;
	mul.rn.f64 	%fd290, %fd290, %fd175;

BB14_168:
	add.u64 	%rd22, %SP, 12;
	mul.f64 	%fd176, %fd290, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r377, %fd176;
	cvta.to.local.u64 	%rd23, %rd22;
	st.local.u32 	[%rd23], %r377;
	cvt.rn.f64.s32	%fd177, %r377;
	neg.f64 	%fd178, %fd177;
	fma.rn.f64 	%fd180, %fd178, %fd125, %fd290;
	fma.rn.f64 	%fd182, %fd178, %fd127, %fd180;
	fma.rn.f64 	%fd291, %fd178, %fd129, %fd182;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r218}, %fd290;
	}
	and.b32  	%r219, %r218, 2145386496;
	setp.lt.u32	%p246, %r219, 1105199104;
	@%p246 bra 	BB14_170;

	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64	[param0+0], %fd290;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd291, [retval0+0];
	}
	// Callseq End 3
	ld.local.u32 	%r377, [%rd23];

BB14_170:
	and.b32  	%r220, %r377, 1;
	shl.b32 	%r221, %r220, 3;
	setp.eq.s32	%p247, %r220, 0;
	selp.f64	%fd184, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p247;
	mul.wide.u32 	%rd26, %r221, 8;
	add.s64 	%rd28, %rd26, %rd13;
	ld.const.f64 	%fd185, [%rd28+8];
	mul.rn.f64 	%fd46, %fd291, %fd291;
	fma.rn.f64 	%fd186, %fd184, %fd46, %fd185;
	ld.const.f64 	%fd187, [%rd28+16];
	fma.rn.f64 	%fd188, %fd186, %fd46, %fd187;
	ld.const.f64 	%fd189, [%rd28+24];
	fma.rn.f64 	%fd190, %fd188, %fd46, %fd189;
	ld.const.f64 	%fd191, [%rd28+32];
	fma.rn.f64 	%fd192, %fd190, %fd46, %fd191;
	ld.const.f64 	%fd193, [%rd28+40];
	fma.rn.f64 	%fd194, %fd192, %fd46, %fd193;
	ld.const.f64 	%fd195, [%rd28+48];
	fma.rn.f64 	%fd47, %fd194, %fd46, %fd195;
	fma.rn.f64 	%fd292, %fd47, %fd291, %fd291;
	@%p247 bra 	BB14_172;

	mov.f64 	%fd196, 0d3FF0000000000000;
	fma.rn.f64 	%fd292, %fd47, %fd46, %fd196;

BB14_172:
	and.b32  	%r222, %r377, 2;
	setp.eq.s32	%p248, %r222, 0;
	@%p248 bra 	BB14_174;

	mov.f64 	%fd197, 0d0000000000000000;
	mov.f64 	%fd198, 0dBFF0000000000000;
	fma.rn.f64 	%fd292, %fd292, %fd198, %fd197;

BB14_174:
	add.ftz.f32 	%f616, %f873, 0fBE4CCCCD;
	add.ftz.f32 	%f617, %f876, 0fBE4CCCCD;
	add.ftz.f32 	%f618, %f887, 0fBE4CCCCD;
	mul.f64 	%fd199, %fd292, 0d3FB99999A0000000;
	cvt.rn.ftz.f32.f64	%f619, %fd199;
	sub.ftz.f32 	%f620, %f616, %f619;
	sub.ftz.f32 	%f621, %f617, %f619;
	sub.ftz.f32 	%f622, %f618, %f619;
	abs.ftz.f32 	%f623, %f620;
	abs.ftz.f32 	%f624, %f621;
	abs.ftz.f32 	%f625, %f622;
	add.ftz.f32 	%f626, %f623, 0fBDCCCCCD;
	add.ftz.f32 	%f627, %f624, 0fBDCCCCCD;
	add.ftz.f32 	%f628, %f625, 0fBDCCCCCD;
	max.ftz.f32 	%f629, %f627, %f628;
	max.ftz.f32 	%f630, %f626, %f629;
	min.ftz.f32 	%f632, %f630, %f506;
	max.ftz.f32 	%f633, %f626, %f506;
	max.ftz.f32 	%f634, %f627, %f506;
	max.ftz.f32 	%f635, %f628, %f506;
	mul.ftz.f32 	%f636, %f634, %f634;
	fma.rn.ftz.f32 	%f637, %f633, %f633, %f636;
	fma.rn.ftz.f32 	%f638, %f635, %f635, %f637;
	sqrt.approx.ftz.f32 	%f639, %f638;
	add.ftz.f32 	%f230, %f632, %f639;
	add.ftz.f32 	%f231, %f841, 0f80000000;
	sub.ftz.f32 	%f232, %f842, %f80;
	mov.f32 	%f888, 0f3F800000;
	mov.u32 	%r378, 0;

BB14_175:
	mul.ftz.f32 	%f640, %f231, %f888;
	abs.ftz.f32 	%f235, %f640;
	setp.eq.ftz.f32	%p249, %f235, 0f7F800000;
	or.pred  	%p251, %p249, %p73;
	setp.ltu.ftz.f32	%p252, %f235, %f84;
	or.pred  	%p253, %p251, %p252;
	@%p253 bra 	BB14_178;

	mov.b32 	 %r224, %f235;
	and.b32  	%r225, %r224, 2139095040;
	or.b32  	%r228, %r8, %r225;
	mov.b32 	 %f641, %r228;
	setp.gt.ftz.f32	%p254, %f641, %f235;
	mul.ftz.f32 	%f642, %f641, 0f3F000000;
	selp.f32	%f889, %f642, %f641, %p254;
	setp.ltu.ftz.f32	%p255, %f889, %f84;
	@%p255 bra 	BB14_178;

BB14_177:
	mul.ftz.f32 	%f889, %f889, 0f3F000000;
	setp.ge.ftz.f32	%p256, %f889, %f84;
	@%p256 bra 	BB14_177;

BB14_178:
	mul.ftz.f32 	%f643, %f232, %f888;
	abs.ftz.f32 	%f239, %f643;
	setp.eq.ftz.f32	%p258, %f239, 0f7F800000;
	or.pred  	%p259, %p258, %p73;
	setp.ltu.ftz.f32	%p260, %f239, %f84;
	or.pred  	%p261, %p259, %p260;
	@%p261 bra 	BB14_181;

	mov.b32 	 %r229, %f239;
	and.b32  	%r230, %r229, 2139095040;
	or.b32  	%r233, %r230, %r8;
	mov.b32 	 %f644, %r233;
	setp.gt.ftz.f32	%p262, %f644, %f239;
	mul.ftz.f32 	%f645, %f644, 0f3F000000;
	selp.f32	%f890, %f645, %f644, %p262;
	setp.ltu.ftz.f32	%p263, %f890, %f84;
	@%p263 bra 	BB14_181;

BB14_180:
	mul.ftz.f32 	%f890, %f890, 0f3F000000;
	setp.ge.ftz.f32	%p264, %f890, %f84;
	@%p264 bra 	BB14_180;

BB14_181:
	mul.ftz.f32 	%f646, %f521, %f888;
	abs.ftz.f32 	%f243, %f646;
	setp.eq.ftz.f32	%p266, %f243, 0f7F800000;
	or.pred  	%p267, %p266, %p73;
	setp.ltu.ftz.f32	%p268, %f243, %f84;
	or.pred  	%p269, %p267, %p268;
	@%p269 bra 	BB14_184;

	mov.b32 	 %r234, %f243;
	and.b32  	%r235, %r234, 2139095040;
	or.b32  	%r238, %r235, %r8;
	mov.b32 	 %f647, %r238;
	setp.gt.ftz.f32	%p270, %f647, %f243;
	mul.ftz.f32 	%f648, %f647, 0f3F000000;
	selp.f32	%f891, %f648, %f647, %p270;
	setp.ltu.ftz.f32	%p271, %f891, %f84;
	@%p271 bra 	BB14_184;

BB14_183:
	mul.ftz.f32 	%f891, %f891, 0f3F000000;
	setp.ge.ftz.f32	%p272, %f891, %f84;
	@%p272 bra 	BB14_183;

BB14_184:
	mul.ftz.f32 	%f888, %f888, 0f40400000;
	add.s32 	%r378, %r378, 1;
	setp.lt.s32	%p273, %r378, 4;
	@%p273 bra 	BB14_175;

	add.ftz.f32 	%f248, %f232, 0f3E4CCCCD;
	add.ftz.f32 	%f249, %f231, 0f3E4CCCCD;
	abs.ftz.f32 	%f250, %f249;
	setp.eq.ftz.f32	%p275, %f250, 0f7F800000;
	or.pred  	%p2, %p275, %p98;
	@!%p2 bra 	BB14_187;
	bra.uni 	BB14_186;

BB14_186:
	mov.f32 	%f893, 0f7FFFFFFF;
	bra.uni 	BB14_193;

BB14_187:
	setp.ltu.ftz.f32	%p276, %f250, %f103;
	@%p276 bra 	BB14_192;

	mov.b32 	 %r239, %f103;
	and.b32  	%r240, %r239, 8388607;
	mov.b32 	 %r241, %f250;
	and.b32  	%r242, %r241, 2139095040;
	or.b32  	%r243, %r240, %r242;
	mov.b32 	 %f649, %r243;
	setp.gt.ftz.f32	%p277, %f649, %f250;
	mul.ftz.f32 	%f650, %f649, 0f3F000000;
	selp.f32	%f892, %f650, %f649, %p277;
	setp.ltu.ftz.f32	%p278, %f892, %f103;
	mov.f32 	%f949, %f250;
	@%p278 bra 	BB14_191;

	mov.f32 	%f950, %f250;

BB14_190:
	sub.ftz.f32 	%f651, %f950, %f892;
	setp.ltu.ftz.f32	%p279, %f950, %f892;
	selp.f32	%f254, %f950, %f651, %p279;
	mul.ftz.f32 	%f892, %f892, 0f3F000000;
	setp.ge.ftz.f32	%p280, %f892, %f103;
	mov.f32 	%f950, %f254;
	mov.f32 	%f949, %f254;
	@%p280 bra 	BB14_190;

BB14_191:
	mov.f32 	%f256, %f949;
	mov.b32 	 %r244, %f249;
	and.b32  	%r245, %r244, -2147483648;
	mov.b32 	 %r246, %f256;
	or.b32  	%r247, %r246, %r245;
	mov.b32 	 %f893, %r247;
	bra.uni 	BB14_193;

BB14_192:
	setp.gtu.ftz.f32	%p281, %f103, 0f7F800000;
	add.ftz.f32 	%f652, %f249, 0f3ECCCCCD;
	selp.f32	%f653, %f652, %f249, %p281;
	add.ftz.f32 	%f654, %f653, %f249;
	setp.leu.ftz.f32	%p282, %f250, 0f00000000;
	selp.f32	%f893, %f654, %f653, %p282;

BB14_193:
	abs.ftz.f32 	%f895, %f248;
	setp.eq.ftz.f32	%p283, %f895, 0f7F800000;
	or.pred  	%p285, %p283, %p98;
	@!%p285 bra 	BB14_195;
	bra.uni 	BB14_194;

BB14_194:
	mov.f32 	%f896, 0f7FFFFFFF;
	bra.uni 	BB14_200;

BB14_195:
	setp.ltu.ftz.f32	%p286, %f895, %f103;
	@%p286 bra 	BB14_199;

	mov.b32 	 %r248, %f103;
	and.b32  	%r249, %r248, 8388607;
	mov.b32 	 %r250, %f895;
	and.b32  	%r251, %r250, 2139095040;
	or.b32  	%r252, %r251, %r249;
	mov.b32 	 %f656, %r252;
	setp.gt.ftz.f32	%p287, %f656, %f895;
	mul.ftz.f32 	%f657, %f656, 0f3F000000;
	selp.f32	%f894, %f657, %f656, %p287;
	setp.ltu.ftz.f32	%p288, %f894, %f103;
	@%p288 bra 	BB14_198;

BB14_197:
	sub.ftz.f32 	%f658, %f895, %f894;
	setp.ltu.ftz.f32	%p289, %f895, %f894;
	selp.f32	%f895, %f895, %f658, %p289;
	mul.ftz.f32 	%f894, %f894, 0f3F000000;
	setp.ge.ftz.f32	%p290, %f894, %f103;
	@%p290 bra 	BB14_197;

BB14_198:
	mov.b32 	 %r253, %f248;
	and.b32  	%r254, %r253, -2147483648;
	mov.b32 	 %r255, %f895;
	or.b32  	%r256, %r255, %r254;
	mov.b32 	 %f896, %r256;
	bra.uni 	BB14_200;

BB14_199:
	setp.gtu.ftz.f32	%p291, %f103, 0f7F800000;
	add.ftz.f32 	%f659, %f248, 0f3ECCCCCD;
	selp.f32	%f660, %f659, %f248, %p291;
	add.ftz.f32 	%f661, %f660, %f248;
	setp.leu.ftz.f32	%p292, %f895, 0f00000000;
	selp.f32	%f896, %f661, %f660, %p292;

BB14_200:
	@!%p178 bra 	BB14_202;
	bra.uni 	BB14_201;

BB14_201:
	mov.f32 	%f907, 0f7FFFFFFF;
	bra.uni 	BB14_208;

BB14_202:
	setp.ltu.ftz.f32	%p296, %f172, %f103;
	@%p296 bra 	BB14_207;

	mov.b32 	 %r257, %f103;
	and.b32  	%r258, %r257, 8388607;
	mov.b32 	 %r259, %f172;
	and.b32  	%r260, %r259, 2139095040;
	or.b32  	%r261, %r260, %r258;
	mov.b32 	 %f663, %r261;
	setp.gt.ftz.f32	%p297, %f663, %f172;
	mul.ftz.f32 	%f664, %f663, 0f3F000000;
	selp.f32	%f897, %f664, %f663, %p297;
	setp.ltu.ftz.f32	%p298, %f897, %f103;
	mov.f32 	%f903, %f172;
	@%p298 bra 	BB14_206;

	mov.f32 	%f904, %f172;

BB14_205:
	sub.ftz.f32 	%f665, %f904, %f897;
	setp.ltu.ftz.f32	%p299, %f904, %f897;
	selp.f32	%f903, %f904, %f665, %p299;
	mul.ftz.f32 	%f897, %f897, 0f3F000000;
	setp.ge.ftz.f32	%p300, %f897, %f103;
	mov.f32 	%f904, %f903;
	@%p300 bra 	BB14_205;

BB14_206:
	mov.b32 	 %r262, %f540;
	and.b32  	%r263, %r262, -2147483648;
	mov.b32 	 %r264, %f903;
	or.b32  	%r265, %r264, %r263;
	mov.b32 	 %f907, %r265;
	bra.uni 	BB14_208;

BB14_207:
	setp.gtu.ftz.f32	%p301, %f103, 0f7F800000;
	add.ftz.f32 	%f670, %f540, 0f3ECCCCCD;
	selp.f32	%f671, %f670, %f540, %p301;
	add.ftz.f32 	%f672, %f671, %f540;
	setp.leu.ftz.f32	%p302, %f172, 0f00000000;
	selp.f32	%f907, %f672, %f671, %p302;

BB14_208:
	ld.global.f32 	%f674, [global_t];
	cvt.ftz.f64.f32	%fd200, %f674;
	mul.f64 	%fd293, %fd200, 0d3FB0000000000000;
	abs.f64 	%fd201, %fd293;
	setp.neu.f64	%p303, %fd201, 0d7FF0000000000000;
	@%p303 bra 	BB14_210;

	mov.f64 	%fd202, 0d0000000000000000;
	mul.rn.f64 	%fd293, %fd293, %fd202;

BB14_210:
	add.u64 	%rd29, %SP, 8;
	mul.f64 	%fd203, %fd293, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r379, %fd203;
	cvta.to.local.u64 	%rd30, %rd29;
	st.local.u32 	[%rd30], %r379;
	cvt.rn.f64.s32	%fd204, %r379;
	neg.f64 	%fd205, %fd204;
	fma.rn.f64 	%fd207, %fd205, %fd125, %fd293;
	fma.rn.f64 	%fd209, %fd205, %fd127, %fd207;
	fma.rn.f64 	%fd294, %fd205, %fd129, %fd209;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r266}, %fd293;
	}
	and.b32  	%r267, %r266, 2145386496;
	setp.lt.u32	%p304, %r267, 1105199104;
	@%p304 bra 	BB14_212;

	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64	[param0+0], %fd293;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd29;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd294, [retval0+0];
	}
	// Callseq End 4
	ld.local.u32 	%r379, [%rd30];

BB14_212:
	and.b32  	%r268, %r379, 1;
	shl.b32 	%r269, %r268, 3;
	setp.eq.s32	%p305, %r268, 0;
	selp.f64	%fd211, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p305;
	mul.wide.u32 	%rd33, %r269, 8;
	add.s64 	%rd35, %rd33, %rd13;
	ld.const.f64 	%fd212, [%rd35+8];
	mul.rn.f64 	%fd59, %fd294, %fd294;
	fma.rn.f64 	%fd213, %fd211, %fd59, %fd212;
	ld.const.f64 	%fd214, [%rd35+16];
	fma.rn.f64 	%fd215, %fd213, %fd59, %fd214;
	ld.const.f64 	%fd216, [%rd35+24];
	fma.rn.f64 	%fd217, %fd215, %fd59, %fd216;
	ld.const.f64 	%fd218, [%rd35+32];
	fma.rn.f64 	%fd219, %fd217, %fd59, %fd218;
	ld.const.f64 	%fd220, [%rd35+40];
	fma.rn.f64 	%fd221, %fd219, %fd59, %fd220;
	ld.const.f64 	%fd222, [%rd35+48];
	fma.rn.f64 	%fd60, %fd221, %fd59, %fd222;
	fma.rn.f64 	%fd295, %fd60, %fd294, %fd294;
	@%p305 bra 	BB14_214;

	mov.f64 	%fd223, 0d3FF0000000000000;
	fma.rn.f64 	%fd295, %fd60, %fd59, %fd223;

BB14_214:
	and.b32  	%r270, %r379, 2;
	setp.eq.s32	%p306, %r270, 0;
	@%p306 bra 	BB14_216;

	mov.f64 	%fd224, 0d0000000000000000;
	mov.f64 	%fd225, 0dBFF0000000000000;
	fma.rn.f64 	%fd295, %fd295, %fd225, %fd224;

BB14_216:
	add.ftz.f32 	%f676, %f893, 0fBE4CCCCD;
	add.ftz.f32 	%f677, %f896, 0fBE4CCCCD;
	add.ftz.f32 	%f678, %f907, 0fBE4CCCCD;
	mul.f64 	%fd226, %fd295, 0d3FB99999A0000000;
	cvt.rn.ftz.f32.f64	%f679, %fd226;
	sub.ftz.f32 	%f680, %f676, %f679;
	sub.ftz.f32 	%f681, %f677, %f679;
	sub.ftz.f32 	%f682, %f678, %f679;
	abs.ftz.f32 	%f683, %f680;
	abs.ftz.f32 	%f684, %f681;
	abs.ftz.f32 	%f685, %f682;
	add.ftz.f32 	%f686, %f683, 0fBDCCCCCD;
	add.ftz.f32 	%f687, %f684, 0fBDCCCCCD;
	add.ftz.f32 	%f688, %f685, 0fBDCCCCCD;
	max.ftz.f32 	%f689, %f687, %f688;
	max.ftz.f32 	%f690, %f686, %f689;
	min.ftz.f32 	%f692, %f690, %f506;
	max.ftz.f32 	%f693, %f686, %f506;
	max.ftz.f32 	%f694, %f687, %f506;
	max.ftz.f32 	%f695, %f688, %f506;
	mul.ftz.f32 	%f696, %f694, %f694;
	fma.rn.ftz.f32 	%f697, %f693, %f693, %f696;
	fma.rn.ftz.f32 	%f698, %f695, %f695, %f697;
	sqrt.approx.ftz.f32 	%f699, %f698;
	add.ftz.f32 	%f700, %f692, %f699;
	sub.ftz.f32 	%f279, %f230, %f700;
	add.ftz.f32 	%f280, %f843, %f80;
	mov.f32 	%f908, 0f3F800000;
	mov.u32 	%r380, 0;

BB14_217:
	mul.ftz.f32 	%f701, %f183, %f908;
	abs.ftz.f32 	%f282, %f701;
	setp.eq.ftz.f32	%p307, %f282, 0f7F800000;
	or.pred  	%p309, %p307, %p73;
	setp.ltu.ftz.f32	%p310, %f282, %f84;
	or.pred  	%p311, %p309, %p310;
	@%p311 bra 	BB14_220;

	mov.b32 	 %r272, %f282;
	and.b32  	%r273, %r272, 2139095040;
	or.b32  	%r276, %r8, %r273;
	mov.b32 	 %f702, %r276;
	setp.gt.ftz.f32	%p312, %f702, %f282;
	mul.ftz.f32 	%f703, %f702, 0f3F000000;
	selp.f32	%f909, %f703, %f702, %p312;
	setp.ltu.ftz.f32	%p313, %f909, %f84;
	@%p313 bra 	BB14_220;

BB14_219:
	mul.ftz.f32 	%f909, %f909, 0f3F000000;
	setp.ge.ftz.f32	%p314, %f909, %f84;
	@%p314 bra 	BB14_219;

BB14_220:
	mul.ftz.f32 	%f704, %f82, %f908;
	abs.ftz.f32 	%f286, %f704;
	setp.eq.ftz.f32	%p316, %f286, 0f7F800000;
	or.pred  	%p317, %p316, %p73;
	setp.ltu.ftz.f32	%p318, %f286, %f84;
	or.pred  	%p319, %p317, %p318;
	@%p319 bra 	BB14_223;

	mov.b32 	 %r277, %f286;
	and.b32  	%r278, %r277, 2139095040;
	or.b32  	%r281, %r278, %r8;
	mov.b32 	 %f705, %r281;
	setp.gt.ftz.f32	%p320, %f705, %f286;
	mul.ftz.f32 	%f706, %f705, 0f3F000000;
	selp.f32	%f910, %f706, %f705, %p320;
	setp.ltu.ftz.f32	%p321, %f910, %f84;
	@%p321 bra 	BB14_223;

BB14_222:
	mul.ftz.f32 	%f910, %f910, 0f3F000000;
	setp.ge.ftz.f32	%p322, %f910, %f84;
	@%p322 bra 	BB14_222;

BB14_223:
	mul.ftz.f32 	%f707, %f280, %f908;
	abs.ftz.f32 	%f290, %f707;
	setp.eq.ftz.f32	%p324, %f290, 0f7F800000;
	or.pred  	%p325, %p324, %p73;
	setp.ltu.ftz.f32	%p326, %f290, %f84;
	or.pred  	%p327, %p325, %p326;
	@%p327 bra 	BB14_226;

	mov.b32 	 %r282, %f290;
	and.b32  	%r283, %r282, 2139095040;
	or.b32  	%r286, %r283, %r8;
	mov.b32 	 %f708, %r286;
	setp.gt.ftz.f32	%p328, %f708, %f290;
	mul.ftz.f32 	%f709, %f708, 0f3F000000;
	selp.f32	%f911, %f709, %f708, %p328;
	setp.ltu.ftz.f32	%p329, %f911, %f84;
	@%p329 bra 	BB14_226;

BB14_225:
	mul.ftz.f32 	%f911, %f911, 0f3F000000;
	setp.ge.ftz.f32	%p330, %f911, %f84;
	@%p330 bra 	BB14_225;

BB14_226:
	mul.ftz.f32 	%f908, %f908, 0f40400000;
	add.s32 	%r380, %r380, 1;
	setp.lt.s32	%p331, %r380, 4;
	@%p331 bra 	BB14_217;

	add.ftz.f32 	%f295, %f280, 0f3E4CCCCD;
	@!%p217 bra 	BB14_229;
	bra.uni 	BB14_228;

BB14_228:
	mov.f32 	%f922, 0f7FFFFFFF;
	bra.uni 	BB14_235;

BB14_229:
	setp.ltu.ftz.f32	%p335, %f201, %f103;
	@%p335 bra 	BB14_234;

	mov.b32 	 %r287, %f103;
	and.b32  	%r288, %r287, 8388607;
	mov.b32 	 %r289, %f201;
	and.b32  	%r290, %r289, 2139095040;
	or.b32  	%r291, %r288, %r290;
	mov.b32 	 %f710, %r291;
	setp.gt.ftz.f32	%p336, %f710, %f201;
	mul.ftz.f32 	%f711, %f710, 0f3F000000;
	selp.f32	%f912, %f711, %f710, %p336;
	setp.ltu.ftz.f32	%p337, %f912, %f103;
	mov.f32 	%f918, %f201;
	@%p337 bra 	BB14_233;

	mov.f32 	%f919, %f201;

BB14_232:
	sub.ftz.f32 	%f712, %f919, %f912;
	setp.ltu.ftz.f32	%p338, %f919, %f912;
	selp.f32	%f918, %f919, %f712, %p338;
	mul.ftz.f32 	%f912, %f912, 0f3F000000;
	setp.ge.ftz.f32	%p339, %f912, %f103;
	mov.f32 	%f919, %f918;
	@%p339 bra 	BB14_232;

BB14_233:
	mov.b32 	 %r292, %f200;
	and.b32  	%r293, %r292, -2147483648;
	mov.b32 	 %r294, %f918;
	or.b32  	%r295, %r294, %r293;
	mov.b32 	 %f922, %r295;
	bra.uni 	BB14_235;

BB14_234:
	setp.gtu.ftz.f32	%p340, %f103, 0f7F800000;
	add.ftz.f32 	%f713, %f200, 0f3ECCCCCD;
	selp.f32	%f714, %f713, %f200, %p340;
	add.ftz.f32 	%f715, %f714, %f200;
	setp.leu.ftz.f32	%p341, %f201, 0f00000000;
	selp.f32	%f922, %f715, %f714, %p341;

BB14_235:
	@!%p109 bra 	BB14_237;
	bra.uni 	BB14_236;

BB14_236:
	mov.f32 	%f933, 0f7FFFFFFF;
	bra.uni 	BB14_243;

BB14_237:
	setp.ltu.ftz.f32	%p345, %f113, %f103;
	@%p345 bra 	BB14_242;

	mov.b32 	 %r296, %f103;
	and.b32  	%r297, %r296, 8388607;
	mov.b32 	 %r298, %f113;
	and.b32  	%r299, %r298, 2139095040;
	or.b32  	%r300, %r299, %r297;
	mov.b32 	 %f717, %r300;
	setp.gt.ftz.f32	%p346, %f717, %f113;
	mul.ftz.f32 	%f718, %f717, 0f3F000000;
	selp.f32	%f923, %f718, %f717, %p346;
	setp.ltu.ftz.f32	%p347, %f923, %f103;
	mov.f32 	%f929, %f113;
	@%p347 bra 	BB14_241;

	mov.f32 	%f930, %f113;

BB14_240:
	sub.ftz.f32 	%f719, %f930, %f923;
	setp.ltu.ftz.f32	%p348, %f930, %f923;
	selp.f32	%f929, %f930, %f719, %p348;
	mul.ftz.f32 	%f923, %f923, 0f3F000000;
	setp.ge.ftz.f32	%p349, %f923, %f103;
	mov.f32 	%f930, %f929;
	@%p349 bra 	BB14_240;

BB14_241:
	mov.b32 	 %r301, %f100;
	and.b32  	%r302, %r301, -2147483648;
	mov.b32 	 %r303, %f929;
	or.b32  	%r304, %r303, %r302;
	mov.b32 	 %f933, %r304;
	bra.uni 	BB14_243;

BB14_242:
	setp.gtu.ftz.f32	%p350, %f103, 0f7F800000;
	add.ftz.f32 	%f720, %f100, 0f3ECCCCCD;
	selp.f32	%f721, %f720, %f100, %p350;
	add.ftz.f32 	%f722, %f721, %f100;
	setp.leu.ftz.f32	%p351, %f113, 0f00000000;
	selp.f32	%f933, %f722, %f721, %p351;

BB14_243:
	abs.ftz.f32 	%f935, %f295;
	setp.eq.ftz.f32	%p352, %f935, 0f7F800000;
	or.pred  	%p354, %p352, %p98;
	@!%p354 bra 	BB14_245;
	bra.uni 	BB14_244;

BB14_244:
	mov.f32 	%f936, 0f7FFFFFFF;
	bra.uni 	BB14_250;

BB14_245:
	setp.ltu.ftz.f32	%p355, %f935, %f103;
	@%p355 bra 	BB14_249;

	mov.b32 	 %r305, %f103;
	and.b32  	%r306, %r305, 8388607;
	mov.b32 	 %r307, %f935;
	and.b32  	%r308, %r307, 2139095040;
	or.b32  	%r309, %r308, %r306;
	mov.b32 	 %f724, %r309;
	setp.gt.ftz.f32	%p356, %f724, %f935;
	mul.ftz.f32 	%f725, %f724, 0f3F000000;
	selp.f32	%f934, %f725, %f724, %p356;
	setp.ltu.ftz.f32	%p357, %f934, %f103;
	@%p357 bra 	BB14_248;

BB14_247:
	sub.ftz.f32 	%f726, %f935, %f934;
	setp.ltu.ftz.f32	%p358, %f935, %f934;
	selp.f32	%f935, %f935, %f726, %p358;
	mul.ftz.f32 	%f934, %f934, 0f3F000000;
	setp.ge.ftz.f32	%p359, %f934, %f103;
	@%p359 bra 	BB14_247;

BB14_248:
	mov.b32 	 %r310, %f295;
	and.b32  	%r311, %r310, -2147483648;
	mov.b32 	 %r312, %f935;
	or.b32  	%r313, %r312, %r311;
	mov.b32 	 %f936, %r313;
	bra.uni 	BB14_250;

BB14_249:
	setp.gtu.ftz.f32	%p360, %f103, 0f7F800000;
	add.ftz.f32 	%f727, %f295, 0f3ECCCCCD;
	selp.f32	%f728, %f727, %f295, %p360;
	add.ftz.f32 	%f729, %f728, %f295;
	setp.leu.ftz.f32	%p361, %f935, 0f00000000;
	selp.f32	%f936, %f729, %f728, %p361;

BB14_250:
	ld.global.f32 	%f731, [global_t];
	cvt.ftz.f64.f32	%fd227, %f731;
	mul.f64 	%fd296, %fd227, 0d3FB0000000000000;
	abs.f64 	%fd228, %fd296;
	setp.neu.f64	%p362, %fd228, 0d7FF0000000000000;
	@%p362 bra 	BB14_252;

	mov.f64 	%fd229, 0d0000000000000000;
	mul.rn.f64 	%fd296, %fd296, %fd229;

BB14_252:
	add.u64 	%rd36, %SP, 4;
	mul.f64 	%fd230, %fd296, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r381, %fd230;
	cvta.to.local.u64 	%rd37, %rd36;
	st.local.u32 	[%rd37], %r381;
	cvt.rn.f64.s32	%fd231, %r381;
	neg.f64 	%fd232, %fd231;
	fma.rn.f64 	%fd234, %fd232, %fd125, %fd296;
	fma.rn.f64 	%fd236, %fd232, %fd127, %fd234;
	fma.rn.f64 	%fd297, %fd232, %fd129, %fd236;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r314}, %fd296;
	}
	and.b32  	%r315, %r314, 2145386496;
	setp.lt.u32	%p363, %r315, 1105199104;
	@%p363 bra 	BB14_254;

	// Callseq Start 5
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64	[param0+0], %fd296;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd36;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd297, [retval0+0];
	}
	// Callseq End 5
	ld.local.u32 	%r381, [%rd37];

BB14_254:
	and.b32  	%r316, %r381, 1;
	shl.b32 	%r317, %r316, 3;
	setp.eq.s32	%p364, %r316, 0;
	selp.f64	%fd238, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p364;
	mul.wide.u32 	%rd40, %r317, 8;
	add.s64 	%rd42, %rd40, %rd13;
	ld.const.f64 	%fd239, [%rd42+8];
	mul.rn.f64 	%fd72, %fd297, %fd297;
	fma.rn.f64 	%fd240, %fd238, %fd72, %fd239;
	ld.const.f64 	%fd241, [%rd42+16];
	fma.rn.f64 	%fd242, %fd240, %fd72, %fd241;
	ld.const.f64 	%fd243, [%rd42+24];
	fma.rn.f64 	%fd244, %fd242, %fd72, %fd243;
	ld.const.f64 	%fd245, [%rd42+32];
	fma.rn.f64 	%fd246, %fd244, %fd72, %fd245;
	ld.const.f64 	%fd247, [%rd42+40];
	fma.rn.f64 	%fd248, %fd246, %fd72, %fd247;
	ld.const.f64 	%fd249, [%rd42+48];
	fma.rn.f64 	%fd73, %fd248, %fd72, %fd249;
	fma.rn.f64 	%fd298, %fd73, %fd297, %fd297;
	@%p364 bra 	BB14_256;

	mov.f64 	%fd250, 0d3FF0000000000000;
	fma.rn.f64 	%fd298, %fd73, %fd72, %fd250;

BB14_256:
	and.b32  	%r318, %r381, 2;
	setp.eq.s32	%p365, %r318, 0;
	@%p365 bra 	BB14_258;

	mov.f64 	%fd251, 0d0000000000000000;
	mov.f64 	%fd252, 0dBFF0000000000000;
	fma.rn.f64 	%fd298, %fd298, %fd252, %fd251;

BB14_258:
	add.ftz.f32 	%f733, %f922, 0fBE4CCCCD;
	add.ftz.f32 	%f734, %f933, 0fBE4CCCCD;
	add.ftz.f32 	%f735, %f936, 0fBE4CCCCD;
	mul.f64 	%fd253, %fd298, 0d3FB99999A0000000;
	cvt.rn.ftz.f32.f64	%f736, %fd253;
	sub.ftz.f32 	%f737, %f733, %f736;
	sub.ftz.f32 	%f738, %f734, %f736;
	sub.ftz.f32 	%f739, %f735, %f736;
	abs.ftz.f32 	%f740, %f737;
	abs.ftz.f32 	%f741, %f738;
	abs.ftz.f32 	%f742, %f739;
	add.ftz.f32 	%f743, %f740, 0fBDCCCCCD;
	add.ftz.f32 	%f744, %f741, 0fBDCCCCCD;
	add.ftz.f32 	%f745, %f742, 0fBDCCCCCD;
	max.ftz.f32 	%f746, %f744, %f745;
	max.ftz.f32 	%f747, %f743, %f746;
	min.ftz.f32 	%f749, %f747, %f506;
	max.ftz.f32 	%f750, %f743, %f506;
	max.ftz.f32 	%f751, %f744, %f506;
	max.ftz.f32 	%f752, %f745, %f506;
	mul.ftz.f32 	%f753, %f751, %f751;
	fma.rn.ftz.f32 	%f754, %f750, %f750, %f753;
	fma.rn.ftz.f32 	%f755, %f752, %f752, %f754;
	sqrt.approx.ftz.f32 	%f756, %f755;
	add.ftz.f32 	%f324, %f749, %f756;
	sub.ftz.f32 	%f325, %f843, %f80;
	mov.f32 	%f937, 0f3F800000;
	mov.u32 	%r382, 0;

BB14_259:
	mul.ftz.f32 	%f757, %f231, %f937;
	abs.ftz.f32 	%f327, %f757;
	setp.eq.ftz.f32	%p366, %f327, 0f7F800000;
	or.pred  	%p368, %p366, %p73;
	setp.ltu.ftz.f32	%p369, %f327, %f84;
	or.pred  	%p370, %p368, %p369;
	@%p370 bra 	BB14_262;

	mov.b32 	 %r320, %f327;
	and.b32  	%r321, %r320, 2139095040;
	or.b32  	%r324, %r8, %r321;
	mov.b32 	 %f758, %r324;
	setp.gt.ftz.f32	%p371, %f758, %f327;
	mul.ftz.f32 	%f759, %f758, 0f3F000000;
	selp.f32	%f938, %f759, %f758, %p371;
	setp.ltu.ftz.f32	%p372, %f938, %f84;
	@%p372 bra 	BB14_262;

BB14_261:
	mul.ftz.f32 	%f938, %f938, 0f3F000000;
	setp.ge.ftz.f32	%p373, %f938, %f84;
	@%p373 bra 	BB14_261;

BB14_262:
	mul.ftz.f32 	%f760, %f135, %f937;
	abs.ftz.f32 	%f331, %f760;
	setp.eq.ftz.f32	%p375, %f331, 0f7F800000;
	or.pred  	%p376, %p375, %p73;
	setp.ltu.ftz.f32	%p377, %f331, %f84;
	or.pred  	%p378, %p376, %p377;
	@%p378 bra 	BB14_265;

	mov.b32 	 %r325, %f331;
	and.b32  	%r326, %r325, 2139095040;
	or.b32  	%r329, %r326, %r8;
	mov.b32 	 %f761, %r329;
	setp.gt.ftz.f32	%p379, %f761, %f331;
	mul.ftz.f32 	%f762, %f761, 0f3F000000;
	selp.f32	%f939, %f762, %f761, %p379;
	setp.ltu.ftz.f32	%p380, %f939, %f84;
	@%p380 bra 	BB14_265;

BB14_264:
	mul.ftz.f32 	%f939, %f939, 0f3F000000;
	setp.ge.ftz.f32	%p381, %f939, %f84;
	@%p381 bra 	BB14_264;

BB14_265:
	mul.ftz.f32 	%f763, %f325, %f937;
	abs.ftz.f32 	%f335, %f763;
	setp.eq.ftz.f32	%p383, %f335, 0f7F800000;
	or.pred  	%p384, %p383, %p73;
	setp.ltu.ftz.f32	%p385, %f335, %f84;
	or.pred  	%p386, %p384, %p385;
	@%p386 bra 	BB14_268;

	mov.b32 	 %r330, %f335;
	and.b32  	%r331, %r330, 2139095040;
	or.b32  	%r334, %r331, %r8;
	mov.b32 	 %f764, %r334;
	setp.gt.ftz.f32	%p387, %f764, %f335;
	mul.ftz.f32 	%f765, %f764, 0f3F000000;
	selp.f32	%f940, %f765, %f764, %p387;
	setp.ltu.ftz.f32	%p388, %f940, %f84;
	@%p388 bra 	BB14_268;

BB14_267:
	mul.ftz.f32 	%f940, %f940, 0f3F000000;
	setp.ge.ftz.f32	%p389, %f940, %f84;
	@%p389 bra 	BB14_267;

BB14_268:
	mul.ftz.f32 	%f937, %f937, 0f40400000;
	add.s32 	%r382, %r382, 1;
	setp.lt.s32	%p390, %r382, 4;
	@%p390 bra 	BB14_259;

	add.ftz.f32 	%f340, %f325, 0f3E4CCCCD;
	@!%p2 bra 	BB14_271;
	bra.uni 	BB14_270;

BB14_270:
	mov.f32 	%f951, 0f7FFFFFFF;
	bra.uni 	BB14_277;

BB14_271:
	setp.ltu.ftz.f32	%p391, %f250, %f103;
	@%p391 bra 	BB14_276;

	mov.b32 	 %r335, %f103;
	and.b32  	%r336, %r335, 8388607;
	mov.b32 	 %r337, %f250;
	and.b32  	%r338, %r337, 2139095040;
	or.b32  	%r339, %r336, %r338;
	mov.b32 	 %f766, %r339;
	setp.gt.ftz.f32	%p392, %f766, %f250;
	mul.ftz.f32 	%f767, %f766, 0f3F000000;
	selp.f32	%f941, %f767, %f766, %p392;
	setp.ltu.ftz.f32	%p393, %f941, %f103;
	mov.f32 	%f947, %f250;
	@%p393 bra 	BB14_275;

	mov.f32 	%f948, %f250;

BB14_274:
	sub.ftz.f32 	%f768, %f948, %f941;
	setp.ltu.ftz.f32	%p394, %f948, %f941;
	selp.f32	%f947, %f948, %f768, %p394;
	mul.ftz.f32 	%f941, %f941, 0f3F000000;
	setp.ge.ftz.f32	%p395, %f941, %f103;
	mov.f32 	%f948, %f947;
	@%p395 bra 	BB14_274;

BB14_275:
	mov.b32 	 %r340, %f249;
	and.b32  	%r341, %r340, -2147483648;
	mov.b32 	 %r342, %f947;
	or.b32  	%r343, %r342, %r341;
	mov.b32 	 %f951, %r343;
	bra.uni 	BB14_277;

BB14_276:
	setp.gtu.ftz.f32	%p396, %f103, 0f7F800000;
	add.ftz.f32 	%f769, %f249, 0f3ECCCCCD;
	selp.f32	%f770, %f769, %f249, %p396;
	add.ftz.f32 	%f771, %f770, %f249;
	setp.leu.ftz.f32	%p397, %f250, 0f00000000;
	selp.f32	%f951, %f771, %f770, %p397;

BB14_277:
	@!%p168 bra 	BB14_279;
	bra.uni 	BB14_278;

BB14_278:
	mov.f32 	%f962, 0f7FFFFFFF;
	bra.uni 	BB14_285;

BB14_279:
	setp.ltu.ftz.f32	%p401, %f162, %f103;
	@%p401 bra 	BB14_284;

	mov.b32 	 %r344, %f103;
	and.b32  	%r345, %r344, 8388607;
	mov.b32 	 %r346, %f162;
	and.b32  	%r347, %r346, 2139095040;
	or.b32  	%r348, %r347, %r345;
	mov.b32 	 %f773, %r348;
	setp.gt.ftz.f32	%p402, %f773, %f162;
	mul.ftz.f32 	%f774, %f773, 0f3F000000;
	selp.f32	%f952, %f774, %f773, %p402;
	setp.ltu.ftz.f32	%p403, %f952, %f103;
	mov.f32 	%f958, %f162;
	@%p403 bra 	BB14_283;

	mov.f32 	%f959, %f162;

BB14_282:
	sub.ftz.f32 	%f775, %f959, %f952;
	setp.ltu.ftz.f32	%p404, %f959, %f952;
	selp.f32	%f958, %f959, %f775, %p404;
	mul.ftz.f32 	%f952, %f952, 0f3F000000;
	setp.ge.ftz.f32	%p405, %f952, %f103;
	mov.f32 	%f959, %f958;
	@%p405 bra 	BB14_282;

BB14_283:
	mov.b32 	 %r349, %f150;
	and.b32  	%r350, %r349, -2147483648;
	mov.b32 	 %r351, %f958;
	or.b32  	%r352, %r351, %r350;
	mov.b32 	 %f962, %r352;
	bra.uni 	BB14_285;

BB14_284:
	setp.gtu.ftz.f32	%p406, %f103, 0f7F800000;
	add.ftz.f32 	%f776, %f150, 0f3ECCCCCD;
	selp.f32	%f777, %f776, %f150, %p406;
	add.ftz.f32 	%f778, %f777, %f150;
	setp.leu.ftz.f32	%p407, %f162, 0f00000000;
	selp.f32	%f962, %f778, %f777, %p407;

BB14_285:
	abs.ftz.f32 	%f964, %f340;
	setp.eq.ftz.f32	%p408, %f964, 0f7F800000;
	or.pred  	%p410, %p408, %p98;
	@!%p410 bra 	BB14_287;
	bra.uni 	BB14_286;

BB14_286:
	mov.f32 	%f965, 0f7FFFFFFF;
	bra.uni 	BB14_292;

BB14_287:
	setp.ltu.ftz.f32	%p411, %f964, %f103;
	@%p411 bra 	BB14_291;

	mov.b32 	 %r353, %f103;
	and.b32  	%r354, %r353, 8388607;
	mov.b32 	 %r355, %f964;
	and.b32  	%r356, %r355, 2139095040;
	or.b32  	%r357, %r356, %r354;
	mov.b32 	 %f780, %r357;
	setp.gt.ftz.f32	%p412, %f780, %f964;
	mul.ftz.f32 	%f781, %f780, 0f3F000000;
	selp.f32	%f963, %f781, %f780, %p412;
	setp.ltu.ftz.f32	%p413, %f963, %f103;
	@%p413 bra 	BB14_290;

BB14_289:
	sub.ftz.f32 	%f782, %f964, %f963;
	setp.ltu.ftz.f32	%p414, %f964, %f963;
	selp.f32	%f964, %f964, %f782, %p414;
	mul.ftz.f32 	%f963, %f963, 0f3F000000;
	setp.ge.ftz.f32	%p415, %f963, %f103;
	@%p415 bra 	BB14_289;

BB14_290:
	mov.b32 	 %r358, %f340;
	and.b32  	%r359, %r358, -2147483648;
	mov.b32 	 %r360, %f964;
	or.b32  	%r361, %r360, %r359;
	mov.b32 	 %f965, %r361;
	bra.uni 	BB14_292;

BB14_291:
	setp.gtu.ftz.f32	%p416, %f103, 0f7F800000;
	add.ftz.f32 	%f783, %f340, 0f3ECCCCCD;
	selp.f32	%f784, %f783, %f340, %p416;
	add.ftz.f32 	%f785, %f784, %f340;
	setp.leu.ftz.f32	%p417, %f964, 0f00000000;
	selp.f32	%f965, %f785, %f784, %p417;

BB14_292:
	ld.global.f32 	%f787, [global_t];
	cvt.ftz.f64.f32	%fd254, %f787;
	mul.f64 	%fd299, %fd254, 0d3FB0000000000000;
	abs.f64 	%fd255, %fd299;
	setp.neu.f64	%p418, %fd255, 0d7FF0000000000000;
	@%p418 bra 	BB14_294;

	mov.f64 	%fd256, 0d0000000000000000;
	mul.rn.f64 	%fd299, %fd299, %fd256;

BB14_294:
	add.u64 	%rd43, %SP, 0;
	mul.f64 	%fd257, %fd299, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r383, %fd257;
	cvta.to.local.u64 	%rd44, %rd43;
	st.local.u32 	[%rd44], %r383;
	cvt.rn.f64.s32	%fd258, %r383;
	neg.f64 	%fd259, %fd258;
	fma.rn.f64 	%fd261, %fd259, %fd125, %fd299;
	fma.rn.f64 	%fd263, %fd259, %fd127, %fd261;
	fma.rn.f64 	%fd300, %fd259, %fd129, %fd263;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r362}, %fd299;
	}
	and.b32  	%r363, %r362, 2145386496;
	setp.lt.u32	%p419, %r363, 1105199104;
	@%p419 bra 	BB14_296;

	// Callseq Start 6
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64	[param0+0], %fd299;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd300, [retval0+0];
	}
	// Callseq End 6
	ld.local.u32 	%r383, [%rd44];

BB14_296:
	and.b32  	%r364, %r383, 1;
	shl.b32 	%r365, %r364, 3;
	setp.eq.s32	%p420, %r364, 0;
	selp.f64	%fd265, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p420;
	mul.wide.u32 	%rd47, %r365, 8;
	add.s64 	%rd49, %rd47, %rd13;
	ld.const.f64 	%fd266, [%rd49+8];
	mul.rn.f64 	%fd85, %fd300, %fd300;
	fma.rn.f64 	%fd267, %fd265, %fd85, %fd266;
	ld.const.f64 	%fd268, [%rd49+16];
	fma.rn.f64 	%fd269, %fd267, %fd85, %fd268;
	ld.const.f64 	%fd270, [%rd49+24];
	fma.rn.f64 	%fd271, %fd269, %fd85, %fd270;
	ld.const.f64 	%fd272, [%rd49+32];
	fma.rn.f64 	%fd273, %fd271, %fd85, %fd272;
	ld.const.f64 	%fd274, [%rd49+40];
	fma.rn.f64 	%fd275, %fd273, %fd85, %fd274;
	ld.const.f64 	%fd276, [%rd49+48];
	fma.rn.f64 	%fd86, %fd275, %fd85, %fd276;
	fma.rn.f64 	%fd301, %fd86, %fd300, %fd300;
	@%p420 bra 	BB14_298;

	mov.f64 	%fd277, 0d3FF0000000000000;
	fma.rn.f64 	%fd301, %fd86, %fd85, %fd277;

BB14_298:
	and.b32  	%r366, %r383, 2;
	setp.eq.s32	%p421, %r366, 0;
	@%p421 bra 	BB14_300;

	mov.f64 	%fd278, 0d0000000000000000;
	mov.f64 	%fd279, 0dBFF0000000000000;
	fma.rn.f64 	%fd301, %fd301, %fd279, %fd278;

BB14_300:
	add.ftz.f32 	%f788, %f951, 0fBE4CCCCD;
	add.ftz.f32 	%f789, %f962, 0fBE4CCCCD;
	add.ftz.f32 	%f790, %f965, 0fBE4CCCCD;
	mul.f64 	%fd280, %fd301, 0d3FB99999A0000000;
	cvt.rn.ftz.f32.f64	%f791, %fd280;
	sub.ftz.f32 	%f792, %f788, %f791;
	sub.ftz.f32 	%f793, %f789, %f791;
	sub.ftz.f32 	%f794, %f790, %f791;
	abs.ftz.f32 	%f795, %f792;
	abs.ftz.f32 	%f796, %f793;
	abs.ftz.f32 	%f797, %f794;
	add.ftz.f32 	%f798, %f795, 0fBDCCCCCD;
	add.ftz.f32 	%f799, %f796, 0fBDCCCCCD;
	add.ftz.f32 	%f800, %f797, 0fBDCCCCCD;
	max.ftz.f32 	%f801, %f799, %f800;
	max.ftz.f32 	%f802, %f798, %f801;
	min.ftz.f32 	%f804, %f802, %f506;
	max.ftz.f32 	%f805, %f798, %f506;
	max.ftz.f32 	%f806, %f799, %f506;
	max.ftz.f32 	%f807, %f800, %f506;
	mul.ftz.f32 	%f808, %f806, %f806;
	fma.rn.ftz.f32 	%f809, %f805, %f805, %f808;
	fma.rn.ftz.f32 	%f810, %f807, %f807, %f809;
	sqrt.approx.ftz.f32 	%f811, %f810;
	add.ftz.f32 	%f812, %f804, %f811;
	sub.ftz.f32 	%f813, %f324, %f812;
	mul.ftz.f32 	%f814, %f279, %f279;
	fma.rn.ftz.f32 	%f815, %f182, %f182, %f814;
	fma.rn.ftz.f32 	%f816, %f813, %f813, %f815;
	sqrt.approx.ftz.f32 	%f817, %f816;
	rcp.approx.ftz.f32 	%f818, %f817;
	mul.ftz.f32 	%f819, %f813, %f818;
	mul.ftz.f32 	%f820, %f279, %f818;
	mul.ftz.f32 	%f821, %f182, %f818;
	st.global.v2.f32 	[normal], {%f821, %f820};
	st.global.f32 	[normal+8], %f819;
	mov.u32 	%r368, 0;
	// inline asm
	call (%r367), _rt_report_intersection, (%r368);
	// inline asm

BB14_301:
	ret;
}

.visible .entry _Z6boundsiPf(
	.param .u32 _Z6boundsiPf_param_0,
	.param .u64 _Z6boundsiPf_param_1
)
{
	.reg .s32 	%r<3>;
	.reg .s64 	%rd<3>;


	ld.param.u64 	%rd1, [_Z6boundsiPf_param_1];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, -1078774989;
	st.global.u32 	[%rd2], %r1;
	st.global.u32 	[%rd2+8], %r1;
	st.global.u32 	[%rd2+4], %r1;
	mov.u32 	%r2, 1068708659;
	st.global.u32 	[%rd2+12], %r2;
	st.global.u32 	[%rd2+16], %r2;
	st.global.u32 	[%rd2+20], %r2;
	ret;
}

.visible .entry _Z17julia_ch_radiancev(

)
{
	.local .align 4 .b8 	__local_depot16[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<62>;
	.reg .s32 	%r<61>;
	.reg .f32 	%f<256>;
	.reg .s64 	%rd<11>;
	.reg .f64 	%fd<44>;


	mov.u64 	%SPL, __local_depot16;
	cvta.local.u64 	%SP, %SPL;
	mov.u64 	%rd2, ray;
	add.s64 	%rd3, %rd2, 8;
	ldu.global.v2.f32 	{%f74, %f75}, [%rd3];
	ldu.global.f32 	%f76, [isect_t];
	add.s64 	%rd4, %rd2, 16;
	ldu.global.v2.f32 	{%f77, %f78}, [%rd4];
	ldu.global.v2.f32 	{%f79, %f80}, [ray];
	fma.rn.ftz.f32 	%f1, %f75, %f76, %f79;
	fma.rn.ftz.f32 	%f2, %f77, %f76, %f80;
	fma.rn.ftz.f32 	%f3, %f78, %f76, %f74;
	mov.f32 	%f87, 0f40000000;
	abs.ftz.f32 	%f4, %f87;
	mov.f32 	%f88, 0f3ECCCCCD;
	abs.ftz.f32 	%f5, %f88;
	mov.f32 	%f73, 0f3F800000;
	mov.f32 	%f237, 0f40E00000;
	mov.u32 	%r8, 0;
	mov.u32 	%r59, %r8;
	mov.f32 	%f240, %f73;

BB16_1:
	cvt.rn.f32.s32	%f90, %r59;
	mul.ftz.f32 	%f8, %f90, 0f3D4CCCCD;
	ld.global.v2.f32 	{%f91, %f92}, [normal];
	ld.global.f32 	%f93, [normal+8];
	fma.rn.ftz.f32 	%f9, %f91, %f8, %f1;
	fma.rn.ftz.f32 	%f10, %f92, %f8, %f2;
	fma.rn.ftz.f32 	%f11, %f93, %f8, %f3;
	mov.u32 	%r58, %r8;
	mov.f32 	%f239, %f73;

BB16_2:
	mov.f32 	%f12, %f239;
	mov.u32 	%r2, %r58;
	mul.ftz.f32 	%f96, %f9, %f12;
	abs.ftz.f32 	%f13, %f96;
	setp.eq.ftz.f32	%p1, %f13, 0f7F800000;
	setp.eq.ftz.f32	%p2, %f4, 0f00000000;
	or.pred  	%p3, %p1, %p2;
	setp.ltu.ftz.f32	%p4, %f13, %f4;
	or.pred  	%p5, %p3, %p4;
	@%p5 bra 	BB16_5;

	mov.b32 	 %r10, %f13;
	and.b32  	%r11, %r10, 2139095040;
	mov.b32 	 %r12, %f4;
	and.b32  	%r13, %r12, 8388607;
	or.b32  	%r14, %r13, %r11;
	mov.b32 	 %f97, %r14;
	setp.gt.ftz.f32	%p6, %f97, %f13;
	mul.ftz.f32 	%f98, %f97, 0f3F000000;
	selp.f32	%f241, %f98, %f97, %p6;
	setp.ltu.ftz.f32	%p7, %f241, %f4;
	@%p7 bra 	BB16_5;

BB16_4:
	mul.ftz.f32 	%f241, %f241, 0f3F000000;
	setp.ge.ftz.f32	%p8, %f241, %f4;
	@%p8 bra 	BB16_4;

BB16_5:
	mul.ftz.f32 	%f99, %f10, %f12;
	abs.ftz.f32 	%f17, %f99;
	setp.eq.ftz.f32	%p10, %f17, 0f7F800000;
	or.pred  	%p11, %p10, %p2;
	setp.ltu.ftz.f32	%p12, %f17, %f4;
	or.pred  	%p13, %p11, %p12;
	@%p13 bra 	BB16_8;

	mov.b32 	 %r15, %f17;
	and.b32  	%r16, %r15, 2139095040;
	mov.b32 	 %r17, %f4;
	and.b32  	%r18, %r17, 8388607;
	or.b32  	%r19, %r16, %r18;
	mov.b32 	 %f100, %r19;
	setp.gt.ftz.f32	%p14, %f100, %f17;
	mul.ftz.f32 	%f101, %f100, 0f3F000000;
	selp.f32	%f242, %f101, %f100, %p14;
	setp.ltu.ftz.f32	%p15, %f242, %f4;
	@%p15 bra 	BB16_8;

BB16_7:
	mul.ftz.f32 	%f242, %f242, 0f3F000000;
	setp.ge.ftz.f32	%p16, %f242, %f4;
	@%p16 bra 	BB16_7;

BB16_8:
	mul.ftz.f32 	%f102, %f11, %f12;
	abs.ftz.f32 	%f21, %f102;
	setp.eq.ftz.f32	%p18, %f21, 0f7F800000;
	or.pred  	%p19, %p18, %p2;
	setp.ltu.ftz.f32	%p20, %f21, %f4;
	or.pred  	%p21, %p19, %p20;
	@%p21 bra 	BB16_11;

	mov.b32 	 %r20, %f21;
	and.b32  	%r21, %r20, 2139095040;
	mov.b32 	 %r22, %f4;
	and.b32  	%r23, %r22, 8388607;
	or.b32  	%r24, %r21, %r23;
	mov.b32 	 %f103, %r24;
	setp.gt.ftz.f32	%p22, %f103, %f21;
	mul.ftz.f32 	%f104, %f103, 0f3F000000;
	selp.f32	%f243, %f104, %f103, %p22;
	setp.ltu.ftz.f32	%p23, %f243, %f4;
	@%p23 bra 	BB16_11;

BB16_10:
	mul.ftz.f32 	%f243, %f243, 0f3F000000;
	setp.ge.ftz.f32	%p24, %f243, %f4;
	@%p24 bra 	BB16_10;

BB16_11:
	mul.ftz.f32 	%f25, %f12, 0f40400000;
	add.s32 	%r3, %r2, 1;
	setp.lt.s32	%p25, %r3, 4;
	add.u64 	%rd5, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd5;
	mov.u32 	%r58, %r3;
	mov.f32 	%f239, %f25;
	@%p25 bra 	BB16_2;

	setp.eq.ftz.f32	%p26, %f5, 0f00000000;
	add.ftz.f32 	%f26, %f10, 0f3E4CCCCD;
	add.ftz.f32 	%f27, %f11, 0f3E4CCCCD;
	add.ftz.f32 	%f28, %f9, 0f3E4CCCCD;
	abs.ftz.f32 	%f245, %f28;
	setp.eq.ftz.f32	%p27, %f245, 0f7F800000;
	or.pred  	%p28, %p27, %p26;
	@!%p28 bra 	BB16_14;
	bra.uni 	BB16_13;

BB16_13:
	mov.f32 	%f246, 0f7FFFFFFF;
	bra.uni 	BB16_19;

BB16_14:
	setp.ltu.ftz.f32	%p29, %f245, %f5;
	@%p29 bra 	BB16_18;

	mov.b32 	 %r25, %f245;
	and.b32  	%r26, %r25, 2139095040;
	mov.b32 	 %r27, %f5;
	and.b32  	%r28, %r27, 8388607;
	or.b32  	%r29, %r28, %r26;
	mov.b32 	 %f105, %r29;
	setp.gt.ftz.f32	%p30, %f105, %f245;
	mul.ftz.f32 	%f106, %f105, 0f3F000000;
	selp.f32	%f244, %f106, %f105, %p30;
	setp.ltu.ftz.f32	%p31, %f244, %f5;
	@%p31 bra 	BB16_17;

BB16_16:
	sub.ftz.f32 	%f107, %f245, %f244;
	setp.ltu.ftz.f32	%p32, %f245, %f244;
	selp.f32	%f245, %f245, %f107, %p32;
	mul.ftz.f32 	%f244, %f244, 0f3F000000;
	setp.ge.ftz.f32	%p33, %f244, %f5;
	@%p33 bra 	BB16_16;

BB16_17:
	mov.b32 	 %r30, %f28;
	and.b32  	%r31, %r30, -2147483648;
	mov.b32 	 %r32, %f245;
	or.b32  	%r33, %r32, %r31;
	mov.b32 	 %f246, %r33;
	bra.uni 	BB16_19;

BB16_18:
	setp.gtu.ftz.f32	%p34, %f5, 0f7F800000;
	add.ftz.f32 	%f108, %f28, 0f3ECCCCCD;
	selp.f32	%f109, %f108, %f28, %p34;
	add.ftz.f32 	%f110, %f109, %f28;
	setp.leu.ftz.f32	%p35, %f245, 0f00000000;
	selp.f32	%f246, %f110, %f109, %p35;

BB16_19:
	abs.ftz.f32 	%f248, %f26;
	setp.eq.ftz.f32	%p36, %f248, 0f7F800000;
	or.pred  	%p38, %p36, %p26;
	@!%p38 bra 	BB16_21;
	bra.uni 	BB16_20;

BB16_20:
	mov.f32 	%f249, 0f7FFFFFFF;
	bra.uni 	BB16_26;

BB16_21:
	setp.ltu.ftz.f32	%p39, %f248, %f5;
	@%p39 bra 	BB16_25;

	mov.b32 	 %r34, %f248;
	and.b32  	%r35, %r34, 2139095040;
	mov.b32 	 %r36, %f5;
	and.b32  	%r37, %r36, 8388607;
	or.b32  	%r38, %r35, %r37;
	mov.b32 	 %f112, %r38;
	setp.gt.ftz.f32	%p40, %f112, %f248;
	mul.ftz.f32 	%f113, %f112, 0f3F000000;
	selp.f32	%f247, %f113, %f112, %p40;
	setp.ltu.ftz.f32	%p41, %f247, %f5;
	@%p41 bra 	BB16_24;

BB16_23:
	sub.ftz.f32 	%f114, %f248, %f247;
	setp.ltu.ftz.f32	%p42, %f248, %f247;
	selp.f32	%f248, %f248, %f114, %p42;
	mul.ftz.f32 	%f247, %f247, 0f3F000000;
	setp.ge.ftz.f32	%p43, %f247, %f5;
	@%p43 bra 	BB16_23;

BB16_24:
	mov.b32 	 %r39, %f26;
	and.b32  	%r40, %r39, -2147483648;
	mov.b32 	 %r41, %f248;
	or.b32  	%r42, %r41, %r40;
	mov.b32 	 %f249, %r42;
	bra.uni 	BB16_26;

BB16_25:
	setp.gtu.ftz.f32	%p44, %f5, 0f7F800000;
	add.ftz.f32 	%f115, %f26, 0f3ECCCCCD;
	selp.f32	%f116, %f115, %f26, %p44;
	add.ftz.f32 	%f117, %f116, %f26;
	setp.leu.ftz.f32	%p45, %f248, 0f00000000;
	selp.f32	%f249, %f117, %f116, %p45;

BB16_26:
	abs.ftz.f32 	%f251, %f27;
	setp.eq.ftz.f32	%p46, %f251, 0f7F800000;
	or.pred  	%p48, %p46, %p26;
	@!%p48 bra 	BB16_28;
	bra.uni 	BB16_27;

BB16_27:
	mov.f32 	%f252, 0f7FFFFFFF;
	bra.uni 	BB16_33;

BB16_28:
	setp.ltu.ftz.f32	%p49, %f251, %f5;
	@%p49 bra 	BB16_32;

	mov.b32 	 %r43, %f251;
	and.b32  	%r44, %r43, 2139095040;
	mov.b32 	 %r45, %f5;
	and.b32  	%r46, %r45, 8388607;
	or.b32  	%r47, %r44, %r46;
	mov.b32 	 %f119, %r47;
	setp.gt.ftz.f32	%p50, %f119, %f251;
	mul.ftz.f32 	%f120, %f119, 0f3F000000;
	selp.f32	%f250, %f120, %f119, %p50;
	setp.ltu.ftz.f32	%p51, %f250, %f5;
	@%p51 bra 	BB16_31;

BB16_30:
	sub.ftz.f32 	%f121, %f251, %f250;
	setp.ltu.ftz.f32	%p52, %f251, %f250;
	selp.f32	%f251, %f251, %f121, %p52;
	mul.ftz.f32 	%f250, %f250, 0f3F000000;
	setp.ge.ftz.f32	%p53, %f250, %f5;
	@%p53 bra 	BB16_30;

BB16_31:
	mov.b32 	 %r48, %f27;
	and.b32  	%r49, %r48, -2147483648;
	mov.b32 	 %r50, %f251;
	or.b32  	%r51, %r50, %r49;
	mov.b32 	 %f252, %r51;
	bra.uni 	BB16_33;

BB16_32:
	setp.gtu.ftz.f32	%p54, %f5, 0f7F800000;
	add.ftz.f32 	%f122, %f27, 0f3ECCCCCD;
	selp.f32	%f123, %f122, %f27, %p54;
	add.ftz.f32 	%f124, %f123, %f27;
	setp.leu.ftz.f32	%p55, %f251, 0f00000000;
	selp.f32	%f252, %f124, %f123, %p55;

BB16_33:
	ld.global.f32 	%f126, [global_t];
	cvt.ftz.f64.f32	%fd14, %f126;
	mul.f64 	%fd41, %fd14, 0d3FB0000000000000;
	abs.f64 	%fd15, %fd41;
	setp.neu.f64	%p56, %fd15, 0d7FF0000000000000;
	@%p56 bra 	BB16_35;

	mov.f64 	%fd16, 0d0000000000000000;
	mul.rn.f64 	%fd41, %fd41, %fd16;

BB16_35:
	mul.f64 	%fd17, %fd41, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r60, %fd17;
	st.local.u32 	[%rd1], %r60;
	cvt.rn.f64.s32	%fd18, %r60;
	neg.f64 	%fd19, %fd18;
	mov.f64 	%fd20, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd21, %fd19, %fd20, %fd41;
	mov.f64 	%fd22, 0d3C91A62633145C00;
	fma.rn.f64 	%fd23, %fd19, %fd22, %fd21;
	mov.f64 	%fd24, 0d397B839A252049C0;
	fma.rn.f64 	%fd42, %fd19, %fd24, %fd23;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r52}, %fd41;
	}
	and.b32  	%r53, %r52, 2145386496;
	setp.lt.u32	%p57, %r53, 1105199104;
	@%p57 bra 	BB16_37;

	// Callseq Start 7
	{
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64	[param0+0], %fd41;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd5;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd42, [retval0+0];
	}
	// Callseq End 7
	ld.local.u32 	%r60, [%rd1];

BB16_37:
	and.b32  	%r54, %r60, 1;
	shl.b32 	%r55, %r54, 3;
	setp.eq.s32	%p58, %r54, 0;
	selp.f64	%fd25, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p58;
	mul.wide.u32 	%rd8, %r55, 8;
	mov.u64 	%rd9, __cudart_sin_cos_coeffs;
	add.s64 	%rd10, %rd8, %rd9;
	ld.const.f64 	%fd26, [%rd10+8];
	mul.rn.f64 	%fd7, %fd42, %fd42;
	fma.rn.f64 	%fd27, %fd25, %fd7, %fd26;
	ld.const.f64 	%fd28, [%rd10+16];
	fma.rn.f64 	%fd29, %fd27, %fd7, %fd28;
	ld.const.f64 	%fd30, [%rd10+24];
	fma.rn.f64 	%fd31, %fd29, %fd7, %fd30;
	ld.const.f64 	%fd32, [%rd10+32];
	fma.rn.f64 	%fd33, %fd31, %fd7, %fd32;
	ld.const.f64 	%fd34, [%rd10+40];
	fma.rn.f64 	%fd35, %fd33, %fd7, %fd34;
	ld.const.f64 	%fd36, [%rd10+48];
	fma.rn.f64 	%fd8, %fd35, %fd7, %fd36;
	fma.rn.f64 	%fd43, %fd8, %fd42, %fd42;
	@%p58 bra 	BB16_39;

	mov.f64 	%fd37, 0d3FF0000000000000;
	fma.rn.f64 	%fd43, %fd8, %fd7, %fd37;

BB16_39:
	and.b32  	%r56, %r60, 2;
	setp.eq.s32	%p59, %r56, 0;
	@%p59 bra 	BB16_41;

	mov.f64 	%fd38, 0d0000000000000000;
	mov.f64 	%fd39, 0dBFF0000000000000;
	fma.rn.f64 	%fd43, %fd43, %fd39, %fd38;

BB16_41:
	add.ftz.f32 	%f127, %f246, 0fBE4CCCCD;
	add.ftz.f32 	%f128, %f249, 0fBE4CCCCD;
	add.ftz.f32 	%f129, %f252, 0fBE4CCCCD;
	mul.f64 	%fd40, %fd43, 0d3FB99999A0000000;
	cvt.rn.ftz.f32.f64	%f130, %fd40;
	sub.ftz.f32 	%f131, %f127, %f130;
	sub.ftz.f32 	%f132, %f128, %f130;
	sub.ftz.f32 	%f133, %f129, %f130;
	abs.ftz.f32 	%f134, %f131;
	abs.ftz.f32 	%f135, %f132;
	abs.ftz.f32 	%f136, %f133;
	add.ftz.f32 	%f137, %f134, 0fBDCCCCCD;
	add.ftz.f32 	%f138, %f135, 0fBDCCCCCD;
	add.ftz.f32 	%f139, %f136, 0fBDCCCCCD;
	max.ftz.f32 	%f140, %f138, %f139;
	max.ftz.f32 	%f141, %f137, %f140;
	mov.f32 	%f142, 0f00000000;
	min.ftz.f32 	%f143, %f141, %f142;
	max.ftz.f32 	%f144, %f137, %f142;
	max.ftz.f32 	%f145, %f138, %f142;
	max.ftz.f32 	%f146, %f139, %f142;
	mul.ftz.f32 	%f147, %f145, %f145;
	fma.rn.ftz.f32 	%f148, %f144, %f144, %f147;
	fma.rn.ftz.f32 	%f149, %f146, %f146, %f148;
	sqrt.approx.ftz.f32 	%f150, %f149;
	add.ftz.f32 	%f151, %f143, %f150;
	sub.ftz.f32 	%f152, %f8, %f151;
	mul.ftz.f32 	%f153, %f237, %f152;
	sub.ftz.f32 	%f240, %f240, %f153;
	mul.ftz.f32 	%f237, %f237, 0f3F000000;
	add.s32 	%r59, %r59, 1;
	setp.lt.s32	%p60, %r59, 4;
	@%p60 bra 	BB16_1;

	add.ftz.f32 	%f154, %f240, 0f3E99999A;
	mul.ftz.f32 	%f155, %f154, %f154;
	mov.f32 	%f156, 0f3F800000;
	min.ftz.f32 	%f157, %f155, %f156;
	mov.f32 	%f158, 0f3E4CCCCD;
	max.ftz.f32 	%f61, %f158, %f157;
	ld.global.v2.f32 	{%f159, %f160}, [normal];
	ld.global.f32 	%f161, [normal+8];
	fma.rn.ftz.f32 	%f163, %f160, 0f3F000000, 0f3F000000;
	fma.rn.ftz.f32 	%f164, %f161, 0f3F000000, 0f3F000000;
	abs.ftz.f32 	%f166, %f159;
	fma.rn.ftz.f32 	%f167, %f166, 0f3F000000, 0f3F000000;
	mov.f32 	%f168, 0f3DCCCCCD;
	max.ftz.f32 	%f169, %f167, %f168;
	add.ftz.f32 	%f170, %f169, 0f3DCCCCCD;
	mul.ftz.f32 	%f171, %f169, 0f3F4CCCCD;
	mov.f32 	%f172, 0f3F4CCCCD;
	mul.ftz.f32 	%f173, %f164, 0f3DCCCCCD;
	mul.ftz.f32 	%f174, %f171, 0f3E4CCCCD;
	fma.rn.ftz.f32 	%f175, %f163, %f170, %f174;
	add.ftz.f32 	%f176, %f171, 0f3F19999A;
	max.ftz.f32 	%f177, %f61, %f172;
	ld.global.f32 	%f178, [particle];
	sub.ftz.f32 	%f179, %f1, %f178;
	ld.global.f32 	%f180, [particle+4];
	sub.ftz.f32 	%f181, %f2, %f180;
	ld.global.f32 	%f182, [particle+8];
	sub.ftz.f32 	%f183, %f3, %f182;
	mul.ftz.f32 	%f184, %f181, %f181;
	fma.rn.ftz.f32 	%f185, %f179, %f179, %f184;
	fma.rn.ftz.f32 	%f186, %f183, %f183, %f185;
	sqrt.approx.ftz.f32 	%f187, %f186;
	add.ftz.f32 	%f188, %f187, 0f80000000;
	div.approx.ftz.f32 	%f189, %f188, %f156;
	min.ftz.f32 	%f190, %f189, %f156;
	max.ftz.f32 	%f192, %f142, %f190;
	mul.ftz.f32 	%f193, %f192, %f192;
	fma.rn.ftz.f32 	%f194, %f192, 0fC0000000, 0f40400000;
	mov.f32 	%f195, 0f40400000;
	mul.ftz.f32 	%f196, %f193, %f194;
	sub.ftz.f32 	%f197, %f156, %f196;
	mul.ftz.f32 	%f198, %f197, 0f3ECCCCCD;
	fma.rn.ftz.f32 	%f253, %f176, %f177, %f198;
	fma.rn.ftz.f32 	%f254, %f175, %f61, %f198;
	fma.rn.ftz.f32 	%f255, %f173, %f61, %f198;
	ld.global.f32 	%f199, [ray+12];
	sub.ftz.f32 	%f200, %f156, %f199;
	ld.global.v2.f32 	{%f201, %f202}, [ray+16];
	sub.ftz.f32 	%f204, %f195, %f201;
	sub.ftz.f32 	%f206, %f156, %f202;
	mul.ftz.f32 	%f207, %f204, %f204;
	fma.rn.ftz.f32 	%f208, %f200, %f200, %f207;
	fma.rn.ftz.f32 	%f209, %f206, %f206, %f208;
	sqrt.approx.ftz.f32 	%f210, %f209;
	rcp.approx.ftz.f32 	%f211, %f210;
	mul.ftz.f32 	%f212, %f200, %f211;
	mul.ftz.f32 	%f213, %f204, %f211;
	mul.ftz.f32 	%f214, %f206, %f211;
	mul.ftz.f32 	%f215, %f160, %f213;
	fma.rn.ftz.f32 	%f216, %f159, %f212, %f215;
	fma.rn.ftz.f32 	%f65, %f161, %f214, %f216;
	setp.leu.ftz.f32	%p61, %f65, 0f00000000;
	@%p61 bra 	BB16_44;

	mul.ftz.f32 	%f217, %f61, 0f3F19999A;
	lg2.approx.ftz.f32 	%f218, %f65;
	mul.ftz.f32 	%f219, %f218, 0f41A00000;
	ex2.approx.ftz.f32 	%f220, %f219;
	fma.rn.ftz.f32 	%f253, %f217, %f220, %f253;
	fma.rn.ftz.f32 	%f254, %f217, %f220, %f254;
	fma.rn.ftz.f32 	%f255, %f217, %f220, %f255;

BB16_44:
	st.global.v2.f32 	[prd_radiance], {%f253, %f254};
	st.global.f32 	[prd_radiance+8], %f255;
	ld.global.v2.f32 	{%f221, %f222}, [normal];
	ld.global.f32 	%f224, [normal+8];
	st.global.v2.f32 	[prd_radiance+16], {%f222, %f224};
	st.global.f32 	[prd_radiance+12], %f221;
	st.global.v2.f32 	[prd_radiance+24], {%f1, %f2};
	st.global.f32 	[prd_radiance+32], %f3;
	ld.global.f32 	%f226, [eye];
	sub.ftz.f32 	%f227, %f1, %f226;
	ld.global.f32 	%f228, [eye+4];
	sub.ftz.f32 	%f229, %f2, %f228;
	ld.global.f32 	%f230, [eye+8];
	sub.ftz.f32 	%f231, %f3, %f230;
	mul.ftz.f32 	%f232, %f229, %f229;
	fma.rn.ftz.f32 	%f233, %f227, %f227, %f232;
	fma.rn.ftz.f32 	%f234, %f231, %f231, %f233;
	sqrt.approx.ftz.f32 	%f235, %f234;
	div.full.ftz.f32 	%f236, %f235, 0f42C80000;
	st.global.f32 	[prd_radiance+36], %f236;
	ret;
}

.visible .entry _Z15julia_ah_shadowv(

)
{
	.reg .s32 	%r<2>;
	.reg .f32 	%f<2>;


	mov.u32 	%r1, 0;
	st.global.u32 	[prd_shadow+8], %r1;
	mov.f32 	%f1, 0f00000000;
	st.global.v2.f32 	[prd_shadow], {%f1, %f1};
	// inline asm
	call _rt_terminate_ray, ();
	// inline asm
	ret;
}

.visible .entry _Z18chrome_ch_radiancev(

)
{
	.local .align 8 .b8 	__local_depot18[56];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .s32 	%r<7>;
	.reg .f32 	%f<63>;
	.reg .s64 	%rd<8>;


	mov.u64 	%SPL, __local_depot18;
	cvta.local.u64 	%SP, %SPL;
	ld.global.f32 	%f3, [ray+20];
	ld.global.f32 	%f2, [ray+16];
	ld.global.f32 	%f1, [ray+12];
	mov.u64 	%rd1, prd_radiance;
	add.s64 	%rd2, %rd1, 48;
	ldu.global.u32 	%r1, [%rd2];
	setp.lt.s32	%p1, %r1, 3;
	@%p1 bra 	BB18_2;

	mov.u32 	%r2, 0;
	st.global.u32 	[prd_radiance+8], %r2;
	mov.f32 	%f4, 0f00000000;
	st.global.v2.f32 	[prd_radiance], {%f4, %f4};
	bra.uni 	BB18_3;

BB18_2:
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	ldu.global.f32 	%f13, [isect_t];
	ld.global.v2.f32 	{%f14, %f15}, [ray];
	fma.rn.ftz.f32 	%f5, %f1, %f13, %f14;
	fma.rn.ftz.f32 	%f6, %f2, %f13, %f15;
	ld.global.f32 	%f18, [ray+8];
	fma.rn.ftz.f32 	%f7, %f3, %f13, %f18;
	ld.global.f32 	%f19, [prd_radiance+40];
	st.local.f32 	[%rd4+40], %f19;
	add.s32 	%r6, %r1, 1;
	st.local.u32 	[%rd4+48], %r6;
	ldu.global.f32 	%f20, [shading_normal];
	add.ftz.f32 	%f21, %f20, %f20;
	mov.u64 	%rd5, shading_normal;
	add.s64 	%rd6, %rd5, 4;
	ldu.global.f32 	%f22, [%rd6];
	add.ftz.f32 	%f23, %f22, %f22;
	add.s64 	%rd7, %rd5, 8;
	ldu.global.f32 	%f24, [%rd7];
	add.ftz.f32 	%f25, %f24, %f24;
	mul.ftz.f32 	%f26, %f22, %f2;
	fma.rn.ftz.f32 	%f27, %f20, %f1, %f26;
	fma.rn.ftz.f32 	%f28, %f24, %f3, %f27;
	mul.ftz.f32 	%f29, %f21, %f28;
	mul.ftz.f32 	%f30, %f23, %f28;
	mul.ftz.f32 	%f31, %f25, %f28;
	sub.ftz.f32 	%f8, %f1, %f29;
	sub.ftz.f32 	%f9, %f2, %f30;
	sub.ftz.f32 	%f10, %f3, %f31;
	ldu.global.u32 	%r3, [top_object];
	mov.u32 	%r4, 0;
	mov.f32 	%f11, 0f3A83126F;
	mov.f32 	%f12, 0f6C4ECB8F;
	mov.u32 	%r5, 52;
	// inline asm
	call _rt_trace_64, (%r3, %f5, %f6, %f7, %f8, %f9, %f10, %r4, %f11, %f12, %rd3, %r5);
	// inline asm
	ld.global.f32 	%f32, [shading_normal];
	neg.ftz.f32 	%f33, %f1;
	mul.ftz.f32 	%f34, %f32, %f33;
	ld.global.f32 	%f35, [shading_normal+4];
	mul.ftz.f32 	%f36, %f35, %f2;
	sub.ftz.f32 	%f37, %f34, %f36;
	ld.global.f32 	%f38, [shading_normal+8];
	mul.ftz.f32 	%f39, %f38, %f3;
	sub.ftz.f32 	%f40, %f37, %f39;
	mov.f32 	%f41, 0f3F800000;
	sub.ftz.f32 	%f42, %f41, %f40;
	mov.f32 	%f43, 0f00000000;
	max.ftz.f32 	%f44, %f43, %f42;
	lg2.approx.ftz.f32 	%f45, %f44;
	mul.ftz.f32 	%f46, %f45, 0f40A00000;
	ex2.approx.ftz.f32 	%f47, %f46;
	fma.rn.ftz.f32 	%f48, %f47, 0f3F333333, 0f3E99999A;
	mov.f32 	%f49, 0f3E99999A;
	min.ftz.f32 	%f50, %f48, %f41;
	max.ftz.f32 	%f51, %f49, %f50;
	add.ftz.f32 	%f52, %f35, 0f3F800000;
	mul.ftz.f32 	%f53, %f52, 0f3F000000;
	ld.local.f32 	%f54, [%rd4];
	ld.local.f32 	%f55, [%rd4+4];
	ld.local.f32 	%f56, [%rd4+8];
	mul.ftz.f32 	%f57, %f53, %f53;
	mul.ftz.f32 	%f58, %f57, %f53;
	mul.ftz.f32 	%f59, %f58, 0f3DCCCCCD;
	fma.rn.ftz.f32 	%f60, %f56, %f51, %f59;
	fma.rn.ftz.f32 	%f61, %f55, %f51, %f59;
	fma.rn.ftz.f32 	%f62, %f54, %f51, %f59;
	st.global.v2.f32 	[prd_radiance], {%f62, %f61};
	st.global.f32 	[prd_radiance+8], %f60;

BB18_3:
	ret;
}

.visible .entry _Z16chrome_ah_shadowv(

)
{
	.reg .s32 	%r<2>;
	.reg .f32 	%f<2>;


	mov.u32 	%r1, 0;
	st.global.u32 	[prd_shadow+8], %r1;
	mov.f32 	%f1, 0f00000000;
	st.global.v2.f32 	[prd_shadow], {%f1, %f1};
	// inline asm
	call _rt_terminate_ray, ();
	// inline asm
	ret;
}

.visible .entry _Z11envmap_missv(

)
{
	.reg .pred 	%p<12>;
	.reg .s32 	%r<13>;
	.reg .f32 	%f<72>;
	.reg .s64 	%rd<7>;


	mov.u64 	%rd1, ray;
	add.s64 	%rd2, %rd1, 12;
	ldu.global.f32 	%f7, [%rd2];
	add.s64 	%rd3, %rd1, 20;
	ldu.global.f32 	%f8, [%rd3];
	abs.ftz.f32 	%f1, %f8;
	abs.ftz.f32 	%f2, %f7;
	setp.eq.ftz.f32	%p1, %f1, 0f00000000;
	setp.eq.ftz.f32	%p2, %f2, 0f00000000;
	and.pred  	%p3, %p1, %p2;
	mov.b32 	 %r1, %f8;
	mov.b32 	 %r3, %f7;
	and.b32  	%r2, %r3, -2147483648;
	@%p3 bra 	BB20_4;

	setp.eq.ftz.f32	%p4, %f1, 0f7F800000;
	setp.eq.ftz.f32	%p5, %f2, 0f7F800000;
	and.pred  	%p6, %p4, %p5;
	@%p6 bra 	BB20_3;

	max.ftz.f32 	%f9, %f2, %f1;
	min.ftz.f32 	%f10, %f2, %f1;
	div.full.ftz.f32 	%f11, %f10, %f9;
	mul.rn.ftz.f32 	%f12, %f11, %f11;
	mov.f32 	%f13, 0fC0B59883;
	mov.f32 	%f14, 0fBF52C7EA;
	fma.rn.ftz.f32 	%f15, %f12, %f14, %f13;
	mov.f32 	%f16, 0fC0D21907;
	fma.rn.ftz.f32 	%f17, %f15, %f12, %f16;
	mul.ftz.f32 	%f18, %f17, %f12;
	mul.ftz.f32 	%f19, %f18, %f11;
	add.ftz.f32 	%f20, %f12, 0f41355DC0;
	mov.f32 	%f21, 0f41E6BD60;
	fma.rn.ftz.f32 	%f22, %f20, %f12, %f21;
	mov.f32 	%f23, 0f419D92C8;
	fma.rn.ftz.f32 	%f24, %f22, %f12, %f23;
	rcp.approx.ftz.f32 	%f25, %f24;
	fma.rn.ftz.f32 	%f26, %f19, %f25, %f11;
	mov.f32 	%f27, 0f3FC90FDB;
	sub.ftz.f32 	%f28, %f27, %f26;
	setp.gt.ftz.f32	%p7, %f2, %f1;
	selp.f32	%f29, %f28, %f26, %p7;
	mov.f32 	%f30, 0f40490FDB;
	sub.ftz.f32 	%f31, %f30, %f29;
	setp.lt.s32	%p8, %r1, 0;
	selp.f32	%f32, %f31, %f29, %p8;
	mov.b32 	 %r4, %f32;
	or.b32  	%r5, %r4, %r2;
	mov.b32 	 %f33, %r5;
	add.ftz.f32 	%f34, %f1, %f2;
	setp.gtu.ftz.f32	%p9, %f34, 0f7F800000;
	selp.f32	%f71, %f34, %f33, %p9;
	bra.uni 	BB20_5;

BB20_3:
	shr.s32 	%r6, %r1, 31;
	and.b32  	%r7, %r6, 13483017;
	add.s32 	%r8, %r7, 1061752795;
	or.b32  	%r9, %r8, %r2;
	mov.b32 	 %f71, %r9;
	bra.uni 	BB20_5;

BB20_4:
	shr.s32 	%r10, %r1, 31;
	and.b32  	%r11, %r10, 1078530011;
	or.b32  	%r12, %r11, %r2;
	mov.b32 	 %f71, %r12;

BB20_5:
	add.s64 	%rd6, %rd1, 16;
	ldu.global.f32 	%f41, [%rd6];
	abs.ftz.f32 	%f42, %f41;
	mov.f32 	%f43, 0f3F800000;
	sub.ftz.f32 	%f44, %f43, %f42;
	mul.ftz.f32 	%f45, %f44, 0f3F000000;
	sqrt.approx.ftz.f32 	%f46, %f45;
	setp.gt.ftz.f32	%p10, %f42, 0f3F11EB85;
	selp.f32	%f47, %f46, %f42, %p10;
	mul.ftz.f32 	%f48, %f47, %f47;
	mov.f32 	%f49, 0f3C94D2E9;
	mov.f32 	%f50, 0f3D53F941;
	fma.rn.ftz.f32 	%f51, %f50, %f48, %f49;
	mov.f32 	%f52, 0f3D3F841F;
	fma.rn.ftz.f32 	%f53, %f51, %f48, %f52;
	mov.f32 	%f54, 0f3D994929;
	fma.rn.ftz.f32 	%f55, %f53, %f48, %f54;
	mov.f32 	%f56, 0f3E2AAB94;
	fma.rn.ftz.f32 	%f57, %f55, %f48, %f56;
	mul.ftz.f32 	%f58, %f57, %f48;
	fma.rn.ftz.f32 	%f59, %f58, %f47, %f47;
	add.ftz.f32 	%f60, %f59, %f59;
	mov.f32 	%f61, 0f3FC90FDB;
	sub.ftz.f32 	%f62, %f61, %f59;
	selp.f32	%f63, %f60, %f62, %p10;
	setp.lt.ftz.f32	%p11, %f41, 0f00000000;
	mov.f32 	%f64, 0f40490FDB;
	sub.ftz.f32 	%f65, %f64, %f63;
	selp.f32	%f66, %f65, %f63, %p11;
	sub.ftz.f32 	%f67, %f61, %f66;
	add.ftz.f32 	%f68, %f71, 0f40490FDB;
	mul.ftz.f32 	%f39, %f68, 0f3E22F983;
	sin.approx.ftz.f32 	%f69, %f67;
	add.ftz.f32 	%f70, %f69, 0f3F800000;
	mul.ftz.f32 	%f40, %f70, 0f3F000000;
	// inline asm
	tex.2d.v4.f32.f32 {%f35, %f36, %f37, %f38}, [envmap, {%f39, %f40}];
	// inline asm
	st.global.v2.f32 	[prd_radiance], {%f35, %f36};
	st.global.f32 	[prd_radiance+8], %f37;
	ret;
}

.visible .func _ZN5optix3RayC1Ev(
	.param .b64 _ZN5optix3RayC1Ev_param_0
)
{



	ret;
}

.visible .func _ZN5optix3RayC2Ev(
	.param .b64 _ZN5optix3RayC2Ev_param_0
)
{



	ret;
}

.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
{
	.local .align 8 .b8 	__local_depot23[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .s32 	%r<42>;
	.reg .s64 	%rd<99>;
	.reg .f64 	%fd<5>;


	mov.u64 	%SPL, __local_depot23;
	ld.param.f64 	%fd4, [__internal_trig_reduction_slowpathd_param_0];
	ld.param.u64 	%rd37, [__internal_trig_reduction_slowpathd_param_1];
	add.u64 	%rd38, %SPL, 0;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd4;
	}
	and.b32  	%r40, %r1, -2147483648;
	shr.u32 	%r3, %r1, 20;
	bfe.u32 	%r4, %r1, 20, 11;
	setp.eq.s32	%p1, %r4, 2047;
	@%p1 bra 	BB23_14;

	add.s32 	%r15, %r4, -1024;
	shr.u32 	%r16, %r15, 6;
	mov.u32 	%r17, 15;
	sub.s32 	%r5, %r17, %r16;
	mov.u32 	%r18, 19;
	sub.s32 	%r19, %r18, %r16;
	mov.u32 	%r20, 18;
	min.s32 	%r6, %r20, %r19;
	setp.lt.s32	%p2, %r5, %r6;
	mov.u64 	%rd92, %rd38;
	@%p2 bra 	BB23_3;

	mov.u64 	%rd93, 0;
	bra.uni 	BB23_5;

BB23_3:
	mov.b64 	 %rd41, %fd4;
	shl.b64 	%rd42, %rd41, 11;
	or.b64  	%rd3, %rd42, -9223372036854775808;
	bfe.u32 	%r21, %r1, 20, 11;
	add.s32 	%r22, %r21, -1024;
	shr.u32 	%r23, %r22, 6;
	sub.s32 	%r25, %r17, %r23;
	mul.wide.s32 	%rd43, %r25, 8;
	mov.u64 	%rd44, __cudart_i2opi_d;
	add.s64 	%rd90, %rd44, %rd43;
	mov.u64 	%rd93, 0;
	mov.u64 	%rd91, %rd38;
	mov.u64 	%rd89, %rd38;
	mov.u32 	%r39, %r5;

BB23_4:
	.pragma "nounroll";
	mov.u32 	%r7, %r39;
	mov.u64 	%rd6, %rd89;
	ld.const.u64 	%rd47, [%rd90];
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, alo, ahi, blo, bhi, clo, chi;
	mov.b64         {alo,ahi}, %rd47;    
	mov.b64         {blo,bhi}, %rd3;    
	mov.b64         {clo,chi}, %rd93;    
	mad.lo.cc.u32   r0, alo, blo, clo;
	madc.hi.cc.u32  r1, alo, blo, chi;
	madc.hi.u32     r2, alo, bhi,   0;
	mad.lo.cc.u32   r1, alo, bhi,  r1;
	madc.hi.cc.u32  r2, ahi, blo,  r2;
	madc.hi.u32     r3, ahi, bhi,   0;
	mad.lo.cc.u32   r1, ahi, blo,  r1;
	madc.lo.cc.u32  r2, ahi, bhi,  r2;
	addc.u32        r3,  r3,   0;     
	mov.b64         %rd45, {r0,r1};      
	mov.b64         %rd46, {r2,r3};      
	}
	// inline asm
	st.local.u64 	[%rd91], %rd45;
	add.s32 	%r8, %r7, 1;
	sub.s32 	%r26, %r8, %r5;
	mul.wide.s32 	%rd50, %r26, 8;
	add.s64 	%rd91, %rd38, %rd50;
	add.s64 	%rd90, %rd90, 8;
	add.s64 	%rd92, %rd6, 8;
	setp.lt.s32	%p3, %r8, %r6;
	mov.u64 	%rd13, %rd92;
	mov.u64 	%rd93, %rd46;
	mov.u64 	%rd89, %rd13;
	mov.u32 	%r39, %r8;
	@%p3 bra 	BB23_4;

BB23_5:
	st.local.u64 	[%rd92], %rd93;
	ld.local.u64 	%rd94, [%rd38+16];
	ld.local.u64 	%rd95, [%rd38+24];
	and.b32  	%r9, %r3, 63;
	setp.eq.s32	%p4, %r9, 0;
	@%p4 bra 	BB23_7;

	mov.u32 	%r27, 64;
	sub.s32 	%r28, %r27, %r9;
	shl.b64 	%rd51, %rd95, %r9;
	shr.u64 	%rd52, %rd94, %r28;
	or.b64  	%rd95, %rd51, %rd52;
	shl.b64 	%rd53, %rd94, %r9;
	ld.local.u64 	%rd54, [%rd38+8];
	shr.u64 	%rd55, %rd54, %r28;
	or.b64  	%rd94, %rd55, %rd53;

BB23_7:
	cvta.to.local.u64 	%rd56, %rd37;
	shr.u64 	%rd57, %rd95, 62;
	cvt.u32.u64	%r29, %rd57;
	shr.u64 	%rd58, %rd94, 62;
	shl.b64 	%rd59, %rd95, 2;
	or.b64  	%rd97, %rd59, %rd58;
	shl.b64 	%rd96, %rd94, 2;
	shr.u64 	%rd60, %rd95, 61;
	cvt.u32.u64	%r30, %rd60;
	and.b32  	%r31, %r30, 1;
	add.s32 	%r32, %r31, %r29;
	neg.s32 	%r33, %r32;
	setp.eq.s32	%p5, %r40, 0;
	selp.b32	%r34, %r32, %r33, %p5;
	st.local.u32 	[%rd56], %r34;
	setp.eq.s32	%p6, %r31, 0;
	@%p6 bra 	BB23_9;

	mov.u64 	%rd64, 0;
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, a0, a1, a2, a3, b0, b1, b2, b3;
	mov.b64         {a0,a1}, %rd64;
	mov.b64         {a2,a3}, %rd64;
	mov.b64         {b0,b1}, %rd96;
	mov.b64         {b2,b3}, %rd97;
	sub.cc.u32      r0, a0, b0; 
	subc.cc.u32     r1, a1, b1; 
	subc.cc.u32     r2, a2, b2; 
	subc.u32        r3, a3, b3; 
	mov.b64         %rd61, {r0,r1};
	mov.b64         %rd62, {r2,r3};
	}
	// inline asm
	xor.b32  	%r40, %r40, -2147483648;
	mov.u64 	%rd97, %rd62;
	mov.u64 	%rd96, %rd61;

BB23_9:
	clz.b64 	%r41, %rd97;
	setp.eq.s32	%p7, %r41, 0;
	@%p7 bra 	BB23_11;

	shl.b64 	%rd67, %rd97, %r41;
	mov.u32 	%r35, 64;
	sub.s32 	%r36, %r35, %r41;
	shr.u64 	%rd68, %rd96, %r36;
	or.b64  	%rd97, %rd68, %rd67;

BB23_11:
	mov.u64 	%rd72, -3958705157555305931;
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, alo, ahi, blo, bhi;
	mov.b64         {alo,ahi}, %rd97;   
	mov.b64         {blo,bhi}, %rd72;   
	mul.lo.u32      r0, alo, blo;    
	mul.hi.u32      r1, alo, blo;    
	mad.lo.cc.u32   r1, alo, bhi, r1;
	madc.hi.u32     r2, alo, bhi,  0;
	mad.lo.cc.u32   r1, ahi, blo, r1;
	madc.hi.cc.u32  r2, ahi, blo, r2;
	madc.hi.u32     r3, ahi, bhi,  0;
	mad.lo.cc.u32   r2, ahi, bhi, r2;
	addc.u32        r3, r3,  0;      
	mov.b64         %rd69, {r0,r1};     
	mov.b64         %rd70, {r2,r3};     
	}
	// inline asm
	setp.lt.s64	%p8, %rd70, 1;
	mov.u64 	%rd98, %rd70;
	@%p8 bra 	BB23_13;

	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, a0, a1, a2, a3, b0, b1, b2, b3;
	mov.b64         {a0,a1}, %rd69;
	mov.b64         {a2,a3}, %rd70;
	mov.b64         {b0,b1}, %rd69;
	mov.b64         {b2,b3}, %rd70;
	add.cc.u32      r0, a0, b0; 
	addc.cc.u32     r1, a1, b1; 
	addc.cc.u32     r2, a2, b2; 
	addc.u32        r3, a3, b3; 
	mov.b64         %rd73, {r0,r1};
	mov.b64         %rd74, {r2,r3};
	}
	// inline asm
	add.s32 	%r41, %r41, 1;
	mov.u64 	%rd98, %rd74;

BB23_13:
	cvt.u64.u32	%rd79, %r40;
	shl.b64 	%rd80, %rd79, 32;
	mov.u32 	%r37, 1022;
	sub.s32 	%r38, %r37, %r41;
	cvt.u64.u32	%rd81, %r38;
	shl.b64 	%rd82, %rd81, 52;
	add.s64 	%rd83, %rd98, 1;
	shr.u64 	%rd84, %rd83, 10;
	add.s64 	%rd85, %rd84, 1;
	shr.u64 	%rd86, %rd85, 1;
	add.s64 	%rd87, %rd86, %rd82;
	or.b64  	%rd88, %rd87, %rd80;
	mov.b64 	 %fd4, %rd88;

BB23_14:
	st.param.f64	[func_retval0+0], %fd4;
	ret;
}


