//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-19324607
// Cuda compilation tools, release 7.0, V7.0.27
// Based on LLVM 3.4svn
//

.version 4.2
.target sm_20
.address_size 64

	// .globl	_ZN10Mandelbulb14evalParametersEv
.visible .func _ZN10Mandelbulb14evalParametersEv
(
	.param .b64 _ZN10Mandelbulb14evalParametersEv_param_0
)
;
.visible .func  (.param .b32 func_retval0) _ZN10Mandelbulb12evalDistanceE6float3
(
	.param .b64 _ZN10Mandelbulb12evalDistanceE6float3_param_0,
	.param .align 4 .b8 _ZN10Mandelbulb12evalDistanceE6float3_param_1[12]
)
;
.visible .func _ZN10TunnelTest14evalParametersEv
(
	.param .b64 _ZN10TunnelTest14evalParametersEv_param_0
)
;
.visible .func  (.param .b32 func_retval0) _ZN10TunnelTest12evalDistanceE6float3
(
	.param .b64 _ZN10TunnelTest12evalDistanceE6float3_param_0,
	.param .align 4 .b8 _ZN10TunnelTest12evalDistanceE6float3_param_1[12]
)
;
.global .align 8 .b8 _ZTV17DistanceEstimator[32];
.global .align 8 .u64 _ZTV10Mandelbulb[4] = {0, 0, _ZN10Mandelbulb14evalParametersEv, _ZN10Mandelbulb12evalDistanceE6float3};
.global .align 8 .u64 _ZTV10TunnelTest[4] = {0, 0, _ZN10TunnelTest14evalParametersEv, _ZN10TunnelTest12evalDistanceE6float3};
.const .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .func _ZN10Mandelbulb14evalParametersEv(
	.param .b64 _ZN10Mandelbulb14evalParametersEv_param_0
)
{



	ret;
}

	// .globl	_ZN10Mandelbulb12evalDistanceE6float3
.visible .func  (.param .b32 func_retval0) _ZN10Mandelbulb12evalDistanceE6float3(
	.param .b64 _ZN10Mandelbulb12evalDistanceE6float3_param_0,
	.param .align 4 .b8 _ZN10Mandelbulb12evalDistanceE6float3_param_1[12]
)
{
	.local .align 4 .b8 	__local_depot1[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<299>;
	.reg .f32 	%f<1316>;
	.reg .s32 	%r<1528>;
	.reg .s64 	%rd<181>;


	mov.u64 	%rd180, __local_depot1;
	cvta.local.u64 	%SP, %rd180;
	ld.param.u64 	%rd95, [_ZN10Mandelbulb12evalDistanceE6float3_param_0];
	ld.param.f32 	%f1247, [_ZN10Mandelbulb12evalDistanceE6float3_param_1+8];
	ld.param.f32 	%f401, [_ZN10Mandelbulb12evalDistanceE6float3_param_1+4];
	ld.param.f32 	%f400, [_ZN10Mandelbulb12evalDistanceE6float3_param_1];
	add.u64 	%rd96, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd96;
	add.s64 	%rd2, %rd95, 12;
	ld.f32 	%f403, [%rd95+12];
	div.rn.f32 	%f1207, %f403, 0f42200000;
	abs.f32 	%f404, %f1207;
	setp.neu.f32	%p1, %f404, 0f7F800000;
	@%p1 bra 	BB1_2;

	mov.f32 	%f405, 0f00000000;
	mul.rn.f32 	%f1207, %f1207, %f405;

BB1_2:
	abs.f32 	%f406, %f1207;
	add.s64 	%rd3, %rd1, 24;
	setp.leu.f32	%p2, %f406, 0f47CE4780;
	@%p2 bra 	BB1_6;

	mov.b32 	 %r597, %f1207;
	shl.b32 	%r598, %r597, 8;
	or.b32  	%r1, %r598, -2147483648;
	mov.u32 	%r1366, 0;
	mov.u64 	%rd130, __cudart_i2opi_f;
	mov.u32 	%r1365, -6;
	mov.u64 	%rd179, %rd1;

BB1_4:
	.pragma "nounroll";
	ld.const.u32 	%r601, [%rd130];
	// inline asm
	{
	mad.lo.cc.u32   %r599, %r601, %r1, %r1366;
	madc.hi.u32     %r600, %r601, %r1,  0;
	}
	// inline asm
	mov.u32 	%r1366, %r600;
	st.local.u32 	[%rd179], %r599;
	add.s64 	%rd179, %rd179, 4;
	add.s64 	%rd130, %rd130, 4;
	add.s32 	%r1365, %r1365, 1;
	setp.ne.s32	%p3, %r1365, 0;
	@%p3 bra 	BB1_4;

	st.local.u32 	[%rd3], %r600;

BB1_6:
	ld.f32 	%f4, [%rd2+8];
	ld.f32 	%f5, [%rd2+12];
	ld.f32 	%f6, [%rd2+4];
	add.f32 	%f407, %f6, 0fBF800000;
	abs.f32 	%f408, %f407;
	setp.geu.f32	%p4, %f408, 0f38D1B717;
	@%p4 bra 	BB1_9;

	add.f32 	%f409, %f4, 0fBF800000;
	abs.f32 	%f410, %f409;
	setp.geu.f32	%p5, %f410, 0f38D1B717;
	@%p5 bra 	BB1_9;

	add.f32 	%f411, %f5, 0fBF800000;
	abs.f32 	%f412, %f411;
	setp.lt.f32	%p6, %f412, 0f38D1B717;
	mov.f32 	%f1243, %f400;
	mov.f32 	%f1246, %f401;
	@%p6 bra 	BB1_10;

BB1_9:
	fma.rn.f32 	%f413, %f400, %f6, 0f00000000;
	fma.rn.f32 	%f414, %f401, 0f00000000, %f413;
	fma.rn.f32 	%f415, %f1247, 0f00000000, %f414;
	add.f32 	%f7, %f415, 0f00000000;
	fma.rn.f32 	%f416, %f400, 0f00000000, 0f00000000;
	fma.rn.f32 	%f417, %f401, %f4, %f416;
	fma.rn.f32 	%f418, %f1247, 0f00000000, %f417;
	add.f32 	%f8, %f418, 0f00000000;
	fma.rn.f32 	%f419, %f401, 0f00000000, %f416;
	fma.rn.f32 	%f420, %f1247, %f5, %f419;
	add.f32 	%f1247, %f420, 0f00000000;
	mov.f32 	%f1243, %f7;
	mov.f32 	%f1246, %f8;

BB1_10:
	mov.f32 	%f1245, %f1246;
	mov.f32 	%f1242, %f1243;
	ld.f32 	%f13, [%rd2+44];
	ld.f32 	%f14, [%rd2+48];
	ld.f32 	%f15, [%rd2+40];
	abs.f32 	%f16, %f15;
	setp.geu.f32	%p7, %f16, 0f38D1B717;
	@%p7 bra 	BB1_13;

	abs.f32 	%f421, %f13;
	setp.geu.f32	%p8, %f421, 0f38D1B717;
	@%p8 bra 	BB1_13;

	abs.f32 	%f422, %f14;
	setp.lt.f32	%p9, %f422, 0f38D1B717;
	@%p9 bra 	BB1_146;

BB1_13:
	setp.neu.f32	%p10, %f16, 0f7F800000;
	mov.f32 	%f1214, %f15;
	@%p10 bra 	BB1_15;

	mov.f32 	%f423, 0f00000000;
	mul.rn.f32 	%f17, %f15, %f423;
	mov.f32 	%f1214, %f17;

BB1_15:
	mov.f32 	%f18, %f1214;
	mul.f32 	%f424, %f18, 0f3F22F983;
	cvt.rni.s32.f32	%r1376, %f424;
	cvt.rn.f32.s32	%f425, %r1376;
	neg.f32 	%f426, %f425;
	mov.f32 	%f427, 0f3FC90FDA;
	fma.rn.f32 	%f428, %f426, %f427, %f18;
	mov.f32 	%f429, 0f33A22168;
	fma.rn.f32 	%f430, %f426, %f429, %f428;
	mov.f32 	%f431, 0f27C234C5;
	fma.rn.f32 	%f1208, %f426, %f431, %f430;
	abs.f32 	%f432, %f18;
	setp.leu.f32	%p11, %f432, 0f47CE4780;
	@%p11 bra 	BB1_25;

	mov.b32 	 %r7, %f18;
	shr.u32 	%r8, %r7, 23;
	bfe.u32 	%r606, %r7, 23, 8;
	add.s32 	%r607, %r606, -128;
	shl.b32 	%r608, %r7, 8;
	or.b32  	%r9, %r608, -2147483648;
	shr.u32 	%r10, %r607, 5;
	mov.u32 	%r1368, 0;
	mov.u64 	%rd131, __cudart_i2opi_f;
	mov.u32 	%r1367, -6;
	mov.u64 	%rd178, %rd1;

BB1_17:
	.pragma "nounroll";
	ld.const.u32 	%r611, [%rd131];
	// inline asm
	{
	mad.lo.cc.u32   %r609, %r611, %r9, %r1368;
	madc.hi.u32     %r610, %r611, %r9,  0;
	}
	// inline asm
	mov.u32 	%r1368, %r610;
	st.local.u32 	[%rd178], %r609;
	add.s64 	%rd178, %rd178, 4;
	add.s64 	%rd131, %rd131, 4;
	add.s32 	%r1367, %r1367, 1;
	setp.ne.s32	%p12, %r1367, 0;
	@%p12 bra 	BB1_17;

	and.b32  	%r15, %r7, -2147483648;
	st.local.u32 	[%rd3], %r610;
	mov.u32 	%r614, 6;
	sub.s32 	%r615, %r614, %r10;
	mul.wide.s32 	%rd99, %r615, 4;
	add.s64 	%rd14, %rd1, %rd99;
	ld.local.u32 	%r1369, [%rd14];
	ld.local.u32 	%r1370, [%rd14+-4];
	and.b32  	%r18, %r8, 31;
	setp.eq.s32	%p13, %r18, 0;
	@%p13 bra 	BB1_20;

	mov.u32 	%r616, 32;
	sub.s32 	%r617, %r616, %r18;
	shr.u32 	%r618, %r1370, %r617;
	shl.b32 	%r619, %r1369, %r18;
	add.s32 	%r1369, %r618, %r619;
	ld.local.u32 	%r620, [%rd14+-8];
	shr.u32 	%r621, %r620, %r617;
	shl.b32 	%r622, %r1370, %r18;
	add.s32 	%r1370, %r621, %r622;

BB1_20:
	shr.u32 	%r623, %r1370, 30;
	shl.b32 	%r624, %r1369, 2;
	add.s32 	%r1371, %r623, %r624;
	shl.b32 	%r24, %r1370, 2;
	shr.u32 	%r625, %r1371, 31;
	shr.u32 	%r626, %r1369, 30;
	add.s32 	%r25, %r625, %r626;
	setp.eq.s32	%p14, %r625, 0;
	mov.u32 	%r1372, %r15;
	mov.u32 	%r1373, %r24;
	@%p14 bra 	BB1_22;

	not.b32 	%r627, %r1371;
	neg.s32 	%r26, %r24;
	setp.eq.s32	%p15, %r24, 0;
	selp.u32	%r628, 1, 0, %p15;
	add.s32 	%r1371, %r628, %r627;
	xor.b32  	%r28, %r15, -2147483648;
	mov.u32 	%r1372, %r28;
	mov.u32 	%r1373, %r26;

BB1_22:
	mov.u32 	%r30, %r1372;
	neg.s32 	%r629, %r25;
	setp.eq.s32	%p16, %r15, 0;
	selp.b32	%r1376, %r25, %r629, %p16;
	clz.b32 	%r1375, %r1371;
	setp.eq.s32	%p17, %r1375, 0;
	shl.b32 	%r630, %r1371, %r1375;
	mov.u32 	%r631, 32;
	sub.s32 	%r632, %r631, %r1375;
	shr.u32 	%r633, %r1373, %r632;
	add.s32 	%r634, %r633, %r630;
	selp.b32	%r34, %r1371, %r634, %p17;
	mov.u32 	%r635, -921707870;
	mul.hi.u32 	%r1374, %r34, %r635;
	setp.lt.s32	%p18, %r1374, 1;
	@%p18 bra 	BB1_24;

	mul.lo.s32 	%r636, %r34, -921707870;
	shr.u32 	%r637, %r636, 31;
	shl.b32 	%r638, %r1374, 1;
	add.s32 	%r1374, %r637, %r638;
	add.s32 	%r1375, %r1375, 1;

BB1_24:
	mov.u32 	%r639, 126;
	sub.s32 	%r640, %r639, %r1375;
	shl.b32 	%r641, %r640, 23;
	add.s32 	%r642, %r1374, 1;
	shr.u32 	%r643, %r642, 7;
	add.s32 	%r644, %r643, 1;
	shr.u32 	%r645, %r644, 1;
	add.s32 	%r646, %r645, %r641;
	or.b32  	%r647, %r646, %r30;
	mov.b32 	 %f1208, %r647;

BB1_25:
	mul.rn.f32 	%f22, %f1208, %f1208;
	and.b32  	%r41, %r1376, 1;
	setp.eq.s32	%p19, %r41, 0;
	@%p19 bra 	BB1_27;

	mov.f32 	%f433, 0fBAB6061A;
	mov.f32 	%f434, 0f37CCF5CE;
	fma.rn.f32 	%f1209, %f434, %f22, %f433;
	bra.uni 	BB1_28;

BB1_27:
	mov.f32 	%f435, 0f3C08839E;
	mov.f32 	%f436, 0fB94CA1F9;
	fma.rn.f32 	%f1209, %f436, %f22, %f435;

BB1_28:
	@%p19 bra 	BB1_30;

	mov.f32 	%f437, 0f3D2AAAA5;
	fma.rn.f32 	%f438, %f1209, %f22, %f437;
	mov.f32 	%f439, 0fBF000000;
	fma.rn.f32 	%f1210, %f438, %f22, %f439;
	bra.uni 	BB1_31;

BB1_30:
	mov.f32 	%f440, 0fBE2AAAA3;
	fma.rn.f32 	%f441, %f1209, %f22, %f440;
	mov.f32 	%f442, 0f00000000;
	fma.rn.f32 	%f1210, %f441, %f22, %f442;

BB1_31:
	fma.rn.f32 	%f1211, %f1210, %f1208, %f1208;
	@%p19 bra 	BB1_33;

	mov.f32 	%f443, 0f3F800000;
	fma.rn.f32 	%f1211, %f1210, %f22, %f443;

BB1_33:
	and.b32  	%r648, %r1376, 2;
	setp.eq.s32	%p22, %r648, 0;
	@%p22 bra 	BB1_35;

	mov.f32 	%f444, 0f00000000;
	mov.f32 	%f445, 0fBF800000;
	fma.rn.f32 	%f1211, %f1211, %f445, %f444;

BB1_35:
	mov.f32 	%f1213, %f15;
	@%p10 bra 	BB1_37;

	mov.f32 	%f446, 0f00000000;
	mul.rn.f32 	%f1213, %f15, %f446;

BB1_37:
	mul.f32 	%f447, %f1213, 0f3F22F983;
	cvt.rni.s32.f32	%r1386, %f447;
	cvt.rn.f32.s32	%f448, %r1386;
	neg.f32 	%f449, %f448;
	fma.rn.f32 	%f451, %f449, %f427, %f1213;
	fma.rn.f32 	%f453, %f449, %f429, %f451;
	fma.rn.f32 	%f1215, %f449, %f431, %f453;
	abs.f32 	%f455, %f1213;
	setp.leu.f32	%p24, %f455, 0f47CE4780;
	@%p24 bra 	BB1_47;

	mov.b32 	 %r43, %f1213;
	shr.u32 	%r44, %r43, 23;
	bfe.u32 	%r651, %r43, 23, 8;
	add.s32 	%r652, %r651, -128;
	shl.b32 	%r653, %r43, 8;
	or.b32  	%r45, %r653, -2147483648;
	shr.u32 	%r46, %r652, 5;
	mov.u32 	%r1378, 0;
	mov.u64 	%rd132, __cudart_i2opi_f;
	mov.u32 	%r1377, -6;
	mov.u64 	%rd177, %rd1;

BB1_39:
	.pragma "nounroll";
	ld.const.u32 	%r656, [%rd132];
	// inline asm
	{
	mad.lo.cc.u32   %r654, %r656, %r45, %r1378;
	madc.hi.u32     %r655, %r656, %r45,  0;
	}
	// inline asm
	mov.u32 	%r1378, %r655;
	st.local.u32 	[%rd177], %r654;
	add.s64 	%rd177, %rd177, 4;
	add.s64 	%rd132, %rd132, 4;
	add.s32 	%r1377, %r1377, 1;
	setp.ne.s32	%p25, %r1377, 0;
	@%p25 bra 	BB1_39;

	and.b32  	%r51, %r43, -2147483648;
	st.local.u32 	[%rd3], %r655;
	mov.u32 	%r659, 6;
	sub.s32 	%r660, %r659, %r46;
	mul.wide.s32 	%rd101, %r660, 4;
	add.s64 	%rd20, %rd1, %rd101;
	ld.local.u32 	%r1379, [%rd20];
	ld.local.u32 	%r1380, [%rd20+-4];
	and.b32  	%r54, %r44, 31;
	setp.eq.s32	%p26, %r54, 0;
	@%p26 bra 	BB1_42;

	mov.u32 	%r661, 32;
	sub.s32 	%r662, %r661, %r54;
	shr.u32 	%r663, %r1380, %r662;
	shl.b32 	%r664, %r1379, %r54;
	add.s32 	%r1379, %r663, %r664;
	ld.local.u32 	%r665, [%rd20+-8];
	shr.u32 	%r666, %r665, %r662;
	shl.b32 	%r667, %r1380, %r54;
	add.s32 	%r1380, %r666, %r667;

BB1_42:
	shr.u32 	%r668, %r1380, 30;
	shl.b32 	%r669, %r1379, 2;
	add.s32 	%r1381, %r668, %r669;
	shl.b32 	%r60, %r1380, 2;
	shr.u32 	%r670, %r1381, 31;
	shr.u32 	%r671, %r1379, 30;
	add.s32 	%r61, %r670, %r671;
	setp.eq.s32	%p27, %r670, 0;
	mov.u32 	%r1382, %r51;
	mov.u32 	%r1383, %r60;
	@%p27 bra 	BB1_44;

	not.b32 	%r672, %r1381;
	neg.s32 	%r62, %r60;
	setp.eq.s32	%p28, %r60, 0;
	selp.u32	%r673, 1, 0, %p28;
	add.s32 	%r1381, %r673, %r672;
	xor.b32  	%r64, %r51, -2147483648;
	mov.u32 	%r1382, %r64;
	mov.u32 	%r1383, %r62;

BB1_44:
	mov.u32 	%r66, %r1382;
	neg.s32 	%r674, %r61;
	setp.eq.s32	%p29, %r51, 0;
	selp.b32	%r1386, %r61, %r674, %p29;
	clz.b32 	%r1385, %r1381;
	setp.eq.s32	%p30, %r1385, 0;
	shl.b32 	%r675, %r1381, %r1385;
	mov.u32 	%r676, 32;
	sub.s32 	%r677, %r676, %r1385;
	shr.u32 	%r678, %r1383, %r677;
	add.s32 	%r679, %r678, %r675;
	selp.b32	%r70, %r1381, %r679, %p30;
	mov.u32 	%r680, -921707870;
	mul.hi.u32 	%r1384, %r70, %r680;
	setp.lt.s32	%p31, %r1384, 1;
	@%p31 bra 	BB1_46;

	mul.lo.s32 	%r681, %r70, -921707870;
	shr.u32 	%r682, %r681, 31;
	shl.b32 	%r683, %r1384, 1;
	add.s32 	%r1384, %r682, %r683;
	add.s32 	%r1385, %r1385, 1;

BB1_46:
	mov.u32 	%r684, 126;
	sub.s32 	%r685, %r684, %r1385;
	shl.b32 	%r686, %r685, 23;
	add.s32 	%r687, %r1384, 1;
	shr.u32 	%r688, %r687, 7;
	add.s32 	%r689, %r688, 1;
	shr.u32 	%r690, %r689, 1;
	add.s32 	%r691, %r690, %r686;
	or.b32  	%r692, %r691, %r66;
	mov.b32 	 %f1215, %r692;

BB1_47:
	mul.rn.f32 	%f39, %f1215, %f1215;
	add.s32 	%r77, %r1386, 1;
	and.b32  	%r78, %r77, 1;
	setp.eq.s32	%p32, %r78, 0;
	@%p32 bra 	BB1_49;

	mov.f32 	%f456, 0fBAB6061A;
	mov.f32 	%f457, 0f37CCF5CE;
	fma.rn.f32 	%f1216, %f457, %f39, %f456;
	bra.uni 	BB1_50;

BB1_49:
	mov.f32 	%f458, 0f3C08839E;
	mov.f32 	%f459, 0fB94CA1F9;
	fma.rn.f32 	%f1216, %f459, %f39, %f458;

BB1_50:
	@%p32 bra 	BB1_52;

	mov.f32 	%f460, 0f3D2AAAA5;
	fma.rn.f32 	%f461, %f1216, %f39, %f460;
	mov.f32 	%f462, 0fBF000000;
	fma.rn.f32 	%f1217, %f461, %f39, %f462;
	bra.uni 	BB1_53;

BB1_52:
	mov.f32 	%f463, 0fBE2AAAA3;
	fma.rn.f32 	%f464, %f1216, %f39, %f463;
	mov.f32 	%f465, 0f00000000;
	fma.rn.f32 	%f1217, %f464, %f39, %f465;

BB1_53:
	fma.rn.f32 	%f1218, %f1217, %f1215, %f1215;
	@%p32 bra 	BB1_55;

	mov.f32 	%f466, 0f3F800000;
	fma.rn.f32 	%f1218, %f1217, %f39, %f466;

BB1_55:
	and.b32  	%r693, %r77, 2;
	setp.eq.s32	%p35, %r693, 0;
	@%p35 bra 	BB1_57;

	mov.f32 	%f467, 0f00000000;
	mov.f32 	%f468, 0fBF800000;
	fma.rn.f32 	%f1218, %f1218, %f468, %f467;

BB1_57:
	abs.f32 	%f51, %f13;
	setp.neu.f32	%p36, %f51, 0f7F800000;
	mov.f32 	%f1225, %f13;
	@%p36 bra 	BB1_59;

	mov.f32 	%f469, 0f00000000;
	mul.rn.f32 	%f52, %f13, %f469;
	mov.f32 	%f1225, %f52;

BB1_59:
	mov.f32 	%f53, %f1225;
	mul.f32 	%f470, %f53, 0f3F22F983;
	cvt.rni.s32.f32	%r1396, %f470;
	cvt.rn.f32.s32	%f471, %r1396;
	neg.f32 	%f472, %f471;
	fma.rn.f32 	%f474, %f472, %f427, %f53;
	fma.rn.f32 	%f476, %f472, %f429, %f474;
	fma.rn.f32 	%f1219, %f472, %f431, %f476;
	abs.f32 	%f478, %f53;
	setp.leu.f32	%p37, %f478, 0f47CE4780;
	@%p37 bra 	BB1_69;

	mov.b32 	 %r80, %f53;
	shr.u32 	%r81, %r80, 23;
	bfe.u32 	%r696, %r80, 23, 8;
	add.s32 	%r697, %r696, -128;
	shl.b32 	%r698, %r80, 8;
	or.b32  	%r82, %r698, -2147483648;
	shr.u32 	%r83, %r697, 5;
	mov.u32 	%r1388, 0;
	mov.u64 	%rd133, __cudart_i2opi_f;
	mov.u32 	%r1387, -6;
	mov.u64 	%rd176, %rd1;

BB1_61:
	.pragma "nounroll";
	ld.const.u32 	%r701, [%rd133];
	// inline asm
	{
	mad.lo.cc.u32   %r699, %r701, %r82, %r1388;
	madc.hi.u32     %r700, %r701, %r82,  0;
	}
	// inline asm
	mov.u32 	%r1388, %r700;
	st.local.u32 	[%rd176], %r699;
	add.s64 	%rd176, %rd176, 4;
	add.s64 	%rd133, %rd133, 4;
	add.s32 	%r1387, %r1387, 1;
	setp.ne.s32	%p38, %r1387, 0;
	@%p38 bra 	BB1_61;

	and.b32  	%r88, %r80, -2147483648;
	st.local.u32 	[%rd3], %r700;
	mov.u32 	%r704, 6;
	sub.s32 	%r705, %r704, %r83;
	mul.wide.s32 	%rd103, %r705, 4;
	add.s64 	%rd26, %rd1, %rd103;
	ld.local.u32 	%r1389, [%rd26];
	ld.local.u32 	%r1390, [%rd26+-4];
	and.b32  	%r91, %r81, 31;
	setp.eq.s32	%p39, %r91, 0;
	@%p39 bra 	BB1_64;

	mov.u32 	%r706, 32;
	sub.s32 	%r707, %r706, %r91;
	shr.u32 	%r708, %r1390, %r707;
	shl.b32 	%r709, %r1389, %r91;
	add.s32 	%r1389, %r708, %r709;
	ld.local.u32 	%r710, [%rd26+-8];
	shr.u32 	%r711, %r710, %r707;
	shl.b32 	%r712, %r1390, %r91;
	add.s32 	%r1390, %r711, %r712;

BB1_64:
	shr.u32 	%r713, %r1390, 30;
	shl.b32 	%r714, %r1389, 2;
	add.s32 	%r1391, %r713, %r714;
	shl.b32 	%r97, %r1390, 2;
	shr.u32 	%r715, %r1391, 31;
	shr.u32 	%r716, %r1389, 30;
	add.s32 	%r98, %r715, %r716;
	setp.eq.s32	%p40, %r715, 0;
	mov.u32 	%r1392, %r88;
	mov.u32 	%r1393, %r97;
	@%p40 bra 	BB1_66;

	not.b32 	%r717, %r1391;
	neg.s32 	%r99, %r97;
	setp.eq.s32	%p41, %r97, 0;
	selp.u32	%r718, 1, 0, %p41;
	add.s32 	%r1391, %r718, %r717;
	xor.b32  	%r101, %r88, -2147483648;
	mov.u32 	%r1392, %r101;
	mov.u32 	%r1393, %r99;

BB1_66:
	mov.u32 	%r103, %r1392;
	neg.s32 	%r719, %r98;
	setp.eq.s32	%p42, %r88, 0;
	selp.b32	%r1396, %r98, %r719, %p42;
	clz.b32 	%r1395, %r1391;
	setp.eq.s32	%p43, %r1395, 0;
	shl.b32 	%r720, %r1391, %r1395;
	mov.u32 	%r721, 32;
	sub.s32 	%r722, %r721, %r1395;
	shr.u32 	%r723, %r1393, %r722;
	add.s32 	%r724, %r723, %r720;
	selp.b32	%r107, %r1391, %r724, %p43;
	mov.u32 	%r725, -921707870;
	mul.hi.u32 	%r1394, %r107, %r725;
	setp.lt.s32	%p44, %r1394, 1;
	@%p44 bra 	BB1_68;

	mul.lo.s32 	%r726, %r107, -921707870;
	shr.u32 	%r727, %r726, 31;
	shl.b32 	%r728, %r1394, 1;
	add.s32 	%r1394, %r727, %r728;
	add.s32 	%r1395, %r1395, 1;

BB1_68:
	mov.u32 	%r729, 126;
	sub.s32 	%r730, %r729, %r1395;
	shl.b32 	%r731, %r730, 23;
	add.s32 	%r732, %r1394, 1;
	shr.u32 	%r733, %r732, 7;
	add.s32 	%r734, %r733, 1;
	shr.u32 	%r735, %r734, 1;
	add.s32 	%r736, %r735, %r731;
	or.b32  	%r737, %r736, %r103;
	mov.b32 	 %f1219, %r737;

BB1_69:
	mul.rn.f32 	%f57, %f1219, %f1219;
	and.b32  	%r114, %r1396, 1;
	setp.eq.s32	%p45, %r114, 0;
	@%p45 bra 	BB1_71;

	mov.f32 	%f479, 0fBAB6061A;
	mov.f32 	%f480, 0f37CCF5CE;
	fma.rn.f32 	%f1220, %f480, %f57, %f479;
	bra.uni 	BB1_72;

BB1_71:
	mov.f32 	%f481, 0f3C08839E;
	mov.f32 	%f482, 0fB94CA1F9;
	fma.rn.f32 	%f1220, %f482, %f57, %f481;

BB1_72:
	@%p45 bra 	BB1_74;

	mov.f32 	%f483, 0f3D2AAAA5;
	fma.rn.f32 	%f484, %f1220, %f57, %f483;
	mov.f32 	%f485, 0fBF000000;
	fma.rn.f32 	%f1221, %f484, %f57, %f485;
	bra.uni 	BB1_75;

BB1_74:
	mov.f32 	%f486, 0fBE2AAAA3;
	fma.rn.f32 	%f487, %f1220, %f57, %f486;
	mov.f32 	%f488, 0f00000000;
	fma.rn.f32 	%f1221, %f487, %f57, %f488;

BB1_75:
	fma.rn.f32 	%f1222, %f1221, %f1219, %f1219;
	@%p45 bra 	BB1_77;

	mov.f32 	%f489, 0f3F800000;
	fma.rn.f32 	%f1222, %f1221, %f57, %f489;

BB1_77:
	and.b32  	%r738, %r1396, 2;
	setp.eq.s32	%p48, %r738, 0;
	@%p48 bra 	BB1_79;

	mov.f32 	%f490, 0f00000000;
	mov.f32 	%f491, 0fBF800000;
	fma.rn.f32 	%f1222, %f1222, %f491, %f490;

BB1_79:
	mov.f32 	%f1224, %f13;
	@%p36 bra 	BB1_81;

	mov.f32 	%f492, 0f00000000;
	mul.rn.f32 	%f1224, %f13, %f492;

BB1_81:
	mul.f32 	%f493, %f1224, 0f3F22F983;
	cvt.rni.s32.f32	%r1406, %f493;
	cvt.rn.f32.s32	%f494, %r1406;
	neg.f32 	%f495, %f494;
	fma.rn.f32 	%f497, %f495, %f427, %f1224;
	fma.rn.f32 	%f499, %f495, %f429, %f497;
	fma.rn.f32 	%f1226, %f495, %f431, %f499;
	abs.f32 	%f501, %f1224;
	setp.leu.f32	%p50, %f501, 0f47CE4780;
	@%p50 bra 	BB1_91;

	mov.b32 	 %r116, %f1224;
	shr.u32 	%r117, %r116, 23;
	bfe.u32 	%r741, %r116, 23, 8;
	add.s32 	%r742, %r741, -128;
	shl.b32 	%r743, %r116, 8;
	or.b32  	%r118, %r743, -2147483648;
	shr.u32 	%r119, %r742, 5;
	mov.u32 	%r1398, 0;
	mov.u64 	%rd134, __cudart_i2opi_f;
	mov.u32 	%r1397, -6;
	mov.u64 	%rd175, %rd1;

BB1_83:
	.pragma "nounroll";
	ld.const.u32 	%r746, [%rd134];
	// inline asm
	{
	mad.lo.cc.u32   %r744, %r746, %r118, %r1398;
	madc.hi.u32     %r745, %r746, %r118,  0;
	}
	// inline asm
	mov.u32 	%r1398, %r745;
	st.local.u32 	[%rd175], %r744;
	add.s64 	%rd175, %rd175, 4;
	add.s64 	%rd134, %rd134, 4;
	add.s32 	%r1397, %r1397, 1;
	setp.ne.s32	%p51, %r1397, 0;
	@%p51 bra 	BB1_83;

	and.b32  	%r124, %r116, -2147483648;
	st.local.u32 	[%rd3], %r745;
	mov.u32 	%r749, 6;
	sub.s32 	%r750, %r749, %r119;
	mul.wide.s32 	%rd105, %r750, 4;
	add.s64 	%rd32, %rd1, %rd105;
	ld.local.u32 	%r1399, [%rd32];
	ld.local.u32 	%r1400, [%rd32+-4];
	and.b32  	%r127, %r117, 31;
	setp.eq.s32	%p52, %r127, 0;
	@%p52 bra 	BB1_86;

	mov.u32 	%r751, 32;
	sub.s32 	%r752, %r751, %r127;
	shr.u32 	%r753, %r1400, %r752;
	shl.b32 	%r754, %r1399, %r127;
	add.s32 	%r1399, %r753, %r754;
	ld.local.u32 	%r755, [%rd32+-8];
	shr.u32 	%r756, %r755, %r752;
	shl.b32 	%r757, %r1400, %r127;
	add.s32 	%r1400, %r756, %r757;

BB1_86:
	shr.u32 	%r758, %r1400, 30;
	shl.b32 	%r759, %r1399, 2;
	add.s32 	%r1401, %r758, %r759;
	shl.b32 	%r133, %r1400, 2;
	shr.u32 	%r760, %r1401, 31;
	shr.u32 	%r761, %r1399, 30;
	add.s32 	%r134, %r760, %r761;
	setp.eq.s32	%p53, %r760, 0;
	mov.u32 	%r1402, %r124;
	mov.u32 	%r1403, %r133;
	@%p53 bra 	BB1_88;

	not.b32 	%r762, %r1401;
	neg.s32 	%r135, %r133;
	setp.eq.s32	%p54, %r133, 0;
	selp.u32	%r763, 1, 0, %p54;
	add.s32 	%r1401, %r763, %r762;
	xor.b32  	%r137, %r124, -2147483648;
	mov.u32 	%r1402, %r137;
	mov.u32 	%r1403, %r135;

BB1_88:
	mov.u32 	%r139, %r1402;
	neg.s32 	%r764, %r134;
	setp.eq.s32	%p55, %r124, 0;
	selp.b32	%r1406, %r134, %r764, %p55;
	clz.b32 	%r1405, %r1401;
	setp.eq.s32	%p56, %r1405, 0;
	shl.b32 	%r765, %r1401, %r1405;
	mov.u32 	%r766, 32;
	sub.s32 	%r767, %r766, %r1405;
	shr.u32 	%r768, %r1403, %r767;
	add.s32 	%r769, %r768, %r765;
	selp.b32	%r143, %r1401, %r769, %p56;
	mov.u32 	%r770, -921707870;
	mul.hi.u32 	%r1404, %r143, %r770;
	setp.lt.s32	%p57, %r1404, 1;
	@%p57 bra 	BB1_90;

	mul.lo.s32 	%r771, %r143, -921707870;
	shr.u32 	%r772, %r771, 31;
	shl.b32 	%r773, %r1404, 1;
	add.s32 	%r1404, %r772, %r773;
	add.s32 	%r1405, %r1405, 1;

BB1_90:
	mov.u32 	%r774, 126;
	sub.s32 	%r775, %r774, %r1405;
	shl.b32 	%r776, %r775, 23;
	add.s32 	%r777, %r1404, 1;
	shr.u32 	%r778, %r777, 7;
	add.s32 	%r779, %r778, 1;
	shr.u32 	%r780, %r779, 1;
	add.s32 	%r781, %r780, %r776;
	or.b32  	%r782, %r781, %r139;
	mov.b32 	 %f1226, %r782;

BB1_91:
	mul.rn.f32 	%f74, %f1226, %f1226;
	add.s32 	%r150, %r1406, 1;
	and.b32  	%r151, %r150, 1;
	setp.eq.s32	%p58, %r151, 0;
	@%p58 bra 	BB1_93;

	mov.f32 	%f502, 0fBAB6061A;
	mov.f32 	%f503, 0f37CCF5CE;
	fma.rn.f32 	%f1227, %f503, %f74, %f502;
	bra.uni 	BB1_94;

BB1_93:
	mov.f32 	%f504, 0f3C08839E;
	mov.f32 	%f505, 0fB94CA1F9;
	fma.rn.f32 	%f1227, %f505, %f74, %f504;

BB1_94:
	@%p58 bra 	BB1_96;

	mov.f32 	%f506, 0f3D2AAAA5;
	fma.rn.f32 	%f507, %f1227, %f74, %f506;
	mov.f32 	%f508, 0fBF000000;
	fma.rn.f32 	%f1228, %f507, %f74, %f508;
	bra.uni 	BB1_97;

BB1_96:
	mov.f32 	%f509, 0fBE2AAAA3;
	fma.rn.f32 	%f510, %f1227, %f74, %f509;
	mov.f32 	%f511, 0f00000000;
	fma.rn.f32 	%f1228, %f510, %f74, %f511;

BB1_97:
	fma.rn.f32 	%f1229, %f1228, %f1226, %f1226;
	@%p58 bra 	BB1_99;

	mov.f32 	%f512, 0f3F800000;
	fma.rn.f32 	%f1229, %f1228, %f74, %f512;

BB1_99:
	and.b32  	%r783, %r150, 2;
	setp.eq.s32	%p61, %r783, 0;
	@%p61 bra 	BB1_101;

	mov.f32 	%f513, 0f00000000;
	mov.f32 	%f514, 0fBF800000;
	fma.rn.f32 	%f1229, %f1229, %f514, %f513;

BB1_101:
	abs.f32 	%f86, %f14;
	setp.neu.f32	%p62, %f86, 0f7F800000;
	mov.f32 	%f1236, %f14;
	@%p62 bra 	BB1_103;

	mov.f32 	%f515, 0f00000000;
	mul.rn.f32 	%f87, %f14, %f515;
	mov.f32 	%f1236, %f87;

BB1_103:
	mov.f32 	%f88, %f1236;
	mul.f32 	%f516, %f88, 0f3F22F983;
	cvt.rni.s32.f32	%r1416, %f516;
	cvt.rn.f32.s32	%f517, %r1416;
	neg.f32 	%f518, %f517;
	fma.rn.f32 	%f520, %f518, %f427, %f88;
	fma.rn.f32 	%f522, %f518, %f429, %f520;
	fma.rn.f32 	%f1230, %f518, %f431, %f522;
	abs.f32 	%f524, %f88;
	setp.leu.f32	%p63, %f524, 0f47CE4780;
	@%p63 bra 	BB1_113;

	mov.b32 	 %r153, %f88;
	shl.b32 	%r786, %r153, 8;
	or.b32  	%r154, %r786, -2147483648;
	mov.u32 	%r1408, 0;
	mov.u64 	%rd135, __cudart_i2opi_f;
	mov.u32 	%r1407, -6;
	mov.u64 	%rd174, %rd1;

BB1_105:
	.pragma "nounroll";
	ld.const.u32 	%r789, [%rd135];
	// inline asm
	{
	mad.lo.cc.u32   %r787, %r789, %r154, %r1408;
	madc.hi.u32     %r788, %r789, %r154,  0;
	}
	// inline asm
	mov.u32 	%r1408, %r788;
	st.local.u32 	[%rd174], %r787;
	add.s64 	%rd174, %rd174, 4;
	add.s64 	%rd135, %rd135, 4;
	add.s32 	%r1407, %r1407, 1;
	setp.ne.s32	%p64, %r1407, 0;
	@%p64 bra 	BB1_105;

	and.b32  	%r159, %r153, -2147483648;
	bfe.u32 	%r792, %r153, 23, 8;
	add.s32 	%r793, %r792, -128;
	shr.u32 	%r794, %r793, 5;
	st.local.u32 	[%rd1+24], %r788;
	bfe.u32 	%r160, %r153, 23, 5;
	mov.u32 	%r795, 6;
	sub.s32 	%r796, %r795, %r794;
	mul.wide.s32 	%rd107, %r796, 4;
	add.s64 	%rd37, %rd1, %rd107;
	ld.local.u32 	%r1409, [%rd37];
	ld.local.u32 	%r1410, [%rd37+-4];
	setp.eq.s32	%p65, %r160, 0;
	@%p65 bra 	BB1_108;

	mov.u32 	%r797, 32;
	sub.s32 	%r798, %r797, %r160;
	shr.u32 	%r799, %r1410, %r798;
	shl.b32 	%r800, %r1409, %r160;
	add.s32 	%r1409, %r799, %r800;
	ld.local.u32 	%r801, [%rd37+-8];
	shr.u32 	%r802, %r801, %r798;
	shl.b32 	%r803, %r1410, %r160;
	add.s32 	%r1410, %r802, %r803;

BB1_108:
	shr.u32 	%r804, %r1410, 30;
	shl.b32 	%r805, %r1409, 2;
	add.s32 	%r1411, %r804, %r805;
	shl.b32 	%r168, %r1410, 2;
	shr.u32 	%r806, %r1411, 31;
	shr.u32 	%r807, %r1409, 30;
	add.s32 	%r169, %r806, %r807;
	setp.eq.s32	%p66, %r806, 0;
	mov.u32 	%r1412, %r159;
	mov.u32 	%r1413, %r168;
	@%p66 bra 	BB1_110;

	not.b32 	%r808, %r1411;
	neg.s32 	%r170, %r168;
	setp.eq.s32	%p67, %r168, 0;
	selp.u32	%r809, 1, 0, %p67;
	add.s32 	%r1411, %r809, %r808;
	xor.b32  	%r172, %r159, -2147483648;
	mov.u32 	%r1412, %r172;
	mov.u32 	%r1413, %r170;

BB1_110:
	mov.u32 	%r174, %r1412;
	neg.s32 	%r810, %r169;
	setp.eq.s32	%p68, %r159, 0;
	selp.b32	%r1416, %r169, %r810, %p68;
	clz.b32 	%r1415, %r1411;
	setp.eq.s32	%p69, %r1415, 0;
	shl.b32 	%r811, %r1411, %r1415;
	mov.u32 	%r812, 32;
	sub.s32 	%r813, %r812, %r1415;
	shr.u32 	%r814, %r1413, %r813;
	add.s32 	%r815, %r814, %r811;
	selp.b32	%r178, %r1411, %r815, %p69;
	mov.u32 	%r816, -921707870;
	mul.hi.u32 	%r1414, %r178, %r816;
	setp.lt.s32	%p70, %r1414, 1;
	@%p70 bra 	BB1_112;

	mul.lo.s32 	%r817, %r178, -921707870;
	shr.u32 	%r818, %r817, 31;
	shl.b32 	%r819, %r1414, 1;
	add.s32 	%r1414, %r818, %r819;
	add.s32 	%r1415, %r1415, 1;

BB1_112:
	mov.u32 	%r820, 126;
	sub.s32 	%r821, %r820, %r1415;
	shl.b32 	%r822, %r821, 23;
	add.s32 	%r823, %r1414, 1;
	shr.u32 	%r824, %r823, 7;
	add.s32 	%r825, %r824, 1;
	shr.u32 	%r826, %r825, 1;
	add.s32 	%r827, %r826, %r822;
	or.b32  	%r828, %r827, %r174;
	mov.b32 	 %f1230, %r828;

BB1_113:
	mul.rn.f32 	%f92, %f1230, %f1230;
	and.b32  	%r185, %r1416, 1;
	setp.eq.s32	%p71, %r185, 0;
	@%p71 bra 	BB1_115;

	mov.f32 	%f525, 0fBAB6061A;
	mov.f32 	%f526, 0f37CCF5CE;
	fma.rn.f32 	%f1231, %f526, %f92, %f525;
	bra.uni 	BB1_116;

BB1_115:
	mov.f32 	%f527, 0f3C08839E;
	mov.f32 	%f528, 0fB94CA1F9;
	fma.rn.f32 	%f1231, %f528, %f92, %f527;

BB1_116:
	@%p71 bra 	BB1_118;

	mov.f32 	%f529, 0f3D2AAAA5;
	fma.rn.f32 	%f530, %f1231, %f92, %f529;
	mov.f32 	%f531, 0fBF000000;
	fma.rn.f32 	%f1232, %f530, %f92, %f531;
	bra.uni 	BB1_119;

BB1_118:
	mov.f32 	%f532, 0fBE2AAAA3;
	fma.rn.f32 	%f533, %f1231, %f92, %f532;
	mov.f32 	%f534, 0f00000000;
	fma.rn.f32 	%f1232, %f533, %f92, %f534;

BB1_119:
	fma.rn.f32 	%f1233, %f1232, %f1230, %f1230;
	@%p71 bra 	BB1_121;

	mov.f32 	%f535, 0f3F800000;
	fma.rn.f32 	%f1233, %f1232, %f92, %f535;

BB1_121:
	and.b32  	%r829, %r1416, 2;
	setp.eq.s32	%p74, %r829, 0;
	@%p74 bra 	BB1_123;

	mov.f32 	%f536, 0f00000000;
	mov.f32 	%f537, 0fBF800000;
	fma.rn.f32 	%f1233, %f1233, %f537, %f536;

BB1_123:
	mov.f32 	%f1235, %f14;
	@%p62 bra 	BB1_125;

	mov.f32 	%f538, 0f00000000;
	mul.rn.f32 	%f1235, %f14, %f538;

BB1_125:
	mul.f32 	%f539, %f1235, 0f3F22F983;
	cvt.rni.s32.f32	%r1426, %f539;
	cvt.rn.f32.s32	%f540, %r1426;
	neg.f32 	%f541, %f540;
	fma.rn.f32 	%f543, %f541, %f427, %f1235;
	fma.rn.f32 	%f545, %f541, %f429, %f543;
	fma.rn.f32 	%f1237, %f541, %f431, %f545;
	abs.f32 	%f547, %f1235;
	setp.leu.f32	%p76, %f547, 0f47CE4780;
	@%p76 bra 	BB1_135;

	mov.b32 	 %r187, %f1235;
	shr.u32 	%r188, %r187, 23;
	bfe.u32 	%r832, %r187, 23, 8;
	add.s32 	%r833, %r832, -128;
	shl.b32 	%r834, %r187, 8;
	or.b32  	%r189, %r834, -2147483648;
	shr.u32 	%r190, %r833, 5;
	mov.u32 	%r1418, 0;
	mov.u64 	%rd136, __cudart_i2opi_f;
	mov.u32 	%r1417, -6;
	mov.u64 	%rd173, %rd1;

BB1_127:
	.pragma "nounroll";
	ld.const.u32 	%r837, [%rd136];
	// inline asm
	{
	mad.lo.cc.u32   %r835, %r837, %r189, %r1418;
	madc.hi.u32     %r836, %r837, %r189,  0;
	}
	// inline asm
	mov.u32 	%r1418, %r836;
	st.local.u32 	[%rd173], %r835;
	add.s64 	%rd173, %rd173, 4;
	add.s64 	%rd136, %rd136, 4;
	add.s32 	%r1417, %r1417, 1;
	setp.ne.s32	%p77, %r1417, 0;
	@%p77 bra 	BB1_127;

	and.b32  	%r195, %r187, -2147483648;
	st.local.u32 	[%rd1+24], %r836;
	mov.u32 	%r840, 6;
	sub.s32 	%r841, %r840, %r190;
	mul.wide.s32 	%rd109, %r841, 4;
	add.s64 	%rd43, %rd1, %rd109;
	ld.local.u32 	%r1419, [%rd43];
	ld.local.u32 	%r1420, [%rd43+-4];
	and.b32  	%r198, %r188, 31;
	setp.eq.s32	%p78, %r198, 0;
	@%p78 bra 	BB1_130;

	mov.u32 	%r842, 32;
	sub.s32 	%r843, %r842, %r198;
	shr.u32 	%r844, %r1420, %r843;
	shl.b32 	%r845, %r1419, %r198;
	add.s32 	%r1419, %r844, %r845;
	ld.local.u32 	%r846, [%rd43+-8];
	shr.u32 	%r847, %r846, %r843;
	shl.b32 	%r848, %r1420, %r198;
	add.s32 	%r1420, %r847, %r848;

BB1_130:
	shr.u32 	%r849, %r1420, 30;
	shl.b32 	%r850, %r1419, 2;
	add.s32 	%r1421, %r849, %r850;
	shl.b32 	%r204, %r1420, 2;
	shr.u32 	%r851, %r1421, 31;
	shr.u32 	%r852, %r1419, 30;
	add.s32 	%r205, %r851, %r852;
	setp.eq.s32	%p79, %r851, 0;
	mov.u32 	%r1422, %r195;
	mov.u32 	%r1423, %r204;
	@%p79 bra 	BB1_132;

	not.b32 	%r853, %r1421;
	neg.s32 	%r206, %r204;
	setp.eq.s32	%p80, %r204, 0;
	selp.u32	%r854, 1, 0, %p80;
	add.s32 	%r1421, %r854, %r853;
	xor.b32  	%r208, %r195, -2147483648;
	mov.u32 	%r1422, %r208;
	mov.u32 	%r1423, %r206;

BB1_132:
	mov.u32 	%r210, %r1422;
	neg.s32 	%r855, %r205;
	setp.eq.s32	%p81, %r195, 0;
	selp.b32	%r1426, %r205, %r855, %p81;
	clz.b32 	%r1425, %r1421;
	setp.eq.s32	%p82, %r1425, 0;
	shl.b32 	%r856, %r1421, %r1425;
	mov.u32 	%r857, 32;
	sub.s32 	%r858, %r857, %r1425;
	shr.u32 	%r859, %r1423, %r858;
	add.s32 	%r860, %r859, %r856;
	selp.b32	%r214, %r1421, %r860, %p82;
	mov.u32 	%r861, -921707870;
	mul.hi.u32 	%r1424, %r214, %r861;
	setp.lt.s32	%p83, %r1424, 1;
	@%p83 bra 	BB1_134;

	mul.lo.s32 	%r862, %r214, -921707870;
	shr.u32 	%r863, %r862, 31;
	shl.b32 	%r864, %r1424, 1;
	add.s32 	%r1424, %r863, %r864;
	add.s32 	%r1425, %r1425, 1;

BB1_134:
	mov.u32 	%r865, 126;
	sub.s32 	%r866, %r865, %r1425;
	shl.b32 	%r867, %r866, 23;
	add.s32 	%r868, %r1424, 1;
	shr.u32 	%r869, %r868, 7;
	add.s32 	%r870, %r869, 1;
	shr.u32 	%r871, %r870, 1;
	add.s32 	%r872, %r871, %r867;
	or.b32  	%r873, %r872, %r210;
	mov.b32 	 %f1237, %r873;

BB1_135:
	mul.rn.f32 	%f109, %f1237, %f1237;
	add.s32 	%r221, %r1426, 1;
	and.b32  	%r222, %r221, 1;
	setp.eq.s32	%p84, %r222, 0;
	@%p84 bra 	BB1_137;

	mov.f32 	%f548, 0fBAB6061A;
	mov.f32 	%f549, 0f37CCF5CE;
	fma.rn.f32 	%f1238, %f549, %f109, %f548;
	bra.uni 	BB1_138;

BB1_137:
	mov.f32 	%f550, 0f3C08839E;
	mov.f32 	%f551, 0fB94CA1F9;
	fma.rn.f32 	%f1238, %f551, %f109, %f550;

BB1_138:
	@%p84 bra 	BB1_140;

	mov.f32 	%f552, 0f3D2AAAA5;
	fma.rn.f32 	%f553, %f1238, %f109, %f552;
	mov.f32 	%f554, 0fBF000000;
	fma.rn.f32 	%f1239, %f553, %f109, %f554;
	bra.uni 	BB1_141;

BB1_140:
	mov.f32 	%f555, 0fBE2AAAA3;
	fma.rn.f32 	%f556, %f1238, %f109, %f555;
	mov.f32 	%f557, 0f00000000;
	fma.rn.f32 	%f1239, %f556, %f109, %f557;

BB1_141:
	fma.rn.f32 	%f1240, %f1239, %f1237, %f1237;
	@%p84 bra 	BB1_143;

	mov.f32 	%f558, 0f3F800000;
	fma.rn.f32 	%f1240, %f1239, %f109, %f558;

BB1_143:
	and.b32  	%r874, %r221, 2;
	setp.eq.s32	%p87, %r874, 0;
	@%p87 bra 	BB1_145;

	mov.f32 	%f559, 0f00000000;
	mov.f32 	%f560, 0fBF800000;
	fma.rn.f32 	%f1240, %f1240, %f560, %f559;

BB1_145:
	fma.rn.f32 	%f561, %f1218, 0f00000000, 0f3F800000;
	mov.f32 	%f562, 0f3F800000;
	sub.f32 	%f563, %f562, %f1218;
	mul.f32 	%f564, %f563, 0f00000000;
	mul.f32 	%f565, %f1211, 0f00000000;
	sub.f32 	%f566, %f564, %f565;
	add.f32 	%f567, %f565, %f564;
	add.f32 	%f568, %f1218, 0f00000000;
	sub.f32 	%f569, %f564, %f1211;
	add.f32 	%f570, %f1211, %f564;
	add.f32 	%f571, %f1229, 0f00000000;
	sub.f32 	%f572, %f562, %f1229;
	mul.f32 	%f573, %f572, 0f00000000;
	mul.f32 	%f574, %f1222, 0f00000000;
	sub.f32 	%f575, %f573, %f574;
	add.f32 	%f576, %f1222, %f573;
	add.f32 	%f577, %f574, %f573;
	fma.rn.f32 	%f578, %f1229, 0f00000000, 0f3F800000;
	sub.f32 	%f579, %f573, %f1222;
	sub.f32 	%f580, %f562, %f1240;
	mul.f32 	%f581, %f580, 0f00000000;
	sub.f32 	%f582, %f581, %f1233;
	mul.f32 	%f583, %f1233, 0f00000000;
	add.f32 	%f584, %f583, %f581;
	add.f32 	%f585, %f1233, %f581;
	sub.f32 	%f586, %f581, %f583;
	fma.rn.f32 	%f587, %f1240, 0f00000000, 0f3F800000;
	fma.rn.f32 	%f588, %f1242, %f561, 0f00000000;
	fma.rn.f32 	%f589, %f1245, %f567, %f588;
	fma.rn.f32 	%f590, %f1247, %f566, %f589;
	add.f32 	%f591, %f590, 0f00000000;
	fma.rn.f32 	%f592, %f1242, %f566, 0f00000000;
	fma.rn.f32 	%f593, %f1245, %f568, %f592;
	fma.rn.f32 	%f594, %f1247, %f570, %f593;
	add.f32 	%f595, %f594, 0f00000000;
	fma.rn.f32 	%f596, %f1242, %f567, 0f00000000;
	fma.rn.f32 	%f597, %f1245, %f569, %f596;
	fma.rn.f32 	%f598, %f1247, %f568, %f597;
	add.f32 	%f599, %f598, 0f00000000;
	fma.rn.f32 	%f600, %f1242, 0f00000000, 0f00000000;
	fma.rn.f32 	%f601, %f1245, 0f00000000, %f600;
	fma.rn.f32 	%f602, %f1247, 0f00000000, %f601;
	add.f32 	%f603, %f602, 0f3F800000;
	fma.rn.f32 	%f604, %f591, %f571, 0f00000000;
	fma.rn.f32 	%f605, %f595, %f577, %f604;
	fma.rn.f32 	%f606, %f599, %f579, %f605;
	fma.rn.f32 	%f607, %f603, 0f00000000, %f606;
	fma.rn.f32 	%f608, %f591, %f575, 0f00000000;
	fma.rn.f32 	%f609, %f595, %f578, %f608;
	fma.rn.f32 	%f610, %f599, %f577, %f609;
	fma.rn.f32 	%f611, %f603, 0f00000000, %f610;
	fma.rn.f32 	%f612, %f591, %f576, 0f00000000;
	fma.rn.f32 	%f613, %f595, %f575, %f612;
	fma.rn.f32 	%f614, %f599, %f571, %f613;
	fma.rn.f32 	%f615, %f603, 0f00000000, %f614;
	fma.rn.f32 	%f616, %f591, 0f00000000, 0f00000000;
	fma.rn.f32 	%f617, %f595, 0f00000000, %f616;
	fma.rn.f32 	%f618, %f599, 0f00000000, %f617;
	add.f32 	%f619, %f618, %f603;
	add.f32 	%f620, %f1240, 0f00000000;
	fma.rn.f32 	%f621, %f607, %f620, 0f00000000;
	fma.rn.f32 	%f622, %f611, %f585, %f621;
	fma.rn.f32 	%f623, %f615, %f586, %f622;
	fma.rn.f32 	%f1242, %f619, 0f00000000, %f623;
	fma.rn.f32 	%f624, %f607, %f582, 0f00000000;
	fma.rn.f32 	%f625, %f611, %f620, %f624;
	fma.rn.f32 	%f626, %f615, %f584, %f625;
	fma.rn.f32 	%f1245, %f619, 0f00000000, %f626;
	fma.rn.f32 	%f627, %f607, %f584, 0f00000000;
	fma.rn.f32 	%f628, %f611, %f586, %f627;
	fma.rn.f32 	%f629, %f615, %f587, %f628;
	fma.rn.f32 	%f1247, %f619, 0f00000000, %f629;

BB1_146:
	ld.u32 	%r1427, [%rd95+8];
	setp.eq.s32	%p88, %r1427, 0;
	mov.f32 	%f1315, 0f00000000;
	@%p88 bra 	BB1_422;

	mov.f32 	%f1249, %f1247;
	mov.f32 	%f1250, %f1245;
	mov.f32 	%f1251, %f1242;
	ld.f32 	%f132, [%rd95+36];
	ld.f32 	%f131, [%rd95+32];
	ld.f32 	%f130, [%rd95+28];
	add.f32 	%f633, %f130, 0fBF800000;
	abs.f32 	%f133, %f633;
	ld.f32 	%f136, [%rd95+72];
	ld.f32 	%f135, [%rd95+68];
	ld.f32 	%f134, [%rd95+64];
	abs.f32 	%f137, %f134;
	mov.f32 	%f1315, 0f00000000;
	mov.f32 	%f1248, 0f3F800000;
	bra.uni 	BB1_148;

BB1_302:
	setp.eq.f32	%p195, %f287, 0f7F800000;
	@%p195 bra 	BB1_312;
	bra.uni 	BB1_303;

BB1_312:
	setp.gt.f32	%p214, %f286, 0f3F800000;
	selp.f32	%f997, 0f7F800000, 0f00000000, %p214;
	setp.eq.f32	%p215, %f143, 0fBF800000;
	selp.f32	%f295, 0f3F800000, %f997, %p215;
	mov.f32 	%f1291, %f295;
	bra.uni 	BB1_314;

BB1_317:
	setp.eq.f32	%p219, %f300, 0f7F800000;
	@%p219 bra 	BB1_326;
	bra.uni 	BB1_318;

BB1_326:
	setp.gt.f32	%p239, %f299, 0f3F800000;
	selp.f32	%f1079, 0f7F800000, 0f00000000, %p239;
	setp.eq.f32	%p240, %f143, 0fBF800000;
	selp.f32	%f1290, 0f3F800000, %f1079, %p240;
	bra.uni 	BB1_328;

BB1_303:
	setp.eq.f32	%p196, %f286, 0f7F800000;
	@%p196 bra 	BB1_311;
	bra.uni 	BB1_304;

BB1_311:
	setp.eq.f32	%p211, %f285, 0f3F800000;
	setp.lt.f32	%p212, %f143, 0f00000000;
	and.pred  	%p213, %p212, %p211;
	selp.f32	%f294, 0fFF800000, 0f7F800000, %p213;
	mov.f32 	%f1291, %f294;
	bra.uni 	BB1_314;

BB1_318:
	setp.eq.f32	%p220, %f299, 0f7F800000;
	@%p220 bra 	BB1_325;
	bra.uni 	BB1_319;

BB1_325:
	setp.eq.f32	%p236, %f298, 0f3F800000;
	setp.lt.f32	%p237, %f143, 0f00000000;
	and.pred  	%p238, %p237, %p236;
	selp.f32	%f1290, 0fFF800000, 0f7F800000, %p238;
	bra.uni 	BB1_328;

BB1_304:
	setp.eq.f32	%p197, %f143, 0f00000000;
	@%p197 bra 	BB1_310;
	bra.uni 	BB1_305;

BB1_310:
	setp.eq.f32	%p210, %f285, 0f3F800000;
	add.f32 	%f996, %f143, %f143;
	selp.f32	%f293, %f996, 0f00000000, %p210;
	mov.f32 	%f1291, %f293;
	bra.uni 	BB1_314;

BB1_319:
	setp.eq.f32	%p221, %f143, 0f00000000;
	@%p221 bra 	BB1_324;
	bra.uni 	BB1_320;

BB1_324:
	setp.eq.f32	%p235, %f298, 0f3F800000;
	add.f32 	%f1078, %f143, %f143;
	selp.f32	%f1290, %f1078, 0f00000000, %p235;
	bra.uni 	BB1_328;

BB1_305:
	setp.geu.f32	%p198, %f143, 0f00000000;
	@%p198 bra 	BB1_307;

	cvt.rzi.f32.f32	%f921, %f916;
	setp.neu.f32	%p199, %f921, 0f40000000;
	mov.f32 	%f919, 0f7FFFFFFF;
	mov.f32 	%f1291, %f919;
	@%p199 bra 	BB1_314;

BB1_307:
	setp.lt.f32	%p200, %f286, 0f00800000;
	selp.f32	%f926, 0fC3170000, 0fC2FE0000, %p200;
	mul.f32 	%f927, %f286, 0f4B800000;
	selp.f32	%f928, %f927, %f286, %p200;
	mov.b32 	 %r1165, %f928;
	and.b32  	%r1166, %r1165, 8388607;
	or.b32  	%r1167, %r1166, 1065353216;
	mov.b32 	 %f929, %r1167;
	shr.u32 	%r1168, %r1165, 23;
	cvt.rn.f32.u32	%f930, %r1168;
	add.f32 	%f931, %f926, %f930;
	setp.gt.f32	%p201, %f929, 0f3FB504F3;
	mul.f32 	%f932, %f929, 0f3F000000;
	add.f32 	%f933, %f931, 0f3F800000;
	selp.f32	%f934, %f932, %f929, %p201;
	selp.f32	%f935, %f933, %f931, %p201;
	add.f32 	%f936, %f934, 0fBF800000;
	add.f32 	%f923, %f934, 0f3F800000;
	// inline asm
	rcp.approx.ftz.f32 %f922,%f923;
	// inline asm
	add.f32 	%f937, %f936, %f936;
	mul.f32 	%f938, %f937, %f922;
	mul.f32 	%f939, %f938, %f938;
	mov.f32 	%f940, 0f3C4CAF63;
	mov.f32 	%f941, 0f3B18F0FE;
	fma.rn.f32 	%f942, %f941, %f939, %f940;
	mov.f32 	%f943, 0f3DAAAABD;
	fma.rn.f32 	%f944, %f942, %f939, %f943;
	mul.rn.f32 	%f945, %f944, %f939;
	mul.rn.f32 	%f946, %f945, %f938;
	sub.f32 	%f947, %f936, %f938;
	add.f32 	%f948, %f947, %f947;
	neg.f32 	%f949, %f938;
	fma.rn.f32 	%f950, %f949, %f936, %f948;
	mul.rn.f32 	%f951, %f922, %f950;
	add.f32 	%f952, %f938, %f946;
	sub.f32 	%f953, %f938, %f952;
	add.f32 	%f954, %f946, %f953;
	add.f32 	%f955, %f951, %f954;
	add.f32 	%f956, %f952, %f955;
	sub.f32 	%f957, %f952, %f956;
	add.f32 	%f958, %f955, %f957;
	mov.f32 	%f959, 0f3F317200;
	mul.rn.f32 	%f960, %f935, %f959;
	mov.f32 	%f961, 0f35BFBE8E;
	mul.rn.f32 	%f962, %f935, %f961;
	add.f32 	%f963, %f960, %f956;
	sub.f32 	%f964, %f960, %f963;
	add.f32 	%f965, %f956, %f964;
	add.f32 	%f966, %f958, %f965;
	add.f32 	%f967, %f962, %f966;
	add.f32 	%f968, %f963, %f967;
	sub.f32 	%f969, %f963, %f968;
	add.f32 	%f970, %f967, %f969;
	setp.gt.f32	%p202, %f287, 0f77F684DF;
	selp.f32	%f971, 0f39800000, 0f40000000, %p202;
	mul.rn.f32 	%f972, %f971, %f968;
	neg.f32 	%f973, %f972;
	fma.rn.f32 	%f974, %f971, %f968, %f973;
	fma.rn.f32 	%f975, %f971, %f970, %f974;
	mov.f32 	%f976, 0f00000000;
	fma.rn.f32 	%f977, %f976, %f968, %f975;
	add.rn.f32 	%f978, %f972, %f977;
	neg.f32 	%f979, %f978;
	add.rn.f32 	%f980, %f972, %f979;
	add.rn.f32 	%f981, %f980, %f977;
	mov.b32 	 %r1169, %f978;
	setp.eq.s32	%p203, %r1169, 1118925336;
	add.s32 	%r1170, %r1169, -1;
	mov.b32 	 %f982, %r1170;
	add.f32 	%f983, %f981, 0f37000000;
	selp.f32	%f288, %f983, %f981, %p203;
	selp.f32	%f984, %f982, %f978, %p203;
	mul.f32 	%f985, %f984, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f986, %f985;
	mov.f32 	%f987, 0fBF317200;
	fma.rn.f32 	%f988, %f986, %f987, %f984;
	mov.f32 	%f989, 0fB5BFBE8E;
	fma.rn.f32 	%f990, %f986, %f989, %f988;
	mul.f32 	%f925, %f990, 0f3FB8AA3B;
	// inline asm
	ex2.approx.ftz.f32 %f924,%f925;
	// inline asm
	add.f32 	%f991, %f986, 0f00000000;
	ex2.approx.f32 	%f992, %f991;
	mul.f32 	%f993, %f924, %f992;
	setp.lt.f32	%p204, %f984, 0fC2D20000;
	selp.f32	%f994, 0f00000000, %f993, %p204;
	setp.gt.f32	%p205, %f984, 0f42D20000;
	selp.f32	%f1287, 0f7F800000, %f994, %p205;
	setp.eq.f32	%p206, %f1287, 0f7F800000;
	@%p206 bra 	BB1_309;

	fma.rn.f32 	%f1287, %f1287, %f288, %f1287;

BB1_309:
	setp.eq.f32	%p207, %f285, 0f3F800000;
	setp.lt.f32	%p208, %f143, 0f00000000;
	and.pred  	%p209, %p208, %p207;
	mov.b32 	 %r1171, %f1287;
	xor.b32  	%r1172, %r1171, -2147483648;
	mov.b32 	 %f995, %r1172;
	selp.f32	%f292, %f995, %f1287, %p209;
	mov.f32 	%f1291, %f292;
	bra.uni 	BB1_314;

BB1_320:
	mov.f32 	%f1203, 0f3F800000;
	cvt.rzi.f32.f32	%f1202, %f1203;
	setp.lt.f32	%p222, %f143, 0f00000000;
	setp.neu.f32	%p223, %f1202, 0f3F800000;
	and.pred  	%p224, %p222, %p223;
	mov.f32 	%f1290, 0f7FFFFFFF;
	@%p224 bra 	BB1_328;

	setp.lt.f32	%p225, %f299, 0f00800000;
	selp.f32	%f1008, 0fC3170000, 0fC2FE0000, %p225;
	mul.f32 	%f1009, %f299, 0f4B800000;
	selp.f32	%f1010, %f1009, %f299, %p225;
	mov.b32 	 %r1173, %f1010;
	and.b32  	%r1174, %r1173, 8388607;
	or.b32  	%r1175, %r1174, 1065353216;
	mov.b32 	 %f1011, %r1175;
	shr.u32 	%r1176, %r1173, 23;
	cvt.rn.f32.u32	%f1012, %r1176;
	add.f32 	%f1013, %f1008, %f1012;
	setp.gt.f32	%p226, %f1011, 0f3FB504F3;
	mul.f32 	%f1014, %f1011, 0f3F000000;
	add.f32 	%f1015, %f1013, 0f3F800000;
	selp.f32	%f1016, %f1014, %f1011, %p226;
	selp.f32	%f1017, %f1015, %f1013, %p226;
	add.f32 	%f1018, %f1016, 0fBF800000;
	add.f32 	%f1005, %f1016, 0f3F800000;
	// inline asm
	rcp.approx.ftz.f32 %f1004,%f1005;
	// inline asm
	add.f32 	%f1019, %f1018, %f1018;
	mul.f32 	%f1020, %f1019, %f1004;
	mul.f32 	%f1021, %f1020, %f1020;
	mov.f32 	%f1022, 0f3C4CAF63;
	mov.f32 	%f1023, 0f3B18F0FE;
	fma.rn.f32 	%f1024, %f1023, %f1021, %f1022;
	mov.f32 	%f1025, 0f3DAAAABD;
	fma.rn.f32 	%f1026, %f1024, %f1021, %f1025;
	mul.rn.f32 	%f1027, %f1026, %f1021;
	mul.rn.f32 	%f1028, %f1027, %f1020;
	sub.f32 	%f1029, %f1018, %f1020;
	add.f32 	%f1030, %f1029, %f1029;
	neg.f32 	%f1031, %f1020;
	fma.rn.f32 	%f1032, %f1031, %f1018, %f1030;
	mul.rn.f32 	%f1033, %f1004, %f1032;
	add.f32 	%f1034, %f1020, %f1028;
	sub.f32 	%f1035, %f1020, %f1034;
	add.f32 	%f1036, %f1028, %f1035;
	add.f32 	%f1037, %f1033, %f1036;
	add.f32 	%f1038, %f1034, %f1037;
	sub.f32 	%f1039, %f1034, %f1038;
	add.f32 	%f1040, %f1037, %f1039;
	mov.f32 	%f1041, 0f3F317200;
	mul.rn.f32 	%f1042, %f1017, %f1041;
	mov.f32 	%f1043, 0f35BFBE8E;
	mul.rn.f32 	%f1044, %f1017, %f1043;
	add.f32 	%f1045, %f1042, %f1038;
	sub.f32 	%f1046, %f1042, %f1045;
	add.f32 	%f1047, %f1038, %f1046;
	add.f32 	%f1048, %f1040, %f1047;
	add.f32 	%f1049, %f1044, %f1048;
	add.f32 	%f1050, %f1045, %f1049;
	sub.f32 	%f1051, %f1045, %f1050;
	add.f32 	%f1052, %f1049, %f1051;
	setp.gt.f32	%p227, %f300, 0f77F684DF;
	selp.f32	%f1053, 0f39000000, 0f3F800000, %p227;
	mul.rn.f32 	%f1054, %f1053, %f1050;
	neg.f32 	%f1055, %f1054;
	fma.rn.f32 	%f1056, %f1053, %f1050, %f1055;
	fma.rn.f32 	%f1057, %f1053, %f1052, %f1056;
	mov.f32 	%f1058, 0f00000000;
	fma.rn.f32 	%f1059, %f1058, %f1050, %f1057;
	add.rn.f32 	%f1060, %f1054, %f1059;
	neg.f32 	%f1061, %f1060;
	add.rn.f32 	%f1062, %f1054, %f1061;
	add.rn.f32 	%f1063, %f1062, %f1059;
	mov.b32 	 %r1177, %f1060;
	setp.eq.s32	%p228, %r1177, 1118925336;
	add.s32 	%r1178, %r1177, -1;
	mov.b32 	 %f1064, %r1178;
	add.f32 	%f1065, %f1063, 0f37000000;
	selp.f32	%f301, %f1065, %f1063, %p228;
	selp.f32	%f1066, %f1064, %f1060, %p228;
	mul.f32 	%f1067, %f1066, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f1068, %f1067;
	mov.f32 	%f1069, 0fBF317200;
	fma.rn.f32 	%f1070, %f1068, %f1069, %f1066;
	mov.f32 	%f1071, 0fB5BFBE8E;
	fma.rn.f32 	%f1072, %f1068, %f1071, %f1070;
	mul.f32 	%f1007, %f1072, 0f3FB8AA3B;
	// inline asm
	ex2.approx.ftz.f32 %f1006,%f1007;
	// inline asm
	add.f32 	%f1073, %f1068, 0f00000000;
	ex2.approx.f32 	%f1074, %f1073;
	mul.f32 	%f1075, %f1006, %f1074;
	setp.lt.f32	%p229, %f1066, 0fC2D20000;
	selp.f32	%f1076, 0f00000000, %f1075, %p229;
	setp.gt.f32	%p230, %f1066, 0f42D20000;
	selp.f32	%f1288, 0f7F800000, %f1076, %p230;
	setp.eq.f32	%p231, %f1288, 0f7F800000;
	@%p231 bra 	BB1_323;

	fma.rn.f32 	%f1288, %f1288, %f301, %f1288;

BB1_323:
	setp.eq.f32	%p232, %f298, 0f3F800000;
	and.pred  	%p234, %p222, %p232;
	mov.b32 	 %r1179, %f1288;
	xor.b32  	%r1180, %r1179, -2147483648;
	mov.b32 	 %f1077, %r1180;
	selp.f32	%f1290, %f1077, %f1288, %p234;
	bra.uni 	BB1_328;

BB1_148:
	add.s32 	%r1427, %r1427, -1;
	mul.f32 	%f634, %f1250, %f1250;
	fma.rn.f32 	%f635, %f1251, %f1251, %f634;
	fma.rn.f32 	%f636, %f1249, %f1249, %f635;
	sqrt.rn.f32 	%f143, %f636;
	setp.geu.f32	%p89, %f133, 0f38D1B717;
	@%p89 bra 	BB1_151;

	add.f32 	%f637, %f131, 0fBF800000;
	abs.f32 	%f638, %f637;
	setp.geu.f32	%p90, %f638, 0f38D1B717;
	@%p90 bra 	BB1_151;

	mov.f32 	%f1284, %f1249;
	mov.f32 	%f1283, %f1250;
	mov.f32 	%f1282, %f1251;
	add.f32 	%f639, %f132, 0fBF800000;
	abs.f32 	%f640, %f639;
	setp.lt.f32	%p91, %f640, 0f38D1B717;
	@%p91 bra 	BB1_152;

BB1_151:
	fma.rn.f32 	%f641, %f1251, %f130, 0f00000000;
	fma.rn.f32 	%f642, %f1250, 0f00000000, %f641;
	fma.rn.f32 	%f643, %f1249, 0f00000000, %f642;
	add.f32 	%f1282, %f643, 0f00000000;
	fma.rn.f32 	%f644, %f1251, 0f00000000, 0f00000000;
	fma.rn.f32 	%f645, %f1250, %f131, %f644;
	fma.rn.f32 	%f646, %f1249, 0f00000000, %f645;
	add.f32 	%f1283, %f646, 0f00000000;
	fma.rn.f32 	%f647, %f1250, 0f00000000, %f644;
	fma.rn.f32 	%f648, %f1249, %f132, %f647;
	add.f32 	%f1284, %f648, 0f00000000;

BB1_152:
	setp.geu.f32	%p92, %f137, 0f38D1B717;
	@%p92 bra 	BB1_155;

	abs.f32 	%f649, %f135;
	setp.geu.f32	%p93, %f649, 0f38D1B717;
	@%p93 bra 	BB1_155;

	abs.f32 	%f650, %f136;
	setp.lt.f32	%p94, %f650, 0f38D1B717;
	@%p94 bra 	BB1_288;

BB1_155:
	mov.f32 	%f1252, %f134;
	setp.neu.f32	%p95, %f137, 0f7F800000;
	@%p95 bra 	BB1_157;

	mov.f32 	%f651, 0f00000000;
	mul.rn.f32 	%f1252, %f134, %f651;

BB1_157:
	mul.f32 	%f652, %f1252, 0f3F22F983;
	cvt.rni.s32.f32	%r1437, %f652;
	cvt.rn.f32.s32	%f653, %r1437;
	neg.f32 	%f654, %f653;
	mov.f32 	%f655, 0f3FC90FDA;
	fma.rn.f32 	%f656, %f654, %f655, %f1252;
	mov.f32 	%f657, 0f33A22168;
	fma.rn.f32 	%f658, %f654, %f657, %f656;
	mov.f32 	%f659, 0f27C234C5;
	fma.rn.f32 	%f1253, %f654, %f659, %f658;
	abs.f32 	%f660, %f1252;
	setp.leu.f32	%p96, %f660, 0f47CE4780;
	@%p96 bra 	BB1_167;

	mov.b32 	 %r227, %f1252;
	shr.u32 	%r228, %r227, 23;
	bfe.u32 	%r877, %r227, 23, 8;
	add.s32 	%r878, %r877, -128;
	shl.b32 	%r879, %r227, 8;
	or.b32  	%r229, %r879, -2147483648;
	shr.u32 	%r230, %r878, 5;
	mov.u32 	%r1429, 0;
	mov.u64 	%rd137, __cudart_i2opi_f;
	mov.u32 	%r1428, -6;
	mov.u64 	%rd172, %rd1;

BB1_159:
	.pragma "nounroll";
	mov.u64 	%rd46, %rd172;
	ld.const.u32 	%r882, [%rd137];
	// inline asm
	{
	mad.lo.cc.u32   %r880, %r882, %r229, %r1429;
	madc.hi.u32     %r881, %r882, %r229,  0;
	}
	// inline asm
	mov.u32 	%r1429, %r881;
	st.local.u32 	[%rd46], %r880;
	add.s64 	%rd47, %rd46, 4;
	add.s64 	%rd137, %rd137, 4;
	add.s32 	%r1428, %r1428, 1;
	setp.ne.s32	%p97, %r1428, 0;
	mov.u64 	%rd172, %rd47;
	@%p97 bra 	BB1_159;

	and.b32  	%r235, %r227, -2147483648;
	st.local.u32 	[%rd1+24], %r881;
	mov.u32 	%r885, 6;
	sub.s32 	%r886, %r885, %r230;
	mul.wide.s32 	%rd111, %r886, 4;
	add.s64 	%rd49, %rd1, %rd111;
	ld.local.u32 	%r1430, [%rd49];
	ld.local.u32 	%r1431, [%rd49+-4];
	and.b32  	%r238, %r228, 31;
	setp.eq.s32	%p98, %r238, 0;
	@%p98 bra 	BB1_162;

	mov.u32 	%r887, 32;
	sub.s32 	%r888, %r887, %r238;
	shr.u32 	%r889, %r1431, %r888;
	shl.b32 	%r890, %r1430, %r238;
	add.s32 	%r1430, %r889, %r890;
	ld.local.u32 	%r891, [%rd49+-8];
	shr.u32 	%r892, %r891, %r888;
	shl.b32 	%r893, %r1431, %r238;
	add.s32 	%r1431, %r892, %r893;

BB1_162:
	shr.u32 	%r894, %r1431, 30;
	shl.b32 	%r895, %r1430, 2;
	add.s32 	%r1432, %r894, %r895;
	shl.b32 	%r244, %r1431, 2;
	shr.u32 	%r896, %r1432, 31;
	shr.u32 	%r897, %r1430, 30;
	add.s32 	%r245, %r896, %r897;
	setp.eq.s32	%p99, %r896, 0;
	mov.u32 	%r1433, %r235;
	mov.u32 	%r1434, %r244;
	@%p99 bra 	BB1_164;

	not.b32 	%r898, %r1432;
	neg.s32 	%r246, %r244;
	setp.eq.s32	%p100, %r244, 0;
	selp.u32	%r899, 1, 0, %p100;
	add.s32 	%r1432, %r899, %r898;
	xor.b32  	%r248, %r235, -2147483648;
	mov.u32 	%r1433, %r248;
	mov.u32 	%r1434, %r246;

BB1_164:
	mov.u32 	%r250, %r1433;
	neg.s32 	%r900, %r245;
	setp.eq.s32	%p101, %r235, 0;
	selp.b32	%r1437, %r245, %r900, %p101;
	clz.b32 	%r1436, %r1432;
	setp.eq.s32	%p102, %r1436, 0;
	shl.b32 	%r901, %r1432, %r1436;
	mov.u32 	%r902, 32;
	sub.s32 	%r903, %r902, %r1436;
	shr.u32 	%r904, %r1434, %r903;
	add.s32 	%r905, %r904, %r901;
	selp.b32	%r254, %r1432, %r905, %p102;
	mov.u32 	%r906, -921707870;
	mul.hi.u32 	%r1435, %r254, %r906;
	setp.lt.s32	%p103, %r1435, 1;
	@%p103 bra 	BB1_166;

	mul.lo.s32 	%r907, %r254, -921707870;
	shr.u32 	%r908, %r907, 31;
	shl.b32 	%r909, %r1435, 1;
	add.s32 	%r1435, %r908, %r909;
	add.s32 	%r1436, %r1436, 1;

BB1_166:
	mov.u32 	%r910, 126;
	sub.s32 	%r911, %r910, %r1436;
	shl.b32 	%r912, %r911, 23;
	add.s32 	%r913, %r1435, 1;
	shr.u32 	%r914, %r913, 7;
	add.s32 	%r915, %r914, 1;
	shr.u32 	%r916, %r915, 1;
	add.s32 	%r917, %r916, %r912;
	or.b32  	%r918, %r917, %r250;
	mov.b32 	 %f1253, %r918;

BB1_167:
	mul.rn.f32 	%f159, %f1253, %f1253;
	and.b32  	%r261, %r1437, 1;
	setp.eq.s32	%p104, %r261, 0;
	@%p104 bra 	BB1_169;
	bra.uni 	BB1_168;

BB1_169:
	mov.f32 	%f663, 0f3C08839E;
	mov.f32 	%f664, 0fB94CA1F9;
	fma.rn.f32 	%f1254, %f664, %f159, %f663;
	bra.uni 	BB1_170;

BB1_168:
	mov.f32 	%f661, 0fBAB6061A;
	mov.f32 	%f662, 0f37CCF5CE;
	fma.rn.f32 	%f1254, %f662, %f159, %f661;

BB1_170:
	@%p104 bra 	BB1_172;
	bra.uni 	BB1_171;

BB1_172:
	mov.f32 	%f668, 0fBE2AAAA3;
	fma.rn.f32 	%f669, %f1254, %f159, %f668;
	mov.f32 	%f670, 0f00000000;
	fma.rn.f32 	%f1255, %f669, %f159, %f670;
	bra.uni 	BB1_173;

BB1_171:
	mov.f32 	%f665, 0f3D2AAAA5;
	fma.rn.f32 	%f666, %f1254, %f159, %f665;
	mov.f32 	%f667, 0fBF000000;
	fma.rn.f32 	%f1255, %f666, %f159, %f667;

BB1_173:
	fma.rn.f32 	%f1256, %f1255, %f1253, %f1253;
	@%p104 bra 	BB1_175;

	mov.f32 	%f671, 0f3F800000;
	fma.rn.f32 	%f1256, %f1255, %f159, %f671;

BB1_175:
	and.b32  	%r919, %r1437, 2;
	setp.eq.s32	%p107, %r919, 0;
	@%p107 bra 	BB1_177;

	mov.f32 	%f672, 0f00000000;
	mov.f32 	%f673, 0fBF800000;
	fma.rn.f32 	%f1256, %f1256, %f673, %f672;

BB1_177:
	mov.f32 	%f1257, %f134;
	@%p95 bra 	BB1_179;

	mov.f32 	%f674, 0f00000000;
	mul.rn.f32 	%f1257, %f134, %f674;

BB1_179:
	mul.f32 	%f675, %f1257, 0f3F22F983;
	cvt.rni.s32.f32	%r1447, %f675;
	cvt.rn.f32.s32	%f676, %r1447;
	neg.f32 	%f677, %f676;
	fma.rn.f32 	%f679, %f677, %f655, %f1257;
	fma.rn.f32 	%f681, %f677, %f657, %f679;
	fma.rn.f32 	%f1258, %f677, %f659, %f681;
	abs.f32 	%f683, %f1257;
	setp.leu.f32	%p109, %f683, 0f47CE4780;
	@%p109 bra 	BB1_189;

	mov.b32 	 %r263, %f1257;
	shr.u32 	%r264, %r263, 23;
	bfe.u32 	%r922, %r263, 23, 8;
	add.s32 	%r923, %r922, -128;
	shl.b32 	%r924, %r263, 8;
	or.b32  	%r265, %r924, -2147483648;
	shr.u32 	%r266, %r923, 5;
	mov.u32 	%r1439, 0;
	mov.u64 	%rd138, __cudart_i2opi_f;
	mov.u32 	%r1438, -6;
	mov.u64 	%rd171, %rd1;

BB1_181:
	.pragma "nounroll";
	ld.const.u32 	%r927, [%rd138];
	// inline asm
	{
	mad.lo.cc.u32   %r925, %r927, %r265, %r1439;
	madc.hi.u32     %r926, %r927, %r265,  0;
	}
	// inline asm
	mov.u32 	%r1439, %r926;
	st.local.u32 	[%rd171], %r925;
	add.s64 	%rd171, %rd171, 4;
	add.s64 	%rd138, %rd138, 4;
	add.s32 	%r1438, %r1438, 1;
	setp.ne.s32	%p110, %r1438, 0;
	@%p110 bra 	BB1_181;

	and.b32  	%r271, %r263, -2147483648;
	st.local.u32 	[%rd1+24], %r926;
	mov.u32 	%r930, 6;
	sub.s32 	%r931, %r930, %r266;
	mul.wide.s32 	%rd113, %r931, 4;
	add.s64 	%rd54, %rd1, %rd113;
	ld.local.u32 	%r1440, [%rd54];
	ld.local.u32 	%r1441, [%rd54+-4];
	and.b32  	%r274, %r264, 31;
	setp.eq.s32	%p111, %r274, 0;
	@%p111 bra 	BB1_184;

	mov.u32 	%r932, 32;
	sub.s32 	%r933, %r932, %r274;
	shr.u32 	%r934, %r1441, %r933;
	shl.b32 	%r935, %r1440, %r274;
	add.s32 	%r1440, %r934, %r935;
	ld.local.u32 	%r936, [%rd54+-8];
	shr.u32 	%r937, %r936, %r933;
	shl.b32 	%r938, %r1441, %r274;
	add.s32 	%r1441, %r937, %r938;

BB1_184:
	shr.u32 	%r939, %r1441, 30;
	shl.b32 	%r940, %r1440, 2;
	add.s32 	%r1442, %r939, %r940;
	shl.b32 	%r280, %r1441, 2;
	shr.u32 	%r941, %r1442, 31;
	shr.u32 	%r942, %r1440, 30;
	add.s32 	%r281, %r941, %r942;
	setp.eq.s32	%p112, %r941, 0;
	mov.u32 	%r1443, %r271;
	mov.u32 	%r1444, %r280;
	@%p112 bra 	BB1_186;

	not.b32 	%r943, %r1442;
	neg.s32 	%r282, %r280;
	setp.eq.s32	%p113, %r280, 0;
	selp.u32	%r944, 1, 0, %p113;
	add.s32 	%r1442, %r944, %r943;
	xor.b32  	%r284, %r271, -2147483648;
	mov.u32 	%r1443, %r284;
	mov.u32 	%r1444, %r282;

BB1_186:
	mov.u32 	%r286, %r1443;
	neg.s32 	%r945, %r281;
	setp.eq.s32	%p114, %r271, 0;
	selp.b32	%r1447, %r281, %r945, %p114;
	clz.b32 	%r1446, %r1442;
	setp.eq.s32	%p115, %r1446, 0;
	shl.b32 	%r946, %r1442, %r1446;
	mov.u32 	%r947, 32;
	sub.s32 	%r948, %r947, %r1446;
	shr.u32 	%r949, %r1444, %r948;
	add.s32 	%r950, %r949, %r946;
	selp.b32	%r290, %r1442, %r950, %p115;
	mov.u32 	%r951, -921707870;
	mul.hi.u32 	%r1445, %r290, %r951;
	setp.lt.s32	%p116, %r1445, 1;
	@%p116 bra 	BB1_188;

	mul.lo.s32 	%r952, %r290, -921707870;
	shr.u32 	%r953, %r952, 31;
	shl.b32 	%r954, %r1445, 1;
	add.s32 	%r1445, %r953, %r954;
	add.s32 	%r1446, %r1446, 1;

BB1_188:
	mov.u32 	%r955, 126;
	sub.s32 	%r956, %r955, %r1446;
	shl.b32 	%r957, %r956, 23;
	add.s32 	%r958, %r1445, 1;
	shr.u32 	%r959, %r958, 7;
	add.s32 	%r960, %r959, 1;
	shr.u32 	%r961, %r960, 1;
	add.s32 	%r962, %r961, %r957;
	or.b32  	%r963, %r962, %r286;
	mov.b32 	 %f1258, %r963;

BB1_189:
	mul.rn.f32 	%f177, %f1258, %f1258;
	add.s32 	%r297, %r1447, 1;
	and.b32  	%r298, %r297, 1;
	setp.eq.s32	%p117, %r298, 0;
	@%p117 bra 	BB1_191;
	bra.uni 	BB1_190;

BB1_191:
	mov.f32 	%f686, 0f3C08839E;
	mov.f32 	%f687, 0fB94CA1F9;
	fma.rn.f32 	%f1259, %f687, %f177, %f686;
	bra.uni 	BB1_192;

BB1_190:
	mov.f32 	%f684, 0fBAB6061A;
	mov.f32 	%f685, 0f37CCF5CE;
	fma.rn.f32 	%f1259, %f685, %f177, %f684;

BB1_192:
	@%p117 bra 	BB1_194;
	bra.uni 	BB1_193;

BB1_194:
	mov.f32 	%f691, 0fBE2AAAA3;
	fma.rn.f32 	%f692, %f1259, %f177, %f691;
	mov.f32 	%f693, 0f00000000;
	fma.rn.f32 	%f1260, %f692, %f177, %f693;
	bra.uni 	BB1_195;

BB1_193:
	mov.f32 	%f688, 0f3D2AAAA5;
	fma.rn.f32 	%f689, %f1259, %f177, %f688;
	mov.f32 	%f690, 0fBF000000;
	fma.rn.f32 	%f1260, %f689, %f177, %f690;

BB1_195:
	fma.rn.f32 	%f1261, %f1260, %f1258, %f1258;
	@%p117 bra 	BB1_197;

	mov.f32 	%f694, 0f3F800000;
	fma.rn.f32 	%f1261, %f1260, %f177, %f694;

BB1_197:
	and.b32  	%r964, %r297, 2;
	setp.eq.s32	%p120, %r964, 0;
	@%p120 bra 	BB1_199;

	mov.f32 	%f695, 0f00000000;
	mov.f32 	%f696, 0fBF800000;
	fma.rn.f32 	%f1261, %f1261, %f696, %f695;

BB1_199:
	mov.f32 	%f1262, %f135;
	abs.f32 	%f190, %f135;
	setp.neu.f32	%p121, %f190, 0f7F800000;
	@%p121 bra 	BB1_201;

	mov.f32 	%f697, 0f00000000;
	mul.rn.f32 	%f1262, %f135, %f697;

BB1_201:
	mul.f32 	%f698, %f1262, 0f3F22F983;
	cvt.rni.s32.f32	%r1457, %f698;
	cvt.rn.f32.s32	%f699, %r1457;
	neg.f32 	%f700, %f699;
	fma.rn.f32 	%f702, %f700, %f655, %f1262;
	fma.rn.f32 	%f704, %f700, %f657, %f702;
	fma.rn.f32 	%f1263, %f700, %f659, %f704;
	abs.f32 	%f706, %f1262;
	setp.leu.f32	%p122, %f706, 0f47CE4780;
	@%p122 bra 	BB1_211;

	mov.b32 	 %r300, %f1262;
	shr.u32 	%r301, %r300, 23;
	bfe.u32 	%r967, %r300, 23, 8;
	add.s32 	%r968, %r967, -128;
	shl.b32 	%r969, %r300, 8;
	or.b32  	%r302, %r969, -2147483648;
	shr.u32 	%r303, %r968, 5;
	mov.u32 	%r1449, 0;
	mov.u64 	%rd139, __cudart_i2opi_f;
	mov.u32 	%r1448, -6;
	mov.u64 	%rd170, %rd1;

BB1_203:
	.pragma "nounroll";
	ld.const.u32 	%r972, [%rd139];
	// inline asm
	{
	mad.lo.cc.u32   %r970, %r972, %r302, %r1449;
	madc.hi.u32     %r971, %r972, %r302,  0;
	}
	// inline asm
	mov.u32 	%r1449, %r971;
	st.local.u32 	[%rd170], %r970;
	add.s64 	%rd170, %rd170, 4;
	add.s64 	%rd139, %rd139, 4;
	add.s32 	%r1448, %r1448, 1;
	setp.ne.s32	%p123, %r1448, 0;
	@%p123 bra 	BB1_203;

	and.b32  	%r308, %r300, -2147483648;
	st.local.u32 	[%rd1+24], %r971;
	mov.u32 	%r975, 6;
	sub.s32 	%r976, %r975, %r303;
	mul.wide.s32 	%rd115, %r976, 4;
	add.s64 	%rd59, %rd1, %rd115;
	ld.local.u32 	%r1450, [%rd59];
	ld.local.u32 	%r1451, [%rd59+-4];
	and.b32  	%r311, %r301, 31;
	setp.eq.s32	%p124, %r311, 0;
	@%p124 bra 	BB1_206;

	mov.u32 	%r977, 32;
	sub.s32 	%r978, %r977, %r311;
	shr.u32 	%r979, %r1451, %r978;
	shl.b32 	%r980, %r1450, %r311;
	add.s32 	%r1450, %r979, %r980;
	ld.local.u32 	%r981, [%rd59+-8];
	shr.u32 	%r982, %r981, %r978;
	shl.b32 	%r983, %r1451, %r311;
	add.s32 	%r1451, %r982, %r983;

BB1_206:
	shr.u32 	%r984, %r1451, 30;
	shl.b32 	%r985, %r1450, 2;
	add.s32 	%r1452, %r984, %r985;
	shl.b32 	%r317, %r1451, 2;
	shr.u32 	%r986, %r1452, 31;
	shr.u32 	%r987, %r1450, 30;
	add.s32 	%r318, %r986, %r987;
	setp.eq.s32	%p125, %r986, 0;
	mov.u32 	%r1453, %r308;
	mov.u32 	%r1454, %r317;
	@%p125 bra 	BB1_208;

	not.b32 	%r988, %r1452;
	neg.s32 	%r319, %r317;
	setp.eq.s32	%p126, %r317, 0;
	selp.u32	%r989, 1, 0, %p126;
	add.s32 	%r1452, %r989, %r988;
	xor.b32  	%r321, %r308, -2147483648;
	mov.u32 	%r1453, %r321;
	mov.u32 	%r1454, %r319;

BB1_208:
	mov.u32 	%r323, %r1453;
	neg.s32 	%r990, %r318;
	setp.eq.s32	%p127, %r308, 0;
	selp.b32	%r1457, %r318, %r990, %p127;
	clz.b32 	%r1456, %r1452;
	setp.eq.s32	%p128, %r1456, 0;
	shl.b32 	%r991, %r1452, %r1456;
	mov.u32 	%r992, 32;
	sub.s32 	%r993, %r992, %r1456;
	shr.u32 	%r994, %r1454, %r993;
	add.s32 	%r995, %r994, %r991;
	selp.b32	%r327, %r1452, %r995, %p128;
	mov.u32 	%r996, -921707870;
	mul.hi.u32 	%r1455, %r327, %r996;
	setp.lt.s32	%p129, %r1455, 1;
	@%p129 bra 	BB1_210;

	mul.lo.s32 	%r997, %r327, -921707870;
	shr.u32 	%r998, %r997, 31;
	shl.b32 	%r999, %r1455, 1;
	add.s32 	%r1455, %r998, %r999;
	add.s32 	%r1456, %r1456, 1;

BB1_210:
	mov.u32 	%r1000, 126;
	sub.s32 	%r1001, %r1000, %r1456;
	shl.b32 	%r1002, %r1001, 23;
	add.s32 	%r1003, %r1455, 1;
	shr.u32 	%r1004, %r1003, 7;
	add.s32 	%r1005, %r1004, 1;
	shr.u32 	%r1006, %r1005, 1;
	add.s32 	%r1007, %r1006, %r1002;
	or.b32  	%r1008, %r1007, %r323;
	mov.b32 	 %f1263, %r1008;

BB1_211:
	mul.rn.f32 	%f196, %f1263, %f1263;
	and.b32  	%r334, %r1457, 1;
	setp.eq.s32	%p130, %r334, 0;
	@%p130 bra 	BB1_213;
	bra.uni 	BB1_212;

BB1_213:
	mov.f32 	%f709, 0f3C08839E;
	mov.f32 	%f710, 0fB94CA1F9;
	fma.rn.f32 	%f1264, %f710, %f196, %f709;
	bra.uni 	BB1_214;

BB1_212:
	mov.f32 	%f707, 0fBAB6061A;
	mov.f32 	%f708, 0f37CCF5CE;
	fma.rn.f32 	%f1264, %f708, %f196, %f707;

BB1_214:
	@%p130 bra 	BB1_216;
	bra.uni 	BB1_215;

BB1_216:
	mov.f32 	%f714, 0fBE2AAAA3;
	fma.rn.f32 	%f715, %f1264, %f196, %f714;
	mov.f32 	%f716, 0f00000000;
	fma.rn.f32 	%f1265, %f715, %f196, %f716;
	bra.uni 	BB1_217;

BB1_215:
	mov.f32 	%f711, 0f3D2AAAA5;
	fma.rn.f32 	%f712, %f1264, %f196, %f711;
	mov.f32 	%f713, 0fBF000000;
	fma.rn.f32 	%f1265, %f712, %f196, %f713;

BB1_217:
	fma.rn.f32 	%f1266, %f1265, %f1263, %f1263;
	@%p130 bra 	BB1_219;

	mov.f32 	%f717, 0f3F800000;
	fma.rn.f32 	%f1266, %f1265, %f196, %f717;

BB1_219:
	and.b32  	%r1009, %r1457, 2;
	setp.eq.s32	%p133, %r1009, 0;
	@%p133 bra 	BB1_221;

	mov.f32 	%f718, 0f00000000;
	mov.f32 	%f719, 0fBF800000;
	fma.rn.f32 	%f1266, %f1266, %f719, %f718;

BB1_221:
	mov.f32 	%f1267, %f135;
	@%p121 bra 	BB1_223;

	mov.f32 	%f720, 0f00000000;
	mul.rn.f32 	%f1267, %f135, %f720;

BB1_223:
	mul.f32 	%f721, %f1267, 0f3F22F983;
	cvt.rni.s32.f32	%r1467, %f721;
	cvt.rn.f32.s32	%f722, %r1467;
	neg.f32 	%f723, %f722;
	fma.rn.f32 	%f725, %f723, %f655, %f1267;
	fma.rn.f32 	%f727, %f723, %f657, %f725;
	fma.rn.f32 	%f1268, %f723, %f659, %f727;
	abs.f32 	%f729, %f1267;
	setp.leu.f32	%p135, %f729, 0f47CE4780;
	@%p135 bra 	BB1_233;

	mov.b32 	 %r336, %f1267;
	shr.u32 	%r337, %r336, 23;
	bfe.u32 	%r1012, %r336, 23, 8;
	add.s32 	%r1013, %r1012, -128;
	shl.b32 	%r1014, %r336, 8;
	or.b32  	%r338, %r1014, -2147483648;
	shr.u32 	%r339, %r1013, 5;
	mov.u32 	%r1459, 0;
	mov.u64 	%rd140, __cudart_i2opi_f;
	mov.u32 	%r1458, -6;
	mov.u64 	%rd169, %rd1;

BB1_225:
	.pragma "nounroll";
	ld.const.u32 	%r1017, [%rd140];
	// inline asm
	{
	mad.lo.cc.u32   %r1015, %r1017, %r338, %r1459;
	madc.hi.u32     %r1016, %r1017, %r338,  0;
	}
	// inline asm
	mov.u32 	%r1459, %r1016;
	st.local.u32 	[%rd169], %r1015;
	add.s64 	%rd169, %rd169, 4;
	add.s64 	%rd140, %rd140, 4;
	add.s32 	%r1458, %r1458, 1;
	setp.ne.s32	%p136, %r1458, 0;
	@%p136 bra 	BB1_225;

	and.b32  	%r344, %r336, -2147483648;
	st.local.u32 	[%rd1+24], %r1016;
	mov.u32 	%r1020, 6;
	sub.s32 	%r1021, %r1020, %r339;
	mul.wide.s32 	%rd117, %r1021, 4;
	add.s64 	%rd64, %rd1, %rd117;
	ld.local.u32 	%r1460, [%rd64];
	ld.local.u32 	%r1461, [%rd64+-4];
	and.b32  	%r347, %r337, 31;
	setp.eq.s32	%p137, %r347, 0;
	@%p137 bra 	BB1_228;

	mov.u32 	%r1022, 32;
	sub.s32 	%r1023, %r1022, %r347;
	shr.u32 	%r1024, %r1461, %r1023;
	shl.b32 	%r1025, %r1460, %r347;
	add.s32 	%r1460, %r1024, %r1025;
	ld.local.u32 	%r1026, [%rd64+-8];
	shr.u32 	%r1027, %r1026, %r1023;
	shl.b32 	%r1028, %r1461, %r347;
	add.s32 	%r1461, %r1027, %r1028;

BB1_228:
	shr.u32 	%r1029, %r1461, 30;
	shl.b32 	%r1030, %r1460, 2;
	add.s32 	%r1462, %r1029, %r1030;
	shl.b32 	%r353, %r1461, 2;
	shr.u32 	%r1031, %r1462, 31;
	shr.u32 	%r1032, %r1460, 30;
	add.s32 	%r354, %r1031, %r1032;
	setp.eq.s32	%p138, %r1031, 0;
	mov.u32 	%r1463, %r344;
	mov.u32 	%r1464, %r353;
	@%p138 bra 	BB1_230;

	not.b32 	%r1033, %r1462;
	neg.s32 	%r355, %r353;
	setp.eq.s32	%p139, %r353, 0;
	selp.u32	%r1034, 1, 0, %p139;
	add.s32 	%r1462, %r1034, %r1033;
	xor.b32  	%r357, %r344, -2147483648;
	mov.u32 	%r1463, %r357;
	mov.u32 	%r1464, %r355;

BB1_230:
	mov.u32 	%r359, %r1463;
	neg.s32 	%r1035, %r354;
	setp.eq.s32	%p140, %r344, 0;
	selp.b32	%r1467, %r354, %r1035, %p140;
	clz.b32 	%r1466, %r1462;
	setp.eq.s32	%p141, %r1466, 0;
	shl.b32 	%r1036, %r1462, %r1466;
	mov.u32 	%r1037, 32;
	sub.s32 	%r1038, %r1037, %r1466;
	shr.u32 	%r1039, %r1464, %r1038;
	add.s32 	%r1040, %r1039, %r1036;
	selp.b32	%r363, %r1462, %r1040, %p141;
	mov.u32 	%r1041, -921707870;
	mul.hi.u32 	%r1465, %r363, %r1041;
	setp.lt.s32	%p142, %r1465, 1;
	@%p142 bra 	BB1_232;

	mul.lo.s32 	%r1042, %r363, -921707870;
	shr.u32 	%r1043, %r1042, 31;
	shl.b32 	%r1044, %r1465, 1;
	add.s32 	%r1465, %r1043, %r1044;
	add.s32 	%r1466, %r1466, 1;

BB1_232:
	mov.u32 	%r1045, 126;
	sub.s32 	%r1046, %r1045, %r1466;
	shl.b32 	%r1047, %r1046, 23;
	add.s32 	%r1048, %r1465, 1;
	shr.u32 	%r1049, %r1048, 7;
	add.s32 	%r1050, %r1049, 1;
	shr.u32 	%r1051, %r1050, 1;
	add.s32 	%r1052, %r1051, %r1047;
	or.b32  	%r1053, %r1052, %r359;
	mov.b32 	 %f1268, %r1053;

BB1_233:
	mul.rn.f32 	%f214, %f1268, %f1268;
	add.s32 	%r370, %r1467, 1;
	and.b32  	%r371, %r370, 1;
	setp.eq.s32	%p143, %r371, 0;
	@%p143 bra 	BB1_235;
	bra.uni 	BB1_234;

BB1_235:
	mov.f32 	%f732, 0f3C08839E;
	mov.f32 	%f733, 0fB94CA1F9;
	fma.rn.f32 	%f1269, %f733, %f214, %f732;
	bra.uni 	BB1_236;

BB1_234:
	mov.f32 	%f730, 0fBAB6061A;
	mov.f32 	%f731, 0f37CCF5CE;
	fma.rn.f32 	%f1269, %f731, %f214, %f730;

BB1_236:
	@%p143 bra 	BB1_238;
	bra.uni 	BB1_237;

BB1_238:
	mov.f32 	%f737, 0fBE2AAAA3;
	fma.rn.f32 	%f738, %f1269, %f214, %f737;
	mov.f32 	%f739, 0f00000000;
	fma.rn.f32 	%f1270, %f738, %f214, %f739;
	bra.uni 	BB1_239;

BB1_237:
	mov.f32 	%f734, 0f3D2AAAA5;
	fma.rn.f32 	%f735, %f1269, %f214, %f734;
	mov.f32 	%f736, 0fBF000000;
	fma.rn.f32 	%f1270, %f735, %f214, %f736;

BB1_239:
	fma.rn.f32 	%f1271, %f1270, %f1268, %f1268;
	@%p143 bra 	BB1_241;

	mov.f32 	%f740, 0f3F800000;
	fma.rn.f32 	%f1271, %f1270, %f214, %f740;

BB1_241:
	and.b32  	%r1054, %r370, 2;
	setp.eq.s32	%p146, %r1054, 0;
	@%p146 bra 	BB1_243;

	mov.f32 	%f741, 0f00000000;
	mov.f32 	%f742, 0fBF800000;
	fma.rn.f32 	%f1271, %f1271, %f742, %f741;

BB1_243:
	mov.f32 	%f1272, %f136;
	abs.f32 	%f227, %f136;
	setp.neu.f32	%p147, %f227, 0f7F800000;
	@%p147 bra 	BB1_245;

	mov.f32 	%f743, 0f00000000;
	mul.rn.f32 	%f1272, %f136, %f743;

BB1_245:
	mul.f32 	%f744, %f1272, 0f3F22F983;
	cvt.rni.s32.f32	%r1477, %f744;
	cvt.rn.f32.s32	%f745, %r1477;
	neg.f32 	%f746, %f745;
	fma.rn.f32 	%f748, %f746, %f655, %f1272;
	fma.rn.f32 	%f750, %f746, %f657, %f748;
	fma.rn.f32 	%f1273, %f746, %f659, %f750;
	abs.f32 	%f752, %f1272;
	setp.leu.f32	%p148, %f752, 0f47CE4780;
	@%p148 bra 	BB1_255;

	mov.b32 	 %r373, %f1272;
	shr.u32 	%r374, %r373, 23;
	bfe.u32 	%r1057, %r373, 23, 8;
	add.s32 	%r1058, %r1057, -128;
	shl.b32 	%r1059, %r373, 8;
	or.b32  	%r375, %r1059, -2147483648;
	shr.u32 	%r376, %r1058, 5;
	mov.u32 	%r1469, 0;
	mov.u64 	%rd141, __cudart_i2opi_f;
	mov.u32 	%r1468, -6;
	mov.u64 	%rd168, %rd1;

BB1_247:
	.pragma "nounroll";
	ld.const.u32 	%r1062, [%rd141];
	// inline asm
	{
	mad.lo.cc.u32   %r1060, %r1062, %r375, %r1469;
	madc.hi.u32     %r1061, %r1062, %r375,  0;
	}
	// inline asm
	mov.u32 	%r1469, %r1061;
	st.local.u32 	[%rd168], %r1060;
	add.s64 	%rd168, %rd168, 4;
	add.s64 	%rd141, %rd141, 4;
	add.s32 	%r1468, %r1468, 1;
	setp.ne.s32	%p149, %r1468, 0;
	@%p149 bra 	BB1_247;

	and.b32  	%r381, %r373, -2147483648;
	st.local.u32 	[%rd1+24], %r1061;
	mov.u32 	%r1065, 6;
	sub.s32 	%r1066, %r1065, %r376;
	mul.wide.s32 	%rd119, %r1066, 4;
	add.s64 	%rd69, %rd1, %rd119;
	ld.local.u32 	%r1470, [%rd69];
	ld.local.u32 	%r1471, [%rd69+-4];
	and.b32  	%r384, %r374, 31;
	setp.eq.s32	%p150, %r384, 0;
	@%p150 bra 	BB1_250;

	mov.u32 	%r1067, 32;
	sub.s32 	%r1068, %r1067, %r384;
	shr.u32 	%r1069, %r1471, %r1068;
	shl.b32 	%r1070, %r1470, %r384;
	add.s32 	%r1470, %r1069, %r1070;
	ld.local.u32 	%r1071, [%rd69+-8];
	shr.u32 	%r1072, %r1071, %r1068;
	shl.b32 	%r1073, %r1471, %r384;
	add.s32 	%r1471, %r1072, %r1073;

BB1_250:
	shr.u32 	%r1074, %r1471, 30;
	shl.b32 	%r1075, %r1470, 2;
	add.s32 	%r1472, %r1074, %r1075;
	shl.b32 	%r390, %r1471, 2;
	shr.u32 	%r1076, %r1472, 31;
	shr.u32 	%r1077, %r1470, 30;
	add.s32 	%r391, %r1076, %r1077;
	setp.eq.s32	%p151, %r1076, 0;
	mov.u32 	%r1473, %r381;
	mov.u32 	%r1474, %r390;
	@%p151 bra 	BB1_252;

	not.b32 	%r1078, %r1472;
	neg.s32 	%r392, %r390;
	setp.eq.s32	%p152, %r390, 0;
	selp.u32	%r1079, 1, 0, %p152;
	add.s32 	%r1472, %r1079, %r1078;
	xor.b32  	%r394, %r381, -2147483648;
	mov.u32 	%r1473, %r394;
	mov.u32 	%r1474, %r392;

BB1_252:
	mov.u32 	%r396, %r1473;
	neg.s32 	%r1080, %r391;
	setp.eq.s32	%p153, %r381, 0;
	selp.b32	%r1477, %r391, %r1080, %p153;
	clz.b32 	%r1476, %r1472;
	setp.eq.s32	%p154, %r1476, 0;
	shl.b32 	%r1081, %r1472, %r1476;
	mov.u32 	%r1082, 32;
	sub.s32 	%r1083, %r1082, %r1476;
	shr.u32 	%r1084, %r1474, %r1083;
	add.s32 	%r1085, %r1084, %r1081;
	selp.b32	%r400, %r1472, %r1085, %p154;
	mov.u32 	%r1086, -921707870;
	mul.hi.u32 	%r1475, %r400, %r1086;
	setp.lt.s32	%p155, %r1475, 1;
	@%p155 bra 	BB1_254;

	mul.lo.s32 	%r1087, %r400, -921707870;
	shr.u32 	%r1088, %r1087, 31;
	shl.b32 	%r1089, %r1475, 1;
	add.s32 	%r1475, %r1088, %r1089;
	add.s32 	%r1476, %r1476, 1;

BB1_254:
	mov.u32 	%r1090, 126;
	sub.s32 	%r1091, %r1090, %r1476;
	shl.b32 	%r1092, %r1091, 23;
	add.s32 	%r1093, %r1475, 1;
	shr.u32 	%r1094, %r1093, 7;
	add.s32 	%r1095, %r1094, 1;
	shr.u32 	%r1096, %r1095, 1;
	add.s32 	%r1097, %r1096, %r1092;
	or.b32  	%r1098, %r1097, %r396;
	mov.b32 	 %f1273, %r1098;

BB1_255:
	mul.rn.f32 	%f233, %f1273, %f1273;
	and.b32  	%r407, %r1477, 1;
	setp.eq.s32	%p156, %r407, 0;
	@%p156 bra 	BB1_257;
	bra.uni 	BB1_256;

BB1_257:
	mov.f32 	%f755, 0f3C08839E;
	mov.f32 	%f756, 0fB94CA1F9;
	fma.rn.f32 	%f1274, %f756, %f233, %f755;
	bra.uni 	BB1_258;

BB1_256:
	mov.f32 	%f753, 0fBAB6061A;
	mov.f32 	%f754, 0f37CCF5CE;
	fma.rn.f32 	%f1274, %f754, %f233, %f753;

BB1_258:
	@%p156 bra 	BB1_260;
	bra.uni 	BB1_259;

BB1_260:
	mov.f32 	%f760, 0fBE2AAAA3;
	fma.rn.f32 	%f761, %f1274, %f233, %f760;
	mov.f32 	%f762, 0f00000000;
	fma.rn.f32 	%f1275, %f761, %f233, %f762;
	bra.uni 	BB1_261;

BB1_259:
	mov.f32 	%f757, 0f3D2AAAA5;
	fma.rn.f32 	%f758, %f1274, %f233, %f757;
	mov.f32 	%f759, 0fBF000000;
	fma.rn.f32 	%f1275, %f758, %f233, %f759;

BB1_261:
	fma.rn.f32 	%f1276, %f1275, %f1273, %f1273;
	@%p156 bra 	BB1_263;

	mov.f32 	%f763, 0f3F800000;
	fma.rn.f32 	%f1276, %f1275, %f233, %f763;

BB1_263:
	and.b32  	%r1099, %r1477, 2;
	setp.eq.s32	%p159, %r1099, 0;
	@%p159 bra 	BB1_265;

	mov.f32 	%f764, 0f00000000;
	mov.f32 	%f765, 0fBF800000;
	fma.rn.f32 	%f1276, %f1276, %f765, %f764;

BB1_265:
	mov.f32 	%f1277, %f136;
	@%p147 bra 	BB1_267;

	mov.f32 	%f766, 0f00000000;
	mul.rn.f32 	%f1277, %f136, %f766;

BB1_267:
	mul.f32 	%f767, %f1277, 0f3F22F983;
	cvt.rni.s32.f32	%r1487, %f767;
	cvt.rn.f32.s32	%f768, %r1487;
	neg.f32 	%f769, %f768;
	fma.rn.f32 	%f771, %f769, %f655, %f1277;
	fma.rn.f32 	%f773, %f769, %f657, %f771;
	fma.rn.f32 	%f1278, %f769, %f659, %f773;
	abs.f32 	%f775, %f1277;
	setp.leu.f32	%p161, %f775, 0f47CE4780;
	@%p161 bra 	BB1_277;

	mov.b32 	 %r409, %f1277;
	shr.u32 	%r410, %r409, 23;
	bfe.u32 	%r1102, %r409, 23, 8;
	add.s32 	%r1103, %r1102, -128;
	shl.b32 	%r1104, %r409, 8;
	or.b32  	%r411, %r1104, -2147483648;
	shr.u32 	%r412, %r1103, 5;
	mov.u32 	%r1479, 0;
	mov.u64 	%rd142, __cudart_i2opi_f;
	mov.u32 	%r1478, -6;
	mov.u64 	%rd167, %rd1;

BB1_269:
	.pragma "nounroll";
	ld.const.u32 	%r1107, [%rd142];
	// inline asm
	{
	mad.lo.cc.u32   %r1105, %r1107, %r411, %r1479;
	madc.hi.u32     %r1106, %r1107, %r411,  0;
	}
	// inline asm
	mov.u32 	%r1479, %r1106;
	st.local.u32 	[%rd167], %r1105;
	add.s64 	%rd167, %rd167, 4;
	add.s64 	%rd142, %rd142, 4;
	add.s32 	%r1478, %r1478, 1;
	setp.ne.s32	%p162, %r1478, 0;
	@%p162 bra 	BB1_269;

	and.b32  	%r417, %r409, -2147483648;
	st.local.u32 	[%rd1+24], %r1106;
	mov.u32 	%r1110, 6;
	sub.s32 	%r1111, %r1110, %r412;
	mul.wide.s32 	%rd121, %r1111, 4;
	add.s64 	%rd74, %rd1, %rd121;
	ld.local.u32 	%r1480, [%rd74];
	ld.local.u32 	%r1481, [%rd74+-4];
	and.b32  	%r420, %r410, 31;
	setp.eq.s32	%p163, %r420, 0;
	@%p163 bra 	BB1_272;

	mov.u32 	%r1112, 32;
	sub.s32 	%r1113, %r1112, %r420;
	shr.u32 	%r1114, %r1481, %r1113;
	shl.b32 	%r1115, %r1480, %r420;
	add.s32 	%r1480, %r1114, %r1115;
	ld.local.u32 	%r1116, [%rd74+-8];
	shr.u32 	%r1117, %r1116, %r1113;
	shl.b32 	%r1118, %r1481, %r420;
	add.s32 	%r1481, %r1117, %r1118;

BB1_272:
	shr.u32 	%r1119, %r1481, 30;
	shl.b32 	%r1120, %r1480, 2;
	add.s32 	%r1482, %r1119, %r1120;
	shl.b32 	%r426, %r1481, 2;
	shr.u32 	%r1121, %r1482, 31;
	shr.u32 	%r1122, %r1480, 30;
	add.s32 	%r427, %r1121, %r1122;
	setp.eq.s32	%p164, %r1121, 0;
	mov.u32 	%r1483, %r417;
	mov.u32 	%r1484, %r426;
	@%p164 bra 	BB1_274;

	not.b32 	%r1123, %r1482;
	neg.s32 	%r428, %r426;
	setp.eq.s32	%p165, %r426, 0;
	selp.u32	%r1124, 1, 0, %p165;
	add.s32 	%r1482, %r1124, %r1123;
	xor.b32  	%r430, %r417, -2147483648;
	mov.u32 	%r1483, %r430;
	mov.u32 	%r1484, %r428;

BB1_274:
	mov.u32 	%r432, %r1483;
	neg.s32 	%r1125, %r427;
	setp.eq.s32	%p166, %r417, 0;
	selp.b32	%r1487, %r427, %r1125, %p166;
	clz.b32 	%r1486, %r1482;
	setp.eq.s32	%p167, %r1486, 0;
	shl.b32 	%r1126, %r1482, %r1486;
	mov.u32 	%r1127, 32;
	sub.s32 	%r1128, %r1127, %r1486;
	shr.u32 	%r1129, %r1484, %r1128;
	add.s32 	%r1130, %r1129, %r1126;
	selp.b32	%r436, %r1482, %r1130, %p167;
	mov.u32 	%r1131, -921707870;
	mul.hi.u32 	%r1485, %r436, %r1131;
	setp.lt.s32	%p168, %r1485, 1;
	@%p168 bra 	BB1_276;

	mul.lo.s32 	%r1132, %r436, -921707870;
	shr.u32 	%r1133, %r1132, 31;
	shl.b32 	%r1134, %r1485, 1;
	add.s32 	%r1485, %r1133, %r1134;
	add.s32 	%r1486, %r1486, 1;

BB1_276:
	mov.u32 	%r1135, 126;
	sub.s32 	%r1136, %r1135, %r1486;
	shl.b32 	%r1137, %r1136, 23;
	add.s32 	%r1138, %r1485, 1;
	shr.u32 	%r1139, %r1138, 7;
	add.s32 	%r1140, %r1139, 1;
	shr.u32 	%r1141, %r1140, 1;
	add.s32 	%r1142, %r1141, %r1137;
	or.b32  	%r1143, %r1142, %r432;
	mov.b32 	 %f1278, %r1143;

BB1_277:
	mul.rn.f32 	%f251, %f1278, %f1278;
	add.s32 	%r443, %r1487, 1;
	and.b32  	%r444, %r443, 1;
	setp.eq.s32	%p169, %r444, 0;
	@%p169 bra 	BB1_279;
	bra.uni 	BB1_278;

BB1_279:
	mov.f32 	%f778, 0f3C08839E;
	mov.f32 	%f779, 0fB94CA1F9;
	fma.rn.f32 	%f1279, %f779, %f251, %f778;
	bra.uni 	BB1_280;

BB1_278:
	mov.f32 	%f776, 0fBAB6061A;
	mov.f32 	%f777, 0f37CCF5CE;
	fma.rn.f32 	%f1279, %f777, %f251, %f776;

BB1_280:
	@%p169 bra 	BB1_282;
	bra.uni 	BB1_281;

BB1_282:
	mov.f32 	%f783, 0fBE2AAAA3;
	fma.rn.f32 	%f784, %f1279, %f251, %f783;
	mov.f32 	%f785, 0f00000000;
	fma.rn.f32 	%f1280, %f784, %f251, %f785;
	bra.uni 	BB1_283;

BB1_281:
	mov.f32 	%f780, 0f3D2AAAA5;
	fma.rn.f32 	%f781, %f1279, %f251, %f780;
	mov.f32 	%f782, 0fBF000000;
	fma.rn.f32 	%f1280, %f781, %f251, %f782;

BB1_283:
	fma.rn.f32 	%f1281, %f1280, %f1278, %f1278;
	@%p169 bra 	BB1_285;

	mov.f32 	%f786, 0f3F800000;
	fma.rn.f32 	%f1281, %f1280, %f251, %f786;

BB1_285:
	and.b32  	%r1144, %r443, 2;
	setp.eq.s32	%p172, %r1144, 0;
	@%p172 bra 	BB1_287;

	mov.f32 	%f787, 0f00000000;
	mov.f32 	%f788, 0fBF800000;
	fma.rn.f32 	%f1281, %f1281, %f788, %f787;

BB1_287:
	fma.rn.f32 	%f789, %f1261, 0f00000000, 0f3F800000;
	mov.f32 	%f790, 0f3F800000;
	sub.f32 	%f791, %f790, %f1261;
	mul.f32 	%f792, %f791, 0f00000000;
	mul.f32 	%f793, %f1256, 0f00000000;
	sub.f32 	%f794, %f792, %f793;
	add.f32 	%f795, %f793, %f792;
	add.f32 	%f796, %f1261, 0f00000000;
	sub.f32 	%f797, %f792, %f1256;
	add.f32 	%f798, %f1256, %f792;
	add.f32 	%f799, %f1271, 0f00000000;
	sub.f32 	%f800, %f790, %f1271;
	mul.f32 	%f801, %f800, 0f00000000;
	mul.f32 	%f802, %f1266, 0f00000000;
	sub.f32 	%f803, %f801, %f802;
	add.f32 	%f804, %f1266, %f801;
	add.f32 	%f805, %f802, %f801;
	fma.rn.f32 	%f806, %f1271, 0f00000000, 0f3F800000;
	sub.f32 	%f807, %f801, %f1266;
	sub.f32 	%f808, %f790, %f1281;
	mul.f32 	%f809, %f808, 0f00000000;
	sub.f32 	%f810, %f809, %f1276;
	mul.f32 	%f811, %f1276, 0f00000000;
	add.f32 	%f812, %f811, %f809;
	add.f32 	%f813, %f1276, %f809;
	sub.f32 	%f814, %f809, %f811;
	fma.rn.f32 	%f815, %f1281, 0f00000000, 0f3F800000;
	fma.rn.f32 	%f816, %f1282, %f789, 0f00000000;
	fma.rn.f32 	%f817, %f1283, %f795, %f816;
	fma.rn.f32 	%f818, %f1284, %f794, %f817;
	add.f32 	%f819, %f818, 0f00000000;
	fma.rn.f32 	%f820, %f1282, %f794, 0f00000000;
	fma.rn.f32 	%f821, %f1283, %f796, %f820;
	fma.rn.f32 	%f822, %f1284, %f798, %f821;
	add.f32 	%f823, %f822, 0f00000000;
	fma.rn.f32 	%f824, %f1282, %f795, 0f00000000;
	fma.rn.f32 	%f825, %f1283, %f797, %f824;
	fma.rn.f32 	%f826, %f1284, %f796, %f825;
	add.f32 	%f827, %f826, 0f00000000;
	fma.rn.f32 	%f828, %f1282, 0f00000000, 0f00000000;
	fma.rn.f32 	%f829, %f1283, 0f00000000, %f828;
	fma.rn.f32 	%f830, %f1284, 0f00000000, %f829;
	add.f32 	%f831, %f830, 0f3F800000;
	fma.rn.f32 	%f832, %f819, %f799, 0f00000000;
	fma.rn.f32 	%f833, %f823, %f805, %f832;
	fma.rn.f32 	%f834, %f827, %f807, %f833;
	fma.rn.f32 	%f835, %f831, 0f00000000, %f834;
	fma.rn.f32 	%f836, %f819, %f803, 0f00000000;
	fma.rn.f32 	%f837, %f823, %f806, %f836;
	fma.rn.f32 	%f838, %f827, %f805, %f837;
	fma.rn.f32 	%f839, %f831, 0f00000000, %f838;
	fma.rn.f32 	%f840, %f819, %f804, 0f00000000;
	fma.rn.f32 	%f841, %f823, %f803, %f840;
	fma.rn.f32 	%f842, %f827, %f799, %f841;
	fma.rn.f32 	%f843, %f831, 0f00000000, %f842;
	fma.rn.f32 	%f844, %f819, 0f00000000, 0f00000000;
	fma.rn.f32 	%f845, %f823, 0f00000000, %f844;
	fma.rn.f32 	%f846, %f827, 0f00000000, %f845;
	add.f32 	%f847, %f846, %f831;
	add.f32 	%f848, %f1281, 0f00000000;
	fma.rn.f32 	%f849, %f835, %f848, 0f00000000;
	fma.rn.f32 	%f850, %f839, %f813, %f849;
	fma.rn.f32 	%f851, %f843, %f814, %f850;
	fma.rn.f32 	%f1282, %f847, 0f00000000, %f851;
	fma.rn.f32 	%f852, %f835, %f810, 0f00000000;
	fma.rn.f32 	%f853, %f839, %f848, %f852;
	fma.rn.f32 	%f854, %f843, %f812, %f853;
	fma.rn.f32 	%f1283, %f847, 0f00000000, %f854;
	fma.rn.f32 	%f855, %f835, %f812, 0f00000000;
	fma.rn.f32 	%f856, %f839, %f814, %f855;
	fma.rn.f32 	%f857, %f843, %f815, %f856;
	fma.rn.f32 	%f1284, %f847, 0f00000000, %f857;

BB1_288:
	mov.f32 	%f1251, %f1282;
	mov.f32 	%f1250, %f1283;
	mov.f32 	%f1249, %f1284;
	setp.gt.f32	%p173, %f143, 0f40000000;
	@%p173 bra 	BB1_417;
	bra.uni 	BB1_289;

BB1_417:
	setp.lt.f32	%p293, %f143, 0f7F800000;
	setp.gt.f32	%p294, %f143, 0f00000000;
	and.pred  	%p295, %p294, %p293;
	@%p295 bra 	BB1_419;
	bra.uni 	BB1_418;

BB1_419:
	setp.lt.f32	%p296, %f143, 0f00800000;
	mul.f32 	%f1175, %f143, 0f4B800000;
	selp.f32	%f1176, %f1175, %f143, %p296;
	selp.f32	%f1177, 0fC3170000, 0fC2FE0000, %p296;
	mov.b32 	 %r1361, %f1176;
	and.b32  	%r1362, %r1361, 8388607;
	or.b32  	%r1363, %r1362, 1065353216;
	mov.b32 	 %f1178, %r1363;
	shr.u32 	%r1364, %r1361, 23;
	cvt.rn.f32.u32	%f1179, %r1364;
	add.f32 	%f1180, %f1177, %f1179;
	setp.gt.f32	%p297, %f1178, 0f3FAE147B;
	mul.f32 	%f1181, %f1178, 0f3F000000;
	add.f32 	%f1182, %f1180, 0f3F800000;
	selp.f32	%f1183, %f1181, %f1178, %p297;
	selp.f32	%f1184, %f1182, %f1180, %p297;
	add.f32 	%f1174, %f1183, 0f3F800000;
	add.f32 	%f1185, %f1183, 0fBF800000;
	// inline asm
	rcp.approx.ftz.f32 %f1173,%f1174;
	// inline asm
	mul.f32 	%f1186, %f1185, %f1185;
	neg.f32 	%f1187, %f1186;
	mul.rn.f32 	%f1188, %f1173, %f1187;
	add.rn.f32 	%f1189, %f1185, %f1188;
	mul.f32 	%f1190, %f1189, %f1189;
	mov.f32 	%f1191, 0f3C4C6A36;
	mov.f32 	%f1192, 0f3B1E94E6;
	fma.rn.f32 	%f1193, %f1192, %f1190, %f1191;
	mov.f32 	%f1194, 0f3DAAAB1A;
	fma.rn.f32 	%f1195, %f1193, %f1190, %f1194;
	mul.f32 	%f1196, %f1190, %f1195;
	fma.rn.f32 	%f1197, %f1196, %f1189, %f1188;
	add.f32 	%f1198, %f1185, %f1197;
	mov.f32 	%f1199, 0f3F317218;
	fma.rn.f32 	%f1314, %f1184, %f1199, %f1198;
	bra.uni 	BB1_420;

BB1_289:
	mul.f32 	%f858, %f1283, %f1283;
	fma.rn.f32 	%f859, %f1282, %f1282, %f858;
	add.f32 	%f860, %f859, 0f00000000;
	sqrt.rn.f32 	%f861, %f860;
	abs.f32 	%f272, %f861;
	abs.f32 	%f273, %f1284;
	setp.eq.f32	%p174, %f273, 0f00000000;
	setp.eq.f32	%p175, %f272, 0f00000000;
	and.pred  	%p176, %p174, %p175;
	mov.b32 	 %r445, %f1284;
	mov.b32 	 %r1145, %f861;
	and.b32  	%r446, %r1145, -2147483648;
	@%p176 bra 	BB1_293;
	bra.uni 	BB1_290;

BB1_293:
	shr.s32 	%r1152, %r445, 31;
	and.b32  	%r1153, %r1152, 1078530011;
	or.b32  	%r1154, %r446, %r1153;
	mov.b32 	 %f1285, %r1154;
	bra.uni 	BB1_294;

BB1_418:
	lg2.approx.f32 	%f1314, %f143;

BB1_420:
	mul.f32 	%f1200, %f143, 0f3F000000;
	mul.f32 	%f1201, %f1200, %f1314;
	div.rn.f32 	%f1315, %f1201, %f1248;
	bra.uni 	BB1_421;

BB1_290:
	setp.eq.f32	%p177, %f273, 0f7F800000;
	setp.eq.f32	%p178, %f272, 0f7F800000;
	and.pred  	%p179, %p177, %p178;
	@%p179 bra 	BB1_292;
	bra.uni 	BB1_291;

BB1_292:
	shr.s32 	%r1148, %r445, 31;
	and.b32  	%r1149, %r1148, 13483017;
	add.s32 	%r1150, %r1149, 1061752795;
	or.b32  	%r1151, %r446, %r1150;
	mov.b32 	 %f1285, %r1151;
	bra.uni 	BB1_294;

BB1_291:
	max.f32 	%f862, %f272, %f273;
	min.f32 	%f863, %f272, %f273;
	div.rn.f32 	%f864, %f863, %f862;
	mul.rn.f32 	%f865, %f864, %f864;
	mov.f32 	%f866, 0fC0B59883;
	mov.f32 	%f867, 0fBF52C7EA;
	fma.rn.f32 	%f868, %f865, %f867, %f866;
	mov.f32 	%f869, 0fC0D21907;
	fma.rn.f32 	%f870, %f868, %f865, %f869;
	mul.f32 	%f871, %f865, %f870;
	mul.f32 	%f872, %f864, %f871;
	add.f32 	%f873, %f865, 0f41355DC0;
	mov.f32 	%f874, 0f41E6BD60;
	fma.rn.f32 	%f875, %f873, %f865, %f874;
	mov.f32 	%f876, 0f419D92C8;
	fma.rn.f32 	%f877, %f875, %f865, %f876;
	rcp.rn.f32 	%f878, %f877;
	fma.rn.f32 	%f879, %f872, %f878, %f864;
	mov.f32 	%f880, 0f3FC90FDB;
	sub.f32 	%f881, %f880, %f879;
	setp.gt.f32	%p180, %f272, %f273;
	selp.f32	%f882, %f881, %f879, %p180;
	mov.f32 	%f883, 0f40490FDB;
	sub.f32 	%f884, %f883, %f882;
	setp.lt.s32	%p181, %r445, 0;
	selp.f32	%f885, %f884, %f882, %p181;
	mov.b32 	 %r1146, %f885;
	or.b32  	%r1147, %r1146, %r446;
	mov.b32 	 %f886, %r1147;
	add.f32 	%f887, %f273, %f272;
	setp.gtu.f32	%p182, %f887, 0f7F800000;
	selp.f32	%f1285, %f887, %f886, %p182;

BB1_294:
	abs.f32 	%f278, %f1282;
	setp.eq.f32	%p183, %f278, 0f00000000;
	abs.f32 	%f279, %f1283;
	setp.eq.f32	%p184, %f279, 0f00000000;
	and.pred  	%p185, %p183, %p184;
	mov.b32 	 %r447, %f1282;
	mov.b32 	 %r1155, %f1283;
	and.b32  	%r448, %r1155, -2147483648;
	@%p185 bra 	BB1_298;
	bra.uni 	BB1_295;

BB1_298:
	shr.s32 	%r1162, %r447, 31;
	and.b32  	%r1163, %r1162, 1078530011;
	or.b32  	%r1164, %r1163, %r448;
	mov.b32 	 %f1286, %r1164;
	bra.uni 	BB1_299;

BB1_295:
	setp.eq.f32	%p186, %f278, 0f7F800000;
	setp.eq.f32	%p187, %f279, 0f7F800000;
	and.pred  	%p188, %p186, %p187;
	@%p188 bra 	BB1_297;
	bra.uni 	BB1_296;

BB1_297:
	shr.s32 	%r1158, %r447, 31;
	and.b32  	%r1159, %r1158, 13483017;
	add.s32 	%r1160, %r1159, 1061752795;
	or.b32  	%r1161, %r1160, %r448;
	mov.b32 	 %f1286, %r1161;
	bra.uni 	BB1_299;

BB1_296:
	max.f32 	%f888, %f279, %f278;
	min.f32 	%f889, %f279, %f278;
	div.rn.f32 	%f890, %f889, %f888;
	mul.rn.f32 	%f891, %f890, %f890;
	mov.f32 	%f892, 0fC0B59883;
	mov.f32 	%f893, 0fBF52C7EA;
	fma.rn.f32 	%f894, %f891, %f893, %f892;
	mov.f32 	%f895, 0fC0D21907;
	fma.rn.f32 	%f896, %f894, %f891, %f895;
	mul.f32 	%f897, %f891, %f896;
	mul.f32 	%f898, %f890, %f897;
	add.f32 	%f899, %f891, 0f41355DC0;
	mov.f32 	%f900, 0f41E6BD60;
	fma.rn.f32 	%f901, %f899, %f891, %f900;
	mov.f32 	%f902, 0f419D92C8;
	fma.rn.f32 	%f903, %f901, %f891, %f902;
	rcp.rn.f32 	%f904, %f903;
	fma.rn.f32 	%f905, %f898, %f904, %f890;
	mov.f32 	%f906, 0f3FC90FDB;
	sub.f32 	%f907, %f906, %f905;
	setp.gt.f32	%p189, %f279, %f278;
	selp.f32	%f908, %f907, %f905, %p189;
	mov.f32 	%f909, 0f40490FDB;
	sub.f32 	%f910, %f909, %f908;
	setp.lt.s32	%p190, %r447, 0;
	selp.f32	%f911, %f910, %f908, %p190;
	mov.b32 	 %r1156, %f911;
	or.b32  	%r1157, %r1156, %r448;
	mov.b32 	 %f912, %r1157;
	add.f32 	%f913, %f278, %f279;
	setp.gtu.f32	%p191, %f913, 0f7F800000;
	selp.f32	%f1286, %f913, %f912, %p191;

BB1_299:
	mov.f32 	%f914, 0f3F800000;
	cvt.rzi.f32.f32	%f284, %f914;
	add.f32 	%f915, %f284, %f284;
	mov.f32 	%f916, 0f40000000;
	sub.f32 	%f917, %f916, %f915;
	abs.f32 	%f285, %f917;
	setp.eq.f32	%p192, %f143, 0f3F800000;
	mov.f32 	%f1291, %f914;
	@%p192 bra 	BB1_314;

	abs.f32 	%f286, %f143;
	setp.gtu.f32	%p193, %f286, 0f7F800000;
	@%p193 bra 	BB1_313;

	abs.f32 	%f287, %f916;
	setp.gtu.f32	%p194, %f287, 0f7F800000;
	@%p194 bra 	BB1_313;
	bra.uni 	BB1_302;

BB1_313:
	add.f32 	%f296, %f143, 0f40000000;
	mov.f32 	%f1291, %f296;

BB1_314:
	mov.f32 	%f297, %f1291;
	mov.f32 	%f999, 0f3F000000;
	cvt.rzi.f32.f32	%f1000, %f999;
	fma.rn.f32 	%f1001, %f1000, 0fC0000000, 0f3F800000;
	abs.f32 	%f298, %f1001;
	mov.f32 	%f1290, %f914;
	@%p192 bra 	BB1_328;

	abs.f32 	%f299, %f143;
	setp.gtu.f32	%p217, %f299, 0f7F800000;
	@%p217 bra 	BB1_327;

	mov.f32 	%f1002, 0f3F800000;
	abs.f32 	%f300, %f1002;
	setp.gtu.f32	%p218, %f300, 0f7F800000;
	@%p218 bra 	BB1_327;
	bra.uni 	BB1_317;

BB1_327:
	add.f32 	%f1290, %f143, 0f3F800000;

BB1_328:
	mul.f32 	%f311, %f1248, %f1290;
	add.f32 	%f312, %f1285, %f1285;
	abs.f32 	%f313, %f312;
	setp.neu.f32	%p241, %f313, 0f7F800000;
	mov.f32 	%f1309, %f312;
	@%p241 bra 	BB1_330;

	mov.f32 	%f1080, 0f00000000;
	mul.rn.f32 	%f314, %f312, %f1080;
	mov.f32 	%f1309, %f314;

BB1_330:
	mov.f32 	%f315, %f1309;
	mul.f32 	%f1081, %f315, 0f3F22F983;
	cvt.rni.s32.f32	%r1497, %f1081;
	cvt.rn.f32.s32	%f1082, %r1497;
	neg.f32 	%f1083, %f1082;
	mov.f32 	%f1084, 0f3FC90FDA;
	fma.rn.f32 	%f1085, %f1083, %f1084, %f315;
	mov.f32 	%f1086, 0f33A22168;
	fma.rn.f32 	%f1087, %f1083, %f1086, %f1085;
	mov.f32 	%f1088, 0f27C234C5;
	fma.rn.f32 	%f1292, %f1083, %f1088, %f1087;
	abs.f32 	%f1089, %f315;
	setp.leu.f32	%p242, %f1089, 0f47CE4780;
	@%p242 bra 	BB1_340;

	mov.b32 	 %r450, %f315;
	shr.u32 	%r451, %r450, 23;
	bfe.u32 	%r1183, %r450, 23, 8;
	add.s32 	%r1184, %r1183, -128;
	shl.b32 	%r1185, %r450, 8;
	or.b32  	%r452, %r1185, -2147483648;
	shr.u32 	%r453, %r1184, 5;
	mov.u32 	%r1489, 0;
	mov.u64 	%rd143, __cudart_i2opi_f;
	mov.u32 	%r1488, -6;
	mov.u64 	%rd166, %rd1;

BB1_332:
	.pragma "nounroll";
	ld.const.u32 	%r1188, [%rd143];
	// inline asm
	{
	mad.lo.cc.u32   %r1186, %r1188, %r452, %r1489;
	madc.hi.u32     %r1187, %r1188, %r452,  0;
	}
	// inline asm
	mov.u32 	%r1489, %r1187;
	st.local.u32 	[%rd166], %r1186;
	add.s64 	%rd166, %rd166, 4;
	add.s64 	%rd143, %rd143, 4;
	add.s32 	%r1488, %r1488, 1;
	setp.ne.s32	%p243, %r1488, 0;
	@%p243 bra 	BB1_332;

	and.b32  	%r458, %r450, -2147483648;
	st.local.u32 	[%rd1+24], %r1187;
	mov.u32 	%r1191, 6;
	sub.s32 	%r1192, %r1191, %r453;
	mul.wide.s32 	%rd123, %r1192, 4;
	add.s64 	%rd79, %rd1, %rd123;
	ld.local.u32 	%r1490, [%rd79];
	ld.local.u32 	%r1491, [%rd79+-4];
	and.b32  	%r461, %r451, 31;
	setp.eq.s32	%p244, %r461, 0;
	@%p244 bra 	BB1_335;

	mov.u32 	%r1193, 32;
	sub.s32 	%r1194, %r1193, %r461;
	shr.u32 	%r1195, %r1491, %r1194;
	shl.b32 	%r1196, %r1490, %r461;
	add.s32 	%r1490, %r1195, %r1196;
	ld.local.u32 	%r1197, [%rd79+-8];
	shr.u32 	%r1198, %r1197, %r1194;
	shl.b32 	%r1199, %r1491, %r461;
	add.s32 	%r1491, %r1198, %r1199;

BB1_335:
	shr.u32 	%r1200, %r1491, 30;
	shl.b32 	%r1201, %r1490, 2;
	add.s32 	%r1492, %r1200, %r1201;
	shl.b32 	%r467, %r1491, 2;
	shr.u32 	%r1202, %r1492, 31;
	shr.u32 	%r1203, %r1490, 30;
	add.s32 	%r468, %r1202, %r1203;
	setp.eq.s32	%p245, %r1202, 0;
	mov.u32 	%r1493, %r458;
	mov.u32 	%r1494, %r467;
	@%p245 bra 	BB1_337;

	not.b32 	%r1204, %r1492;
	neg.s32 	%r469, %r467;
	setp.eq.s32	%p246, %r467, 0;
	selp.u32	%r1205, 1, 0, %p246;
	add.s32 	%r1492, %r1205, %r1204;
	xor.b32  	%r471, %r458, -2147483648;
	mov.u32 	%r1493, %r471;
	mov.u32 	%r1494, %r469;

BB1_337:
	mov.u32 	%r473, %r1493;
	neg.s32 	%r1206, %r468;
	setp.eq.s32	%p247, %r458, 0;
	selp.b32	%r1497, %r468, %r1206, %p247;
	clz.b32 	%r1496, %r1492;
	setp.eq.s32	%p248, %r1496, 0;
	shl.b32 	%r1207, %r1492, %r1496;
	mov.u32 	%r1208, 32;
	sub.s32 	%r1209, %r1208, %r1496;
	shr.u32 	%r1210, %r1494, %r1209;
	add.s32 	%r1211, %r1210, %r1207;
	selp.b32	%r477, %r1492, %r1211, %p248;
	mov.u32 	%r1212, -921707870;
	mul.hi.u32 	%r1495, %r477, %r1212;
	setp.lt.s32	%p249, %r1495, 1;
	@%p249 bra 	BB1_339;

	mul.lo.s32 	%r1213, %r477, -921707870;
	shr.u32 	%r1214, %r1213, 31;
	shl.b32 	%r1215, %r1495, 1;
	add.s32 	%r1495, %r1214, %r1215;
	add.s32 	%r1496, %r1496, 1;

BB1_339:
	mov.u32 	%r1216, 126;
	sub.s32 	%r1217, %r1216, %r1496;
	shl.b32 	%r1218, %r1217, 23;
	add.s32 	%r1219, %r1495, 1;
	shr.u32 	%r1220, %r1219, 7;
	add.s32 	%r1221, %r1220, 1;
	shr.u32 	%r1222, %r1221, 1;
	add.s32 	%r1223, %r1222, %r1218;
	or.b32  	%r1224, %r1223, %r473;
	mov.b32 	 %f1292, %r1224;

BB1_340:
	mul.rn.f32 	%f319, %f1292, %f1292;
	and.b32  	%r484, %r1497, 1;
	setp.eq.s32	%p250, %r484, 0;
	@%p250 bra 	BB1_342;
	bra.uni 	BB1_341;

BB1_342:
	mov.f32 	%f1092, 0f3C08839E;
	mov.f32 	%f1093, 0fB94CA1F9;
	fma.rn.f32 	%f1293, %f1093, %f319, %f1092;
	bra.uni 	BB1_343;

BB1_341:
	mov.f32 	%f1090, 0fBAB6061A;
	mov.f32 	%f1091, 0f37CCF5CE;
	fma.rn.f32 	%f1293, %f1091, %f319, %f1090;

BB1_343:
	@%p250 bra 	BB1_345;
	bra.uni 	BB1_344;

BB1_345:
	mov.f32 	%f1097, 0fBE2AAAA3;
	fma.rn.f32 	%f1098, %f1293, %f319, %f1097;
	mov.f32 	%f1099, 0f00000000;
	fma.rn.f32 	%f1294, %f1098, %f319, %f1099;
	bra.uni 	BB1_346;

BB1_344:
	mov.f32 	%f1094, 0f3D2AAAA5;
	fma.rn.f32 	%f1095, %f1293, %f319, %f1094;
	mov.f32 	%f1096, 0fBF000000;
	fma.rn.f32 	%f1294, %f1095, %f319, %f1096;

BB1_346:
	fma.rn.f32 	%f1295, %f1294, %f1292, %f1292;
	@%p250 bra 	BB1_348;

	mov.f32 	%f1100, 0f3F800000;
	fma.rn.f32 	%f1295, %f1294, %f319, %f1100;

BB1_348:
	and.b32  	%r1225, %r1497, 2;
	setp.eq.s32	%p253, %r1225, 0;
	@%p253 bra 	BB1_350;

	mov.f32 	%f1101, 0f00000000;
	mov.f32 	%f1102, 0fBF800000;
	fma.rn.f32 	%f1295, %f1295, %f1102, %f1101;

BB1_350:
	add.f32 	%f331, %f1286, %f1286;
	abs.f32 	%f332, %f331;
	setp.neu.f32	%p254, %f332, 0f7F800000;
	mov.f32 	%f1302, %f331;
	@%p254 bra 	BB1_352;

	mov.f32 	%f1103, 0f00000000;
	mul.rn.f32 	%f333, %f331, %f1103;
	mov.f32 	%f1302, %f333;

BB1_352:
	mov.f32 	%f334, %f1302;
	mul.f32 	%f1104, %f334, 0f3F22F983;
	cvt.rni.s32.f32	%r1507, %f1104;
	cvt.rn.f32.s32	%f1105, %r1507;
	neg.f32 	%f1106, %f1105;
	fma.rn.f32 	%f1108, %f1106, %f1084, %f334;
	fma.rn.f32 	%f1110, %f1106, %f1086, %f1108;
	fma.rn.f32 	%f1296, %f1106, %f1088, %f1110;
	abs.f32 	%f1112, %f334;
	setp.leu.f32	%p255, %f1112, 0f47CE4780;
	@%p255 bra 	BB1_362;

	mov.b32 	 %r486, %f334;
	shr.u32 	%r487, %r486, 23;
	bfe.u32 	%r1228, %r486, 23, 8;
	add.s32 	%r1229, %r1228, -128;
	shl.b32 	%r1230, %r486, 8;
	or.b32  	%r488, %r1230, -2147483648;
	shr.u32 	%r489, %r1229, 5;
	mov.u32 	%r1499, 0;
	mov.u64 	%rd144, __cudart_i2opi_f;
	mov.u32 	%r1498, -6;
	mov.u64 	%rd165, %rd1;

BB1_354:
	.pragma "nounroll";
	ld.const.u32 	%r1233, [%rd144];
	// inline asm
	{
	mad.lo.cc.u32   %r1231, %r1233, %r488, %r1499;
	madc.hi.u32     %r1232, %r1233, %r488,  0;
	}
	// inline asm
	mov.u32 	%r1499, %r1232;
	st.local.u32 	[%rd165], %r1231;
	add.s64 	%rd165, %rd165, 4;
	add.s64 	%rd144, %rd144, 4;
	add.s32 	%r1498, %r1498, 1;
	setp.ne.s32	%p256, %r1498, 0;
	@%p256 bra 	BB1_354;

	and.b32  	%r494, %r486, -2147483648;
	st.local.u32 	[%rd1+24], %r1232;
	mov.u32 	%r1236, 6;
	sub.s32 	%r1237, %r1236, %r489;
	mul.wide.s32 	%rd125, %r1237, 4;
	add.s64 	%rd84, %rd1, %rd125;
	ld.local.u32 	%r1500, [%rd84];
	ld.local.u32 	%r1501, [%rd84+-4];
	and.b32  	%r497, %r487, 31;
	setp.eq.s32	%p257, %r497, 0;
	@%p257 bra 	BB1_357;

	mov.u32 	%r1238, 32;
	sub.s32 	%r1239, %r1238, %r497;
	shr.u32 	%r1240, %r1501, %r1239;
	shl.b32 	%r1241, %r1500, %r497;
	add.s32 	%r1500, %r1240, %r1241;
	ld.local.u32 	%r1242, [%rd84+-8];
	shr.u32 	%r1243, %r1242, %r1239;
	shl.b32 	%r1244, %r1501, %r497;
	add.s32 	%r1501, %r1243, %r1244;

BB1_357:
	shr.u32 	%r1245, %r1501, 30;
	shl.b32 	%r1246, %r1500, 2;
	add.s32 	%r1502, %r1245, %r1246;
	shl.b32 	%r503, %r1501, 2;
	shr.u32 	%r1247, %r1502, 31;
	shr.u32 	%r1248, %r1500, 30;
	add.s32 	%r504, %r1247, %r1248;
	setp.eq.s32	%p258, %r1247, 0;
	mov.u32 	%r1503, %r494;
	mov.u32 	%r1504, %r503;
	@%p258 bra 	BB1_359;

	not.b32 	%r1249, %r1502;
	neg.s32 	%r505, %r503;
	setp.eq.s32	%p259, %r503, 0;
	selp.u32	%r1250, 1, 0, %p259;
	add.s32 	%r1502, %r1250, %r1249;
	xor.b32  	%r507, %r494, -2147483648;
	mov.u32 	%r1503, %r507;
	mov.u32 	%r1504, %r505;

BB1_359:
	mov.u32 	%r509, %r1503;
	neg.s32 	%r1251, %r504;
	setp.eq.s32	%p260, %r494, 0;
	selp.b32	%r1507, %r504, %r1251, %p260;
	clz.b32 	%r1506, %r1502;
	setp.eq.s32	%p261, %r1506, 0;
	shl.b32 	%r1252, %r1502, %r1506;
	mov.u32 	%r1253, 32;
	sub.s32 	%r1254, %r1253, %r1506;
	shr.u32 	%r1255, %r1504, %r1254;
	add.s32 	%r1256, %r1255, %r1252;
	selp.b32	%r513, %r1502, %r1256, %p261;
	mov.u32 	%r1257, -921707870;
	mul.hi.u32 	%r1505, %r513, %r1257;
	setp.lt.s32	%p262, %r1505, 1;
	@%p262 bra 	BB1_361;

	mul.lo.s32 	%r1258, %r513, -921707870;
	shr.u32 	%r1259, %r1258, 31;
	shl.b32 	%r1260, %r1505, 1;
	add.s32 	%r1505, %r1259, %r1260;
	add.s32 	%r1506, %r1506, 1;

BB1_361:
	mov.u32 	%r1261, 126;
	sub.s32 	%r1262, %r1261, %r1506;
	shl.b32 	%r1263, %r1262, 23;
	add.s32 	%r1264, %r1505, 1;
	shr.u32 	%r1265, %r1264, 7;
	add.s32 	%r1266, %r1265, 1;
	shr.u32 	%r1267, %r1266, 1;
	add.s32 	%r1268, %r1267, %r1263;
	or.b32  	%r1269, %r1268, %r509;
	mov.b32 	 %f1296, %r1269;

BB1_362:
	mul.rn.f32 	%f338, %f1296, %f1296;
	add.s32 	%r520, %r1507, 1;
	and.b32  	%r521, %r520, 1;
	setp.eq.s32	%p263, %r521, 0;
	@%p263 bra 	BB1_364;
	bra.uni 	BB1_363;

BB1_364:
	mov.f32 	%f1115, 0f3C08839E;
	mov.f32 	%f1116, 0fB94CA1F9;
	fma.rn.f32 	%f1297, %f1116, %f338, %f1115;
	bra.uni 	BB1_365;

BB1_363:
	mov.f32 	%f1113, 0fBAB6061A;
	mov.f32 	%f1114, 0f37CCF5CE;
	fma.rn.f32 	%f1297, %f1114, %f338, %f1113;

BB1_365:
	@%p263 bra 	BB1_367;
	bra.uni 	BB1_366;

BB1_367:
	mov.f32 	%f1120, 0fBE2AAAA3;
	fma.rn.f32 	%f1121, %f1297, %f338, %f1120;
	mov.f32 	%f1122, 0f00000000;
	fma.rn.f32 	%f1298, %f1121, %f338, %f1122;
	bra.uni 	BB1_368;

BB1_366:
	mov.f32 	%f1117, 0f3D2AAAA5;
	fma.rn.f32 	%f1118, %f1297, %f338, %f1117;
	mov.f32 	%f1119, 0fBF000000;
	fma.rn.f32 	%f1298, %f1118, %f338, %f1119;

BB1_368:
	fma.rn.f32 	%f1299, %f1298, %f1296, %f1296;
	@%p263 bra 	BB1_370;

	mov.f32 	%f1123, 0f3F800000;
	fma.rn.f32 	%f1299, %f1298, %f338, %f1123;

BB1_370:
	and.b32  	%r1270, %r520, 2;
	setp.eq.s32	%p266, %r1270, 0;
	@%p266 bra 	BB1_372;

	mov.f32 	%f1124, 0f00000000;
	mov.f32 	%f1125, 0fBF800000;
	fma.rn.f32 	%f1299, %f1299, %f1125, %f1124;

BB1_372:
	mov.f32 	%f1301, %f331;
	@%p254 bra 	BB1_374;

	mov.f32 	%f1126, 0f00000000;
	mul.rn.f32 	%f1301, %f331, %f1126;

BB1_374:
	mul.f32 	%f1127, %f1301, 0f3F22F983;
	cvt.rni.s32.f32	%r1517, %f1127;
	cvt.rn.f32.s32	%f1128, %r1517;
	neg.f32 	%f1129, %f1128;
	fma.rn.f32 	%f1131, %f1129, %f1084, %f1301;
	fma.rn.f32 	%f1133, %f1129, %f1086, %f1131;
	fma.rn.f32 	%f1303, %f1129, %f1088, %f1133;
	abs.f32 	%f1135, %f1301;
	setp.leu.f32	%p268, %f1135, 0f47CE4780;
	@%p268 bra 	BB1_384;

	mov.b32 	 %r523, %f1301;
	shr.u32 	%r524, %r523, 23;
	bfe.u32 	%r1273, %r523, 23, 8;
	add.s32 	%r1274, %r1273, -128;
	shl.b32 	%r1275, %r523, 8;
	or.b32  	%r525, %r1275, -2147483648;
	shr.u32 	%r526, %r1274, 5;
	mov.u32 	%r1509, 0;
	mov.u64 	%rd145, __cudart_i2opi_f;
	mov.u32 	%r1508, -6;
	mov.u64 	%rd164, %rd1;

BB1_376:
	.pragma "nounroll";
	ld.const.u32 	%r1278, [%rd145];
	// inline asm
	{
	mad.lo.cc.u32   %r1276, %r1278, %r525, %r1509;
	madc.hi.u32     %r1277, %r1278, %r525,  0;
	}
	// inline asm
	mov.u32 	%r1509, %r1277;
	st.local.u32 	[%rd164], %r1276;
	add.s64 	%rd164, %rd164, 4;
	add.s64 	%rd145, %rd145, 4;
	add.s32 	%r1508, %r1508, 1;
	setp.ne.s32	%p269, %r1508, 0;
	@%p269 bra 	BB1_376;

	and.b32  	%r531, %r523, -2147483648;
	st.local.u32 	[%rd1+24], %r1277;
	mov.u32 	%r1281, 6;
	sub.s32 	%r1282, %r1281, %r526;
	mul.wide.s32 	%rd127, %r1282, 4;
	add.s64 	%rd89, %rd1, %rd127;
	ld.local.u32 	%r1510, [%rd89];
	ld.local.u32 	%r1511, [%rd89+-4];
	and.b32  	%r534, %r524, 31;
	setp.eq.s32	%p270, %r534, 0;
	@%p270 bra 	BB1_379;

	mov.u32 	%r1283, 32;
	sub.s32 	%r1284, %r1283, %r534;
	shr.u32 	%r1285, %r1511, %r1284;
	shl.b32 	%r1286, %r1510, %r534;
	add.s32 	%r1510, %r1285, %r1286;
	ld.local.u32 	%r1287, [%rd89+-8];
	shr.u32 	%r1288, %r1287, %r1284;
	shl.b32 	%r1289, %r1511, %r534;
	add.s32 	%r1511, %r1288, %r1289;

BB1_379:
	shr.u32 	%r1290, %r1511, 30;
	shl.b32 	%r1291, %r1510, 2;
	add.s32 	%r1512, %r1290, %r1291;
	shl.b32 	%r540, %r1511, 2;
	shr.u32 	%r1292, %r1512, 31;
	shr.u32 	%r1293, %r1510, 30;
	add.s32 	%r541, %r1292, %r1293;
	setp.eq.s32	%p271, %r1292, 0;
	mov.u32 	%r1513, %r531;
	mov.u32 	%r1514, %r540;
	@%p271 bra 	BB1_381;

	not.b32 	%r1294, %r1512;
	neg.s32 	%r542, %r540;
	setp.eq.s32	%p272, %r540, 0;
	selp.u32	%r1295, 1, 0, %p272;
	add.s32 	%r1512, %r1295, %r1294;
	xor.b32  	%r544, %r531, -2147483648;
	mov.u32 	%r1513, %r544;
	mov.u32 	%r1514, %r542;

BB1_381:
	mov.u32 	%r546, %r1513;
	neg.s32 	%r1296, %r541;
	setp.eq.s32	%p273, %r531, 0;
	selp.b32	%r1517, %r541, %r1296, %p273;
	clz.b32 	%r1516, %r1512;
	setp.eq.s32	%p274, %r1516, 0;
	shl.b32 	%r1297, %r1512, %r1516;
	mov.u32 	%r1298, 32;
	sub.s32 	%r1299, %r1298, %r1516;
	shr.u32 	%r1300, %r1514, %r1299;
	add.s32 	%r1301, %r1300, %r1297;
	selp.b32	%r550, %r1512, %r1301, %p274;
	mov.u32 	%r1302, -921707870;
	mul.hi.u32 	%r1515, %r550, %r1302;
	setp.lt.s32	%p275, %r1515, 1;
	@%p275 bra 	BB1_383;

	mul.lo.s32 	%r1303, %r550, -921707870;
	shr.u32 	%r1304, %r1303, 31;
	shl.b32 	%r1305, %r1515, 1;
	add.s32 	%r1515, %r1304, %r1305;
	add.s32 	%r1516, %r1516, 1;

BB1_383:
	mov.u32 	%r1306, 126;
	sub.s32 	%r1307, %r1306, %r1516;
	shl.b32 	%r1308, %r1307, 23;
	add.s32 	%r1309, %r1515, 1;
	shr.u32 	%r1310, %r1309, 7;
	add.s32 	%r1311, %r1310, 1;
	shr.u32 	%r1312, %r1311, 1;
	add.s32 	%r1313, %r1312, %r1308;
	or.b32  	%r1314, %r1313, %r546;
	mov.b32 	 %f1303, %r1314;

BB1_384:
	mul.rn.f32 	%f355, %f1303, %f1303;
	and.b32  	%r557, %r1517, 1;
	setp.eq.s32	%p276, %r557, 0;
	@%p276 bra 	BB1_386;
	bra.uni 	BB1_385;

BB1_386:
	mov.f32 	%f1138, 0f3C08839E;
	mov.f32 	%f1139, 0fB94CA1F9;
	fma.rn.f32 	%f1304, %f1139, %f355, %f1138;
	bra.uni 	BB1_387;

BB1_385:
	mov.f32 	%f1136, 0fBAB6061A;
	mov.f32 	%f1137, 0f37CCF5CE;
	fma.rn.f32 	%f1304, %f1137, %f355, %f1136;

BB1_387:
	@%p276 bra 	BB1_389;
	bra.uni 	BB1_388;

BB1_389:
	mov.f32 	%f1143, 0fBE2AAAA3;
	fma.rn.f32 	%f1144, %f1304, %f355, %f1143;
	mov.f32 	%f1145, 0f00000000;
	fma.rn.f32 	%f1305, %f1144, %f355, %f1145;
	bra.uni 	BB1_390;

BB1_388:
	mov.f32 	%f1140, 0f3D2AAAA5;
	fma.rn.f32 	%f1141, %f1304, %f355, %f1140;
	mov.f32 	%f1142, 0fBF000000;
	fma.rn.f32 	%f1305, %f1141, %f355, %f1142;

BB1_390:
	fma.rn.f32 	%f1306, %f1305, %f1303, %f1303;
	@%p276 bra 	BB1_392;

	mov.f32 	%f1146, 0f3F800000;
	fma.rn.f32 	%f1306, %f1305, %f355, %f1146;

BB1_392:
	and.b32  	%r1315, %r1517, 2;
	setp.eq.s32	%p279, %r1315, 0;
	@%p279 bra 	BB1_394;

	mov.f32 	%f1147, 0f00000000;
	mov.f32 	%f1148, 0fBF800000;
	fma.rn.f32 	%f1306, %f1306, %f1148, %f1147;

BB1_394:
	mul.f32 	%f1149, %f297, %f1295;
	add.f32 	%f1248, %f311, 0f3F800000;
	mul.f32 	%f368, %f1149, %f1299;
	mul.f32 	%f369, %f1149, %f1306;
	mov.f32 	%f1308, %f312;
	@%p241 bra 	BB1_396;

	mov.f32 	%f1150, 0f00000000;
	mul.rn.f32 	%f1308, %f312, %f1150;

BB1_396:
	mul.f32 	%f1151, %f1308, 0f3F22F983;
	cvt.rni.s32.f32	%r1527, %f1151;
	cvt.rn.f32.s32	%f1152, %r1527;
	neg.f32 	%f1153, %f1152;
	fma.rn.f32 	%f1155, %f1153, %f1084, %f1308;
	fma.rn.f32 	%f1157, %f1153, %f1086, %f1155;
	fma.rn.f32 	%f1310, %f1153, %f1088, %f1157;
	abs.f32 	%f1159, %f1308;
	setp.leu.f32	%p281, %f1159, 0f47CE4780;
	@%p281 bra 	BB1_406;

	mov.b32 	 %r559, %f1308;
	shr.u32 	%r560, %r559, 23;
	bfe.u32 	%r1318, %r559, 23, 8;
	add.s32 	%r1319, %r1318, -128;
	shl.b32 	%r1320, %r559, 8;
	or.b32  	%r561, %r1320, -2147483648;
	shr.u32 	%r562, %r1319, 5;
	mov.u32 	%r1519, 0;
	mov.u64 	%rd146, __cudart_i2opi_f;
	mov.u32 	%r1518, -6;
	mov.u64 	%rd163, %rd1;

BB1_398:
	.pragma "nounroll";
	ld.const.u32 	%r1323, [%rd146];
	// inline asm
	{
	mad.lo.cc.u32   %r1321, %r1323, %r561, %r1519;
	madc.hi.u32     %r1322, %r1323, %r561,  0;
	}
	// inline asm
	mov.u32 	%r1519, %r1322;
	st.local.u32 	[%rd163], %r1321;
	add.s64 	%rd163, %rd163, 4;
	add.s64 	%rd146, %rd146, 4;
	add.s32 	%r1518, %r1518, 1;
	setp.ne.s32	%p282, %r1518, 0;
	@%p282 bra 	BB1_398;

	and.b32  	%r567, %r559, -2147483648;
	st.local.u32 	[%rd1+24], %r1322;
	mov.u32 	%r1326, 6;
	sub.s32 	%r1327, %r1326, %r562;
	mul.wide.s32 	%rd129, %r1327, 4;
	add.s64 	%rd94, %rd1, %rd129;
	ld.local.u32 	%r1520, [%rd94];
	ld.local.u32 	%r1521, [%rd94+-4];
	and.b32  	%r570, %r560, 31;
	setp.eq.s32	%p283, %r570, 0;
	@%p283 bra 	BB1_401;

	mov.u32 	%r1328, 32;
	sub.s32 	%r1329, %r1328, %r570;
	shr.u32 	%r1330, %r1521, %r1329;
	shl.b32 	%r1331, %r1520, %r570;
	add.s32 	%r1520, %r1330, %r1331;
	ld.local.u32 	%r1332, [%rd94+-8];
	shr.u32 	%r1333, %r1332, %r1329;
	shl.b32 	%r1334, %r1521, %r570;
	add.s32 	%r1521, %r1333, %r1334;

BB1_401:
	shr.u32 	%r1335, %r1521, 30;
	shl.b32 	%r1336, %r1520, 2;
	add.s32 	%r1522, %r1335, %r1336;
	shl.b32 	%r576, %r1521, 2;
	shr.u32 	%r1337, %r1522, 31;
	shr.u32 	%r1338, %r1520, 30;
	add.s32 	%r577, %r1337, %r1338;
	setp.eq.s32	%p284, %r1337, 0;
	mov.u32 	%r1523, %r567;
	mov.u32 	%r1524, %r576;
	@%p284 bra 	BB1_403;

	not.b32 	%r1339, %r1522;
	neg.s32 	%r578, %r576;
	setp.eq.s32	%p285, %r576, 0;
	selp.u32	%r1340, 1, 0, %p285;
	add.s32 	%r1522, %r1340, %r1339;
	xor.b32  	%r580, %r567, -2147483648;
	mov.u32 	%r1523, %r580;
	mov.u32 	%r1524, %r578;

BB1_403:
	mov.u32 	%r582, %r1523;
	neg.s32 	%r1341, %r577;
	setp.eq.s32	%p286, %r567, 0;
	selp.b32	%r1527, %r577, %r1341, %p286;
	clz.b32 	%r1526, %r1522;
	setp.eq.s32	%p287, %r1526, 0;
	shl.b32 	%r1342, %r1522, %r1526;
	mov.u32 	%r1343, 32;
	sub.s32 	%r1344, %r1343, %r1526;
	shr.u32 	%r1345, %r1524, %r1344;
	add.s32 	%r1346, %r1345, %r1342;
	selp.b32	%r586, %r1522, %r1346, %p287;
	mov.u32 	%r1347, -921707870;
	mul.hi.u32 	%r1525, %r586, %r1347;
	setp.lt.s32	%p288, %r1525, 1;
	@%p288 bra 	BB1_405;

	mul.lo.s32 	%r1348, %r586, -921707870;
	shr.u32 	%r1349, %r1348, 31;
	shl.b32 	%r1350, %r1525, 1;
	add.s32 	%r1525, %r1349, %r1350;
	add.s32 	%r1526, %r1526, 1;

BB1_405:
	mov.u32 	%r1351, 126;
	sub.s32 	%r1352, %r1351, %r1526;
	shl.b32 	%r1353, %r1352, 23;
	add.s32 	%r1354, %r1525, 1;
	shr.u32 	%r1355, %r1354, 7;
	add.s32 	%r1356, %r1355, 1;
	shr.u32 	%r1357, %r1356, 1;
	add.s32 	%r1358, %r1357, %r1353;
	or.b32  	%r1359, %r1358, %r582;
	mov.b32 	 %f1310, %r1359;

BB1_406:
	mul.rn.f32 	%f375, %f1310, %f1310;
	add.s32 	%r593, %r1527, 1;
	and.b32  	%r594, %r593, 1;
	setp.eq.s32	%p289, %r594, 0;
	@%p289 bra 	BB1_408;
	bra.uni 	BB1_407;

BB1_408:
	mov.f32 	%f1162, 0f3C08839E;
	mov.f32 	%f1163, 0fB94CA1F9;
	fma.rn.f32 	%f1311, %f1163, %f375, %f1162;
	bra.uni 	BB1_409;

BB1_407:
	mov.f32 	%f1160, 0fBAB6061A;
	mov.f32 	%f1161, 0f37CCF5CE;
	fma.rn.f32 	%f1311, %f1161, %f375, %f1160;

BB1_409:
	@%p289 bra 	BB1_411;
	bra.uni 	BB1_410;

BB1_411:
	mov.f32 	%f1167, 0fBE2AAAA3;
	fma.rn.f32 	%f1168, %f1311, %f375, %f1167;
	mov.f32 	%f1169, 0f00000000;
	fma.rn.f32 	%f1312, %f1168, %f375, %f1169;
	bra.uni 	BB1_412;

BB1_410:
	mov.f32 	%f1164, 0f3D2AAAA5;
	fma.rn.f32 	%f1165, %f1311, %f375, %f1164;
	mov.f32 	%f1166, 0fBF000000;
	fma.rn.f32 	%f1312, %f1165, %f375, %f1166;

BB1_412:
	fma.rn.f32 	%f1313, %f1312, %f1310, %f1310;
	@%p289 bra 	BB1_414;

	mov.f32 	%f1170, 0f3F800000;
	fma.rn.f32 	%f1313, %f1312, %f375, %f1170;

BB1_414:
	and.b32  	%r1360, %r593, 2;
	setp.eq.s32	%p292, %r1360, 0;
	@%p292 bra 	BB1_416;

	mov.f32 	%f1171, 0f00000000;
	mov.f32 	%f1172, 0fBF800000;
	fma.rn.f32 	%f1313, %f1313, %f1172, %f1171;

BB1_416:
	ld.param.f32 	%f1206, [_ZN10Mandelbulb12evalDistanceE6float3_param_1+8];
	ld.param.f32 	%f1205, [_ZN10Mandelbulb12evalDistanceE6float3_param_1+4];
	ld.param.f32 	%f1204, [_ZN10Mandelbulb12evalDistanceE6float3_param_1];
	add.f32 	%f1251, %f1204, %f368;
	add.f32 	%f1250, %f1205, %f369;
	fma.rn.f32 	%f1249, %f297, %f1313, %f1206;

BB1_421:
	setp.ne.s32	%p298, %r1427, 0;
	@%p298 bra 	BB1_148;

BB1_422:
	st.param.f32	[func_retval0+0], %f1315;
	ret;
}

	// .globl	_ZN10TunnelTest14evalParametersEv
.visible .func _ZN10TunnelTest14evalParametersEv(
	.param .b64 _ZN10TunnelTest14evalParametersEv_param_0
)
{



	ret;
}

	// .globl	_ZN10TunnelTest12evalDistanceE6float3
.visible .func  (.param .b32 func_retval0) _ZN10TunnelTest12evalDistanceE6float3(
	.param .b64 _ZN10TunnelTest12evalDistanceE6float3_param_0,
	.param .align 4 .b8 _ZN10TunnelTest12evalDistanceE6float3_param_1[12]
)
{
	.local .align 4 .b8 	__local_depot3[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<171>;
	.reg .f32 	%f<635>;
	.reg .s32 	%r<641>;
	.reg .f64 	%fd<3>;
	.reg .s64 	%rd<79>;


	mov.u64 	%rd78, __local_depot3;
	cvta.local.u64 	%SP, %rd78;
	ld.param.u64 	%rd42, [_ZN10TunnelTest12evalDistanceE6float3_param_0];
	ld.param.f32 	%f201, [_ZN10TunnelTest12evalDistanceE6float3_param_1+8];
	ld.param.f32 	%f200, [_ZN10TunnelTest12evalDistanceE6float3_param_1+4];
	ld.param.f32 	%f199, [_ZN10TunnelTest12evalDistanceE6float3_param_1];
	add.u64 	%rd43, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd43;
	add.s64 	%rd2, %rd42, 12;
	ld.f32 	%f1, [%rd42+12];
	div.rn.f32 	%f581, %f1, 0f41900000;
	abs.f32 	%f202, %f581;
	setp.neu.f32	%p1, %f202, 0f7F800000;
	@%p1 bra 	BB3_2;

	mov.f32 	%f203, 0f00000000;
	mul.rn.f32 	%f581, %f581, %f203;

BB3_2:
	abs.f32 	%f204, %f581;
	add.s64 	%rd3, %rd1, 24;
	setp.leu.f32	%p2, %f204, 0f47CE4780;
	@%p2 bra 	BB3_6;

	mov.b32 	 %r237, %f581;
	shl.b32 	%r238, %r237, 8;
	or.b32  	%r1, %r238, -2147483648;
	mov.u32 	%r579, 0;
	mov.u64 	%rd58, __cudart_i2opi_f;
	mov.u32 	%r578, -6;
	mov.u64 	%rd77, %rd1;

BB3_4:
	.pragma "nounroll";
	ld.const.u32 	%r241, [%rd58];
	// inline asm
	{
	mad.lo.cc.u32   %r239, %r241, %r1, %r579;
	madc.hi.u32     %r240, %r241, %r1,  0;
	}
	// inline asm
	mov.u32 	%r579, %r240;
	st.local.u32 	[%rd77], %r239;
	add.s64 	%rd77, %rd77, 4;
	add.s64 	%rd58, %rd58, 4;
	add.s32 	%r578, %r578, 1;
	setp.ne.s32	%p3, %r578, 0;
	@%p3 bra 	BB3_4;

	st.local.u32 	[%rd3], %r240;

BB3_6:
	div.rn.f32 	%f582, %f1, 0f40B66666;
	abs.f32 	%f205, %f582;
	setp.neu.f32	%p4, %f205, 0f7F800000;
	@%p4 bra 	BB3_8;

	mov.f32 	%f206, 0f00000000;
	mul.rn.f32 	%f582, %f582, %f206;

BB3_8:
	mul.f32 	%f207, %f582, 0f3F22F983;
	cvt.rni.s32.f32	%r589, %f207;
	cvt.rn.f32.s32	%f208, %r589;
	neg.f32 	%f209, %f208;
	mov.f32 	%f210, 0f3FC90FDA;
	fma.rn.f32 	%f211, %f209, %f210, %f582;
	mov.f32 	%f212, 0f33A22168;
	fma.rn.f32 	%f213, %f209, %f212, %f211;
	mov.f32 	%f214, 0f27C234C5;
	fma.rn.f32 	%f583, %f209, %f214, %f213;
	abs.f32 	%f215, %f582;
	setp.leu.f32	%p5, %f215, 0f47CE4780;
	@%p5 bra 	BB3_18;

	mov.b32 	 %r7, %f582;
	shr.u32 	%r8, %r7, 23;
	bfe.u32 	%r246, %r7, 23, 8;
	add.s32 	%r247, %r246, -128;
	shl.b32 	%r248, %r7, 8;
	or.b32  	%r9, %r248, -2147483648;
	shr.u32 	%r10, %r247, 5;
	mov.u32 	%r581, 0;
	mov.u64 	%rd59, __cudart_i2opi_f;
	mov.u32 	%r580, -6;
	mov.u64 	%rd76, %rd1;

BB3_10:
	.pragma "nounroll";
	ld.const.u32 	%r251, [%rd59];
	// inline asm
	{
	mad.lo.cc.u32   %r249, %r251, %r9, %r581;
	madc.hi.u32     %r250, %r251, %r9,  0;
	}
	// inline asm
	mov.u32 	%r581, %r250;
	st.local.u32 	[%rd76], %r249;
	add.s64 	%rd76, %rd76, 4;
	add.s64 	%rd59, %rd59, 4;
	add.s32 	%r580, %r580, 1;
	setp.ne.s32	%p6, %r580, 0;
	@%p6 bra 	BB3_10;

	and.b32  	%r15, %r7, -2147483648;
	st.local.u32 	[%rd3], %r250;
	mov.u32 	%r254, 6;
	sub.s32 	%r255, %r254, %r10;
	mul.wide.s32 	%rd46, %r255, 4;
	add.s64 	%rd14, %rd1, %rd46;
	ld.local.u32 	%r582, [%rd14];
	ld.local.u32 	%r583, [%rd14+-4];
	and.b32  	%r18, %r8, 31;
	setp.eq.s32	%p7, %r18, 0;
	@%p7 bra 	BB3_13;

	mov.u32 	%r256, 32;
	sub.s32 	%r257, %r256, %r18;
	shr.u32 	%r258, %r583, %r257;
	shl.b32 	%r259, %r582, %r18;
	add.s32 	%r582, %r258, %r259;
	ld.local.u32 	%r260, [%rd14+-8];
	shr.u32 	%r261, %r260, %r257;
	shl.b32 	%r262, %r583, %r18;
	add.s32 	%r583, %r261, %r262;

BB3_13:
	shr.u32 	%r263, %r583, 30;
	shl.b32 	%r264, %r582, 2;
	add.s32 	%r584, %r263, %r264;
	shl.b32 	%r24, %r583, 2;
	shr.u32 	%r265, %r584, 31;
	shr.u32 	%r266, %r582, 30;
	add.s32 	%r25, %r265, %r266;
	setp.eq.s32	%p8, %r265, 0;
	mov.u32 	%r585, %r15;
	mov.u32 	%r586, %r24;
	@%p8 bra 	BB3_15;

	not.b32 	%r267, %r584;
	neg.s32 	%r26, %r24;
	setp.eq.s32	%p9, %r24, 0;
	selp.u32	%r268, 1, 0, %p9;
	add.s32 	%r584, %r268, %r267;
	xor.b32  	%r28, %r15, -2147483648;
	mov.u32 	%r585, %r28;
	mov.u32 	%r586, %r26;

BB3_15:
	mov.u32 	%r30, %r585;
	neg.s32 	%r269, %r25;
	setp.eq.s32	%p10, %r15, 0;
	selp.b32	%r589, %r25, %r269, %p10;
	clz.b32 	%r588, %r584;
	setp.eq.s32	%p11, %r588, 0;
	shl.b32 	%r270, %r584, %r588;
	mov.u32 	%r271, 32;
	sub.s32 	%r272, %r271, %r588;
	shr.u32 	%r273, %r586, %r272;
	add.s32 	%r274, %r273, %r270;
	selp.b32	%r34, %r584, %r274, %p11;
	mov.u32 	%r275, -921707870;
	mul.hi.u32 	%r587, %r34, %r275;
	setp.lt.s32	%p12, %r587, 1;
	@%p12 bra 	BB3_17;

	mul.lo.s32 	%r276, %r34, -921707870;
	shr.u32 	%r277, %r276, 31;
	shl.b32 	%r278, %r587, 1;
	add.s32 	%r587, %r277, %r278;
	add.s32 	%r588, %r588, 1;

BB3_17:
	mov.u32 	%r279, 126;
	sub.s32 	%r280, %r279, %r588;
	shl.b32 	%r281, %r280, 23;
	add.s32 	%r282, %r587, 1;
	shr.u32 	%r283, %r282, 7;
	add.s32 	%r284, %r283, 1;
	shr.u32 	%r285, %r284, 1;
	add.s32 	%r286, %r285, %r281;
	or.b32  	%r287, %r286, %r30;
	mov.b32 	 %f583, %r287;

BB3_18:
	mul.rn.f32 	%f11, %f583, %f583;
	add.s32 	%r41, %r589, 1;
	and.b32  	%r42, %r41, 1;
	setp.eq.s32	%p13, %r42, 0;
	@%p13 bra 	BB3_20;

	mov.f32 	%f216, 0fBAB6061A;
	mov.f32 	%f217, 0f37CCF5CE;
	fma.rn.f32 	%f584, %f217, %f11, %f216;
	bra.uni 	BB3_21;

BB3_20:
	mov.f32 	%f218, 0f3C08839E;
	mov.f32 	%f219, 0fB94CA1F9;
	fma.rn.f32 	%f584, %f219, %f11, %f218;

BB3_21:
	@%p13 bra 	BB3_23;

	mov.f32 	%f220, 0f3D2AAAA5;
	fma.rn.f32 	%f221, %f584, %f11, %f220;
	mov.f32 	%f222, 0fBF000000;
	fma.rn.f32 	%f585, %f221, %f11, %f222;
	bra.uni 	BB3_24;

BB3_23:
	mov.f32 	%f223, 0fBE2AAAA3;
	fma.rn.f32 	%f224, %f584, %f11, %f223;
	mov.f32 	%f225, 0f00000000;
	fma.rn.f32 	%f585, %f224, %f11, %f225;

BB3_24:
	fma.rn.f32 	%f586, %f585, %f583, %f583;
	@%p13 bra 	BB3_26;

	mov.f32 	%f226, 0f3F800000;
	fma.rn.f32 	%f586, %f585, %f11, %f226;

BB3_26:
	and.b32  	%r288, %r41, 2;
	setp.eq.s32	%p16, %r288, 0;
	@%p16 bra 	BB3_28;

	mov.f32 	%f227, 0f00000000;
	mov.f32 	%f228, 0fBF800000;
	fma.rn.f32 	%f586, %f586, %f228, %f227;

BB3_28:
	div.rn.f32 	%f587, %f1, 0f3FD9999A;
	abs.f32 	%f229, %f587;
	setp.neu.f32	%p17, %f229, 0f7F800000;
	@%p17 bra 	BB3_30;

	mov.f32 	%f230, 0f00000000;
	mul.rn.f32 	%f587, %f587, %f230;

BB3_30:
	mul.f32 	%f231, %f587, 0f3F22F983;
	cvt.rni.s32.f32	%r599, %f231;
	cvt.rn.f32.s32	%f232, %r599;
	neg.f32 	%f233, %f232;
	fma.rn.f32 	%f235, %f233, %f210, %f587;
	fma.rn.f32 	%f237, %f233, %f212, %f235;
	fma.rn.f32 	%f588, %f233, %f214, %f237;
	abs.f32 	%f239, %f587;
	setp.leu.f32	%p18, %f239, 0f47CE4780;
	@%p18 bra 	BB3_40;

	mov.b32 	 %r44, %f587;
	shr.u32 	%r45, %r44, 23;
	bfe.u32 	%r291, %r44, 23, 8;
	add.s32 	%r292, %r291, -128;
	shl.b32 	%r293, %r44, 8;
	or.b32  	%r46, %r293, -2147483648;
	shr.u32 	%r47, %r292, 5;
	mov.u32 	%r591, 0;
	mov.u64 	%rd60, __cudart_i2opi_f;
	mov.u32 	%r590, -6;
	mov.u64 	%rd75, %rd1;

BB3_32:
	.pragma "nounroll";
	ld.const.u32 	%r296, [%rd60];
	// inline asm
	{
	mad.lo.cc.u32   %r294, %r296, %r46, %r591;
	madc.hi.u32     %r295, %r296, %r46,  0;
	}
	// inline asm
	mov.u32 	%r591, %r295;
	st.local.u32 	[%rd75], %r294;
	add.s64 	%rd75, %rd75, 4;
	add.s64 	%rd60, %rd60, 4;
	add.s32 	%r590, %r590, 1;
	setp.ne.s32	%p19, %r590, 0;
	@%p19 bra 	BB3_32;

	and.b32  	%r52, %r44, -2147483648;
	st.local.u32 	[%rd3], %r295;
	mov.u32 	%r299, 6;
	sub.s32 	%r300, %r299, %r47;
	mul.wide.s32 	%rd48, %r300, 4;
	add.s64 	%rd20, %rd1, %rd48;
	ld.local.u32 	%r592, [%rd20];
	ld.local.u32 	%r593, [%rd20+-4];
	and.b32  	%r55, %r45, 31;
	setp.eq.s32	%p20, %r55, 0;
	@%p20 bra 	BB3_35;

	mov.u32 	%r301, 32;
	sub.s32 	%r302, %r301, %r55;
	shr.u32 	%r303, %r593, %r302;
	shl.b32 	%r304, %r592, %r55;
	add.s32 	%r592, %r303, %r304;
	ld.local.u32 	%r305, [%rd20+-8];
	shr.u32 	%r306, %r305, %r302;
	shl.b32 	%r307, %r593, %r55;
	add.s32 	%r593, %r306, %r307;

BB3_35:
	shr.u32 	%r308, %r593, 30;
	shl.b32 	%r309, %r592, 2;
	add.s32 	%r594, %r308, %r309;
	shl.b32 	%r61, %r593, 2;
	shr.u32 	%r310, %r594, 31;
	shr.u32 	%r311, %r592, 30;
	add.s32 	%r62, %r310, %r311;
	setp.eq.s32	%p21, %r310, 0;
	mov.u32 	%r595, %r52;
	mov.u32 	%r596, %r61;
	@%p21 bra 	BB3_37;

	not.b32 	%r312, %r594;
	neg.s32 	%r63, %r61;
	setp.eq.s32	%p22, %r61, 0;
	selp.u32	%r313, 1, 0, %p22;
	add.s32 	%r594, %r313, %r312;
	xor.b32  	%r65, %r52, -2147483648;
	mov.u32 	%r595, %r65;
	mov.u32 	%r596, %r63;

BB3_37:
	mov.u32 	%r67, %r595;
	neg.s32 	%r314, %r62;
	setp.eq.s32	%p23, %r52, 0;
	selp.b32	%r599, %r62, %r314, %p23;
	clz.b32 	%r598, %r594;
	setp.eq.s32	%p24, %r598, 0;
	shl.b32 	%r315, %r594, %r598;
	mov.u32 	%r316, 32;
	sub.s32 	%r317, %r316, %r598;
	shr.u32 	%r318, %r596, %r317;
	add.s32 	%r319, %r318, %r315;
	selp.b32	%r71, %r594, %r319, %p24;
	mov.u32 	%r320, -921707870;
	mul.hi.u32 	%r597, %r71, %r320;
	setp.lt.s32	%p25, %r597, 1;
	@%p25 bra 	BB3_39;

	mul.lo.s32 	%r321, %r71, -921707870;
	shr.u32 	%r322, %r321, 31;
	shl.b32 	%r323, %r597, 1;
	add.s32 	%r597, %r322, %r323;
	add.s32 	%r598, %r598, 1;

BB3_39:
	mov.u32 	%r324, 126;
	sub.s32 	%r325, %r324, %r598;
	shl.b32 	%r326, %r325, 23;
	add.s32 	%r327, %r597, 1;
	shr.u32 	%r328, %r327, 7;
	add.s32 	%r329, %r328, 1;
	shr.u32 	%r330, %r329, 1;
	add.s32 	%r331, %r330, %r326;
	or.b32  	%r332, %r331, %r67;
	mov.b32 	 %f588, %r332;

BB3_40:
	mul.rn.f32 	%f29, %f588, %f588;
	add.s32 	%r78, %r599, 1;
	and.b32  	%r79, %r78, 1;
	setp.eq.s32	%p26, %r79, 0;
	@%p26 bra 	BB3_42;

	mov.f32 	%f240, 0fBAB6061A;
	mov.f32 	%f241, 0f37CCF5CE;
	fma.rn.f32 	%f589, %f241, %f29, %f240;
	bra.uni 	BB3_43;

BB3_42:
	mov.f32 	%f242, 0f3C08839E;
	mov.f32 	%f243, 0fB94CA1F9;
	fma.rn.f32 	%f589, %f243, %f29, %f242;

BB3_43:
	@%p26 bra 	BB3_45;

	mov.f32 	%f244, 0f3D2AAAA5;
	fma.rn.f32 	%f245, %f589, %f29, %f244;
	mov.f32 	%f246, 0fBF000000;
	fma.rn.f32 	%f590, %f245, %f29, %f246;
	bra.uni 	BB3_46;

BB3_45:
	mov.f32 	%f247, 0fBE2AAAA3;
	fma.rn.f32 	%f248, %f589, %f29, %f247;
	mov.f32 	%f249, 0f00000000;
	fma.rn.f32 	%f590, %f248, %f29, %f249;

BB3_46:
	fma.rn.f32 	%f591, %f590, %f588, %f588;
	@%p26 bra 	BB3_48;

	mov.f32 	%f250, 0f3F800000;
	fma.rn.f32 	%f591, %f590, %f29, %f250;

BB3_48:
	and.b32  	%r333, %r78, 2;
	setp.eq.s32	%p29, %r333, 0;
	@%p29 bra 	BB3_50;

	mov.f32 	%f251, 0f00000000;
	mov.f32 	%f252, 0fBF800000;
	fma.rn.f32 	%f591, %f591, %f252, %f251;

BB3_50:
	abs.f32 	%f594, %f199;
	setp.eq.f32	%p30, %f594, 0f7F800000;
	mov.f32 	%f254, 0f40000000;
	abs.f32 	%f43, %f254;
	setp.eq.f32	%p31, %f43, 0f00000000;
	or.pred  	%p32, %p30, %p31;
	mov.f32 	%f253, 0f7FFFFFFF;
	mov.f32 	%f605, %f253;
	@%p32 bra 	BB3_63;

	setp.ltu.f32	%p33, %f594, %f43;
	@%p33 bra 	BB3_62;
	bra.uni 	BB3_52;

BB3_62:
	setp.gtu.f32	%p46, %f43, 0f7F800000;
	add.f32 	%f275, %f199, 0f40000000;
	selp.f32	%f276, %f275, %f199, %p46;
	add.f32 	%f277, %f199, %f276;
	setp.leu.f32	%p47, %f594, 0f00000000;
	selp.f32	%f57, %f277, %f276, %p47;
	mov.f32 	%f605, %f57;
	bra.uni 	BB3_63;

BB3_52:
	lg2.approx.f32 	%f255, %f594;
	cvt.rzi.s32.f32	%r334, %f255;
	lg2.approx.f32 	%f256, %f43;
	cvt.rzi.s32.f32	%r335, %f256;
	sub.s32 	%r80, %r334, %r335;
	abs.f32 	%f44, %f43;
	setp.eq.f32	%p34, %f44, 0f00000000;
	setp.eq.f32	%p35, %f44, 0f7F800000;
	or.pred  	%p36, %p34, %p35;
	setp.eq.s32	%p37, %r334, %r335;
	or.pred  	%p38, %p36, %p37;
	@%p38 bra 	BB3_58;
	bra.uni 	BB3_53;

BB3_58:
	setp.leu.f32	%p41, %f44, 0f00000000;
	add.f32 	%f271, %f43, %f43;
	selp.f32	%f592, %f271, %f43, %p41;
	bra.uni 	BB3_59;

BB3_53:
	abs.s32 	%r81, %r80;
	setp.lt.s32	%p39, %r81, 126;
	@%p39 bra 	BB3_57;
	bra.uni 	BB3_54;

BB3_57:
	cvt.rn.f32.s32	%f270, %r80;
	// inline asm
	ex2.approx.ftz.f32 %f269,%f270;
	// inline asm
	mul.f32 	%f592, %f43, %f269;
	bra.uni 	BB3_59;

BB3_54:
	setp.lt.s32	%p40, %r81, 252;
	@%p40 bra 	BB3_56;
	bra.uni 	BB3_55;

BB3_56:
	shr.u32 	%r341, %r80, 31;
	add.s32 	%r342, %r80, %r341;
	shr.s32 	%r343, %r342, 1;
	cvt.rn.f32.s32	%f265, %r343;
	// inline asm
	ex2.approx.ftz.f32 %f264,%f265;
	// inline asm
	mul.f32 	%f268, %f43, %f264;
	sub.s32 	%r344, %r80, %r343;
	cvt.rn.f32.s32	%f267, %r344;
	// inline asm
	ex2.approx.ftz.f32 %f266,%f267;
	// inline asm
	mul.f32 	%f592, %f268, %f266;
	bra.uni 	BB3_59;

BB3_55:
	shr.s32 	%r336, %r80, 31;
	shr.u32 	%r337, %r336, 30;
	add.s32 	%r338, %r80, %r337;
	shr.s32 	%r339, %r338, 2;
	cvt.rn.f32.s32	%f258, %r339;
	// inline asm
	ex2.approx.ftz.f32 %f257,%f258;
	// inline asm
	mul.f32 	%f261, %f43, %f257;
	mul.f32 	%f262, %f257, %f261;
	mul.f32 	%f263, %f257, %f262;
	mad.lo.s32 	%r340, %r339, -3, %r80;
	cvt.rn.f32.s32	%f260, %r340;
	// inline asm
	ex2.approx.ftz.f32 %f259,%f260;
	// inline asm
	mul.f32 	%f592, %f259, %f263;

BB3_59:
	mul.f32 	%f272, %f594, 0f3F000000;
	setp.gtu.f32	%p42, %f592, %f272;
	add.f32 	%f273, %f592, %f592;
	selp.f32	%f593, %f592, %f273, %p42;
	setp.ltu.f32	%p43, %f593, %f43;
	@%p43 bra 	BB3_61;

BB3_60:
	sub.f32 	%f274, %f594, %f593;
	setp.ltu.f32	%p44, %f594, %f593;
	selp.f32	%f594, %f594, %f274, %p44;
	mul.f32 	%f593, %f593, 0f3F000000;
	setp.ge.f32	%p45, %f593, %f43;
	@%p45 bra 	BB3_60;

BB3_61:
	mov.b32 	 %r345, %f199;
	and.b32  	%r346, %r345, -2147483648;
	mov.b32 	 %r347, %f594;
	or.b32  	%r348, %r347, %r346;
	mov.b32 	 %f56, %r348;
	mov.f32 	%f605, %f56;

BB3_63:
	mov.f32 	%f58, %f605;
	abs.f32 	%f60, %f58;
	abs.f32 	%f597, %f200;
	setp.eq.f32	%p48, %f597, 0f7F800000;
	or.pred  	%p50, %p48, %p31;
	mov.f32 	%f604, %f253;
	@%p50 bra 	BB3_76;

	setp.ltu.f32	%p51, %f597, %f43;
	@%p51 bra 	BB3_75;
	bra.uni 	BB3_65;

BB3_75:
	setp.gtu.f32	%p64, %f43, 0f7F800000;
	add.f32 	%f299, %f200, 0f40000000;
	selp.f32	%f300, %f299, %f200, %p64;
	add.f32 	%f301, %f200, %f300;
	setp.leu.f32	%p65, %f597, 0f00000000;
	selp.f32	%f604, %f301, %f300, %p65;
	bra.uni 	BB3_76;

BB3_65:
	lg2.approx.f32 	%f279, %f597;
	cvt.rzi.s32.f32	%r349, %f279;
	lg2.approx.f32 	%f280, %f43;
	cvt.rzi.s32.f32	%r350, %f280;
	sub.s32 	%r82, %r349, %r350;
	abs.f32 	%f62, %f43;
	setp.eq.f32	%p52, %f62, 0f00000000;
	setp.eq.f32	%p53, %f62, 0f7F800000;
	or.pred  	%p54, %p52, %p53;
	setp.eq.s32	%p55, %r349, %r350;
	or.pred  	%p56, %p54, %p55;
	@%p56 bra 	BB3_71;
	bra.uni 	BB3_66;

BB3_71:
	setp.leu.f32	%p59, %f62, 0f00000000;
	add.f32 	%f295, %f43, %f43;
	selp.f32	%f595, %f295, %f43, %p59;
	bra.uni 	BB3_72;

BB3_66:
	abs.s32 	%r83, %r82;
	setp.lt.s32	%p57, %r83, 126;
	@%p57 bra 	BB3_70;
	bra.uni 	BB3_67;

BB3_70:
	cvt.rn.f32.s32	%f294, %r82;
	// inline asm
	ex2.approx.ftz.f32 %f293,%f294;
	// inline asm
	mul.f32 	%f595, %f43, %f293;
	bra.uni 	BB3_72;

BB3_67:
	setp.lt.s32	%p58, %r83, 252;
	@%p58 bra 	BB3_69;
	bra.uni 	BB3_68;

BB3_69:
	shr.u32 	%r356, %r82, 31;
	add.s32 	%r357, %r82, %r356;
	shr.s32 	%r358, %r357, 1;
	cvt.rn.f32.s32	%f289, %r358;
	// inline asm
	ex2.approx.ftz.f32 %f288,%f289;
	// inline asm
	mul.f32 	%f292, %f43, %f288;
	sub.s32 	%r359, %r82, %r358;
	cvt.rn.f32.s32	%f291, %r359;
	// inline asm
	ex2.approx.ftz.f32 %f290,%f291;
	// inline asm
	mul.f32 	%f595, %f292, %f290;
	bra.uni 	BB3_72;

BB3_68:
	shr.s32 	%r351, %r82, 31;
	shr.u32 	%r352, %r351, 30;
	add.s32 	%r353, %r82, %r352;
	shr.s32 	%r354, %r353, 2;
	cvt.rn.f32.s32	%f282, %r354;
	// inline asm
	ex2.approx.ftz.f32 %f281,%f282;
	// inline asm
	mul.f32 	%f285, %f43, %f281;
	mul.f32 	%f286, %f281, %f285;
	mul.f32 	%f287, %f281, %f286;
	mad.lo.s32 	%r355, %r354, -3, %r82;
	cvt.rn.f32.s32	%f284, %r355;
	// inline asm
	ex2.approx.ftz.f32 %f283,%f284;
	// inline asm
	mul.f32 	%f595, %f283, %f287;

BB3_72:
	mul.f32 	%f296, %f597, 0f3F000000;
	setp.gtu.f32	%p60, %f595, %f296;
	add.f32 	%f297, %f595, %f595;
	selp.f32	%f596, %f595, %f297, %p60;
	setp.ltu.f32	%p61, %f596, %f43;
	@%p61 bra 	BB3_74;

BB3_73:
	sub.f32 	%f298, %f597, %f596;
	setp.ltu.f32	%p62, %f597, %f596;
	selp.f32	%f597, %f597, %f298, %p62;
	mul.f32 	%f596, %f596, 0f3F000000;
	setp.ge.f32	%p63, %f596, %f43;
	@%p63 bra 	BB3_73;

BB3_74:
	mov.b32 	 %r360, %f200;
	and.b32  	%r361, %r360, -2147483648;
	mov.b32 	 %r362, %f597;
	or.b32  	%r363, %r362, %r361;
	mov.b32 	 %f604, %r363;

BB3_76:
	abs.f32 	%f78, %f604;
	abs.f32 	%f600, %f201;
	setp.eq.f32	%p66, %f600, 0f7F800000;
	or.pred  	%p68, %p66, %p31;
	mov.f32 	%f603, %f253;
	@%p68 bra 	BB3_89;

	setp.ltu.f32	%p69, %f600, %f43;
	@%p69 bra 	BB3_88;
	bra.uni 	BB3_78;

BB3_88:
	setp.gtu.f32	%p82, %f43, 0f7F800000;
	add.f32 	%f323, %f201, 0f40000000;
	selp.f32	%f324, %f323, %f201, %p82;
	add.f32 	%f325, %f201, %f324;
	setp.leu.f32	%p83, %f600, 0f00000000;
	selp.f32	%f603, %f325, %f324, %p83;
	bra.uni 	BB3_89;

BB3_78:
	lg2.approx.f32 	%f303, %f600;
	cvt.rzi.s32.f32	%r364, %f303;
	lg2.approx.f32 	%f304, %f43;
	cvt.rzi.s32.f32	%r365, %f304;
	sub.s32 	%r84, %r364, %r365;
	abs.f32 	%f80, %f43;
	setp.eq.f32	%p70, %f80, 0f00000000;
	setp.eq.f32	%p71, %f80, 0f7F800000;
	or.pred  	%p72, %p70, %p71;
	setp.eq.s32	%p73, %r364, %r365;
	or.pred  	%p74, %p72, %p73;
	@%p74 bra 	BB3_84;
	bra.uni 	BB3_79;

BB3_84:
	setp.leu.f32	%p77, %f80, 0f00000000;
	add.f32 	%f319, %f43, %f43;
	selp.f32	%f598, %f319, %f43, %p77;
	bra.uni 	BB3_85;

BB3_79:
	abs.s32 	%r85, %r84;
	setp.lt.s32	%p75, %r85, 126;
	@%p75 bra 	BB3_83;
	bra.uni 	BB3_80;

BB3_83:
	cvt.rn.f32.s32	%f318, %r84;
	// inline asm
	ex2.approx.ftz.f32 %f317,%f318;
	// inline asm
	mul.f32 	%f598, %f43, %f317;
	bra.uni 	BB3_85;

BB3_80:
	setp.lt.s32	%p76, %r85, 252;
	@%p76 bra 	BB3_82;
	bra.uni 	BB3_81;

BB3_82:
	shr.u32 	%r371, %r84, 31;
	add.s32 	%r372, %r84, %r371;
	shr.s32 	%r373, %r372, 1;
	cvt.rn.f32.s32	%f313, %r373;
	// inline asm
	ex2.approx.ftz.f32 %f312,%f313;
	// inline asm
	mul.f32 	%f316, %f43, %f312;
	sub.s32 	%r374, %r84, %r373;
	cvt.rn.f32.s32	%f315, %r374;
	// inline asm
	ex2.approx.ftz.f32 %f314,%f315;
	// inline asm
	mul.f32 	%f598, %f316, %f314;
	bra.uni 	BB3_85;

BB3_81:
	shr.s32 	%r366, %r84, 31;
	shr.u32 	%r367, %r366, 30;
	add.s32 	%r368, %r84, %r367;
	shr.s32 	%r369, %r368, 2;
	cvt.rn.f32.s32	%f306, %r369;
	// inline asm
	ex2.approx.ftz.f32 %f305,%f306;
	// inline asm
	mul.f32 	%f309, %f43, %f305;
	mul.f32 	%f310, %f305, %f309;
	mul.f32 	%f311, %f305, %f310;
	mad.lo.s32 	%r370, %r369, -3, %r84;
	cvt.rn.f32.s32	%f308, %r370;
	// inline asm
	ex2.approx.ftz.f32 %f307,%f308;
	// inline asm
	mul.f32 	%f598, %f307, %f311;

BB3_85:
	mul.f32 	%f320, %f600, 0f3F000000;
	setp.gtu.f32	%p78, %f598, %f320;
	add.f32 	%f321, %f598, %f598;
	selp.f32	%f599, %f598, %f321, %p78;
	setp.ltu.f32	%p79, %f599, %f43;
	@%p79 bra 	BB3_87;

BB3_86:
	sub.f32 	%f322, %f600, %f599;
	setp.ltu.f32	%p80, %f600, %f599;
	selp.f32	%f600, %f600, %f322, %p80;
	mul.f32 	%f599, %f599, 0f3F000000;
	setp.ge.f32	%p81, %f599, %f43;
	@%p81 bra 	BB3_86;

BB3_87:
	mov.b32 	 %r375, %f201;
	and.b32  	%r376, %r375, -2147483648;
	mov.b32 	 %r377, %f600;
	or.b32  	%r378, %r377, %r376;
	mov.b32 	 %f603, %r378;

BB3_89:
	ld.u32 	%r86, [%rd2+-4];
	setp.eq.s32	%p84, %r86, 0;
	mov.f32 	%f634, 0f447A0000;
	@%p84 bra 	BB3_195;

	fma.rn.f32 	%f328, %f586, 0f3E4CCCCD, 0f3F800000;
	mul.f32 	%f329, %f591, 0f3DCCCCCD;
	cvt.f64.f32	%fd1, %f329;
	add.f64 	%fd2, %fd1, 0d3FD3333333333333;
	cvt.rn.f32.f64	%f330, %fd2;
	mov.f32 	%f331, 0f3F800000;
	sub.f32 	%f332, %f331, %f60;
	sub.f32 	%f333, %f331, %f78;
	abs.f32 	%f334, %f603;
	sub.f32 	%f335, %f331, %f334;
	abs.f32 	%f606, %f335;
	abs.f32 	%f607, %f333;
	abs.f32 	%f608, %f332;
	ld.f32 	%f98, [%rd2+112];
	add.f32 	%f336, %f98, 0fBF800000;
	mul.f32 	%f99, %f328, %f336;
	mul.f32 	%f100, %f330, %f336;
	div.rn.f32 	%f101, %f1, 0fC1900000;
	abs.f32 	%f102, %f101;
	mov.f32 	%f634, 0f447A0000;
	mov.u32 	%r600, 0;
	bra.uni 	BB3_91;

BB3_182:
	setp.eq.f32	%p146, %f186, 0f7F800000;
	@%p146 bra 	BB3_192;
	bra.uni 	BB3_183;

BB3_192:
	setp.eq.f32	%p167, %f98, 0fBF800000;
	setp.gt.f32	%p168, %f185, 0f3F800000;
	selp.b32	%r575, 2139095040, 0, %p168;
	xor.b32  	%r576, %r575, 2139095040;
	setp.gt.f32	%p169, %f182, 0f80000000;
	selp.b32	%r577, %r576, %r575, %p169;
	mov.b32 	 %f549, %r577;
	selp.f32	%f194, 0f3F800000, %f549, %p167;
	mov.f32 	%f633, %f194;
	bra.uni 	BB3_194;

BB3_183:
	setp.eq.f32	%p147, %f185, 0f7F800000;
	@%p147 bra 	BB3_191;
	bra.uni 	BB3_184;

BB3_191:
	setp.eq.f32	%p163, %f184, 0f3F800000;
	setp.gtu.f32	%p164, %f182, 0f80000000;
	selp.b32	%r572, 0, 2139095040, %p164;
	setp.lt.f32	%p165, %f98, 0f00000000;
	and.pred  	%p166, %p165, %p163;
	or.b32  	%r573, %r572, -2147483648;
	selp.b32	%r574, %r573, %r572, %p166;
	mov.b32 	 %f193, %r574;
	mov.f32 	%f633, %f193;
	bra.uni 	BB3_194;

BB3_184:
	setp.eq.f32	%p148, %f98, 0f00000000;
	@%p148 bra 	BB3_190;
	bra.uni 	BB3_185;

BB3_190:
	setp.eq.f32	%p161, %f184, 0f3F800000;
	add.f32 	%f548, %f98, %f98;
	mov.b32 	 %r568, %f548;
	selp.b32	%r569, %r568, 0, %p161;
	or.b32  	%r570, %r569, 2139095040;
	setp.gt.f32	%p162, %f182, 0f80000000;
	selp.b32	%r571, %r570, %r569, %p162;
	mov.b32 	 %f192, %r571;
	mov.f32 	%f633, %f192;
	bra.uni 	BB3_194;

BB3_185:
	setp.geu.f32	%p149, %f98, 0f00000000;
	@%p149 bra 	BB3_187;

	cvt.rzi.f32.f32	%f472, %f183;
	setp.neu.f32	%p150, %f472, %f183;
	mov.f32 	%f471, 0f7FFFFFFF;
	mov.f32 	%f633, %f471;
	@%p150 bra 	BB3_194;

BB3_187:
	setp.lt.f32	%p151, %f185, 0f00800000;
	selp.f32	%f477, 0fC3170000, 0fC2FE0000, %p151;
	mul.f32 	%f478, %f185, 0f4B800000;
	selp.f32	%f479, %f478, %f185, %p151;
	mov.b32 	 %r560, %f479;
	and.b32  	%r561, %r560, 8388607;
	or.b32  	%r562, %r561, 1065353216;
	mov.b32 	 %f480, %r562;
	shr.u32 	%r563, %r560, 23;
	cvt.rn.f32.u32	%f481, %r563;
	add.f32 	%f482, %f477, %f481;
	setp.gt.f32	%p152, %f480, 0f3FB504F3;
	mul.f32 	%f483, %f480, 0f3F000000;
	add.f32 	%f484, %f482, 0f3F800000;
	selp.f32	%f485, %f483, %f480, %p152;
	selp.f32	%f486, %f484, %f482, %p152;
	add.f32 	%f487, %f485, 0fBF800000;
	add.f32 	%f474, %f485, 0f3F800000;
	// inline asm
	rcp.approx.ftz.f32 %f473,%f474;
	// inline asm
	add.f32 	%f488, %f487, %f487;
	mul.f32 	%f489, %f488, %f473;
	mul.f32 	%f490, %f489, %f489;
	mov.f32 	%f491, 0f3C4CAF63;
	mov.f32 	%f492, 0f3B18F0FE;
	fma.rn.f32 	%f493, %f492, %f490, %f491;
	mov.f32 	%f494, 0f3DAAAABD;
	fma.rn.f32 	%f495, %f493, %f490, %f494;
	mul.rn.f32 	%f496, %f495, %f490;
	mul.rn.f32 	%f497, %f496, %f489;
	sub.f32 	%f498, %f487, %f489;
	add.f32 	%f499, %f498, %f498;
	neg.f32 	%f500, %f489;
	fma.rn.f32 	%f501, %f500, %f487, %f499;
	mul.rn.f32 	%f502, %f473, %f501;
	add.f32 	%f503, %f489, %f497;
	sub.f32 	%f504, %f489, %f503;
	add.f32 	%f505, %f497, %f504;
	add.f32 	%f506, %f502, %f505;
	add.f32 	%f507, %f503, %f506;
	sub.f32 	%f508, %f503, %f507;
	add.f32 	%f509, %f506, %f508;
	mov.f32 	%f510, 0f3F317200;
	mul.rn.f32 	%f511, %f486, %f510;
	mov.f32 	%f512, 0f35BFBE8E;
	mul.rn.f32 	%f513, %f486, %f512;
	add.f32 	%f514, %f511, %f507;
	sub.f32 	%f515, %f511, %f514;
	add.f32 	%f516, %f507, %f515;
	add.f32 	%f517, %f509, %f516;
	add.f32 	%f518, %f513, %f517;
	add.f32 	%f519, %f514, %f518;
	sub.f32 	%f520, %f514, %f519;
	add.f32 	%f521, %f518, %f520;
	mul.f32 	%f522, %f183, 0f39000000;
	setp.gt.f32	%p153, %f186, 0f77F684DF;
	selp.f32	%f523, %f522, %f183, %p153;
	mul.rn.f32 	%f524, %f523, %f519;
	neg.f32 	%f525, %f524;
	fma.rn.f32 	%f526, %f523, %f519, %f525;
	fma.rn.f32 	%f527, %f523, %f521, %f526;
	mov.f32 	%f528, 0f00000000;
	fma.rn.f32 	%f529, %f528, %f519, %f527;
	add.rn.f32 	%f530, %f524, %f529;
	neg.f32 	%f531, %f530;
	add.rn.f32 	%f532, %f524, %f531;
	add.rn.f32 	%f533, %f532, %f529;
	mov.b32 	 %r564, %f530;
	setp.eq.s32	%p154, %r564, 1118925336;
	add.s32 	%r565, %r564, -1;
	mov.b32 	 %f534, %r565;
	add.f32 	%f535, %f533, 0f37000000;
	selp.f32	%f187, %f535, %f533, %p154;
	selp.f32	%f536, %f534, %f530, %p154;
	mul.f32 	%f537, %f536, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f538, %f537;
	mov.f32 	%f539, 0fBF317200;
	fma.rn.f32 	%f540, %f538, %f539, %f536;
	mov.f32 	%f541, 0fB5BFBE8E;
	fma.rn.f32 	%f542, %f538, %f541, %f540;
	mul.f32 	%f476, %f542, 0f3FB8AA3B;
	// inline asm
	ex2.approx.ftz.f32 %f475,%f476;
	// inline asm
	add.f32 	%f543, %f538, 0f00000000;
	ex2.approx.f32 	%f544, %f543;
	mul.f32 	%f545, %f475, %f544;
	setp.lt.f32	%p155, %f536, 0fC2D20000;
	selp.f32	%f546, 0f00000000, %f545, %p155;
	setp.gt.f32	%p156, %f536, 0f42D20000;
	selp.f32	%f632, 0f7F800000, %f546, %p156;
	setp.eq.f32	%p157, %f632, 0f7F800000;
	@%p157 bra 	BB3_189;

	fma.rn.f32 	%f632, %f632, %f187, %f632;

BB3_189:
	setp.lt.f32	%p158, %f98, 0f00000000;
	setp.eq.f32	%p159, %f184, 0f3F800000;
	and.pred  	%p160, %p158, %p159;
	mov.b32 	 %r566, %f632;
	xor.b32  	%r567, %r566, -2147483648;
	mov.b32 	 %f547, %r567;
	selp.f32	%f191, %f547, %f632, %p160;
	mov.f32 	%f633, %f191;
	bra.uni 	BB3_194;

BB3_91:
	add.f32 	%f337, %f608, %f607;
	setp.lt.f32	%p85, %f337, 0f00000000;
	neg.f32 	%f338, %f607;
	selp.f32	%f339, %f338, %f608, %p85;
	neg.f32 	%f340, %f608;
	selp.f32	%f341, %f340, %f607, %p85;
	abs.f32 	%f342, %f339;
	abs.f32 	%f343, %f341;
	abs.f32 	%f344, %f606;
	add.f32 	%f345, %f342, %f344;
	setp.lt.f32	%p86, %f345, 0f00000000;
	neg.f32 	%f346, %f344;
	neg.f32 	%f347, %f342;
	selp.f32	%f348, %f346, %f342, %p86;
	selp.f32	%f349, %f347, %f344, %p86;
	abs.f32 	%f350, %f348;
	abs.f32 	%f351, %f343;
	abs.f32 	%f352, %f349;
	sub.f32 	%f353, %f350, %f351;
	setp.lt.f32	%p87, %f353, 0f00000000;
	selp.f32	%f354, %f351, %f350, %p87;
	selp.f32	%f355, %f350, %f351, %p87;
	abs.f32 	%f356, %f354;
	abs.f32 	%f357, %f355;
	abs.f32 	%f358, %f352;
	sub.f32 	%f359, %f356, %f358;
	setp.lt.f32	%p88, %f359, 0f00000000;
	selp.f32	%f360, %f358, %f356, %p88;
	selp.f32	%f361, %f356, %f358, %p88;
	abs.f32 	%f362, %f360;
	abs.f32 	%f363, %f357;
	abs.f32 	%f364, %f361;
	mul.f32 	%f365, %f362, %f98;
	mul.f32 	%f366, %f363, %f98;
	mul.f32 	%f367, %f364, %f98;
	sub.f32 	%f608, %f365, %f99;
	sub.f32 	%f108, %f366, %f336;
	sub.f32 	%f109, %f367, %f100;
	setp.neu.f32	%p89, %f102, 0f7F800000;
	mov.f32 	%f627, %f101;
	@%p89 bra 	BB3_93;

	mov.f32 	%f369, 0f00000000;
	mul.rn.f32 	%f110, %f101, %f369;
	mov.f32 	%f627, %f110;

BB3_93:
	mov.f32 	%f111, %f627;
	mul.f32 	%f370, %f111, 0f3F22F983;
	cvt.rni.s32.f32	%r610, %f370;
	cvt.rn.f32.s32	%f371, %r610;
	neg.f32 	%f372, %f371;
	fma.rn.f32 	%f374, %f372, %f210, %f111;
	fma.rn.f32 	%f376, %f372, %f212, %f374;
	fma.rn.f32 	%f609, %f372, %f214, %f376;
	abs.f32 	%f378, %f111;
	setp.leu.f32	%p90, %f378, 0f47CE4780;
	@%p90 bra 	BB3_103;

	mov.b32 	 %r89, %f111;
	shr.u32 	%r90, %r89, 23;
	bfe.u32 	%r382, %r89, 23, 8;
	add.s32 	%r383, %r382, -128;
	shl.b32 	%r384, %r89, 8;
	or.b32  	%r91, %r384, -2147483648;
	shr.u32 	%r92, %r383, 5;
	mov.u32 	%r602, 0;
	mov.u64 	%rd61, __cudart_i2opi_f;
	mov.u32 	%r601, -6;
	mov.u64 	%rd74, %rd1;

BB3_95:
	.pragma "nounroll";
	mov.u64 	%rd23, %rd74;
	ld.const.u32 	%r387, [%rd61];
	// inline asm
	{
	mad.lo.cc.u32   %r385, %r387, %r91, %r602;
	madc.hi.u32     %r386, %r387, %r91,  0;
	}
	// inline asm
	mov.u32 	%r602, %r386;
	st.local.u32 	[%rd23], %r385;
	add.s64 	%rd24, %rd23, 4;
	add.s64 	%rd61, %rd61, 4;
	add.s32 	%r601, %r601, 1;
	setp.ne.s32	%p91, %r601, 0;
	mov.u64 	%rd74, %rd24;
	@%p91 bra 	BB3_95;

	and.b32  	%r97, %r89, -2147483648;
	st.local.u32 	[%rd1+24], %r386;
	mov.u32 	%r390, 6;
	sub.s32 	%r391, %r390, %r92;
	mul.wide.s32 	%rd50, %r391, 4;
	add.s64 	%rd26, %rd1, %rd50;
	ld.local.u32 	%r603, [%rd26];
	ld.local.u32 	%r604, [%rd26+-4];
	and.b32  	%r100, %r90, 31;
	setp.eq.s32	%p92, %r100, 0;
	@%p92 bra 	BB3_98;

	mov.u32 	%r392, 32;
	sub.s32 	%r393, %r392, %r100;
	shr.u32 	%r394, %r604, %r393;
	shl.b32 	%r395, %r603, %r100;
	add.s32 	%r603, %r394, %r395;
	ld.local.u32 	%r396, [%rd26+-8];
	shr.u32 	%r397, %r396, %r393;
	shl.b32 	%r398, %r604, %r100;
	add.s32 	%r604, %r397, %r398;

BB3_98:
	shr.u32 	%r399, %r604, 30;
	shl.b32 	%r400, %r603, 2;
	add.s32 	%r605, %r399, %r400;
	shl.b32 	%r106, %r604, 2;
	shr.u32 	%r401, %r605, 31;
	shr.u32 	%r402, %r603, 30;
	add.s32 	%r107, %r401, %r402;
	setp.eq.s32	%p93, %r401, 0;
	mov.u32 	%r606, %r97;
	mov.u32 	%r607, %r106;
	@%p93 bra 	BB3_100;

	not.b32 	%r403, %r605;
	neg.s32 	%r108, %r106;
	setp.eq.s32	%p94, %r106, 0;
	selp.u32	%r404, 1, 0, %p94;
	add.s32 	%r605, %r404, %r403;
	xor.b32  	%r110, %r97, -2147483648;
	mov.u32 	%r606, %r110;
	mov.u32 	%r607, %r108;

BB3_100:
	mov.u32 	%r112, %r606;
	neg.s32 	%r405, %r107;
	setp.eq.s32	%p95, %r97, 0;
	selp.b32	%r610, %r107, %r405, %p95;
	clz.b32 	%r609, %r605;
	setp.eq.s32	%p96, %r609, 0;
	shl.b32 	%r406, %r605, %r609;
	mov.u32 	%r407, 32;
	sub.s32 	%r408, %r407, %r609;
	shr.u32 	%r409, %r607, %r408;
	add.s32 	%r410, %r409, %r406;
	selp.b32	%r116, %r605, %r410, %p96;
	mov.u32 	%r411, -921707870;
	mul.hi.u32 	%r608, %r116, %r411;
	setp.lt.s32	%p97, %r608, 1;
	@%p97 bra 	BB3_102;

	mul.lo.s32 	%r412, %r116, -921707870;
	shr.u32 	%r413, %r412, 31;
	shl.b32 	%r414, %r608, 1;
	add.s32 	%r608, %r413, %r414;
	add.s32 	%r609, %r609, 1;

BB3_102:
	mov.u32 	%r415, 126;
	sub.s32 	%r416, %r415, %r609;
	shl.b32 	%r417, %r416, 23;
	add.s32 	%r418, %r608, 1;
	shr.u32 	%r419, %r418, 7;
	add.s32 	%r420, %r419, 1;
	shr.u32 	%r421, %r420, 1;
	add.s32 	%r422, %r421, %r417;
	or.b32  	%r423, %r422, %r112;
	mov.b32 	 %f609, %r423;

BB3_103:
	mul.rn.f32 	%f115, %f609, %f609;
	add.s32 	%r123, %r610, 1;
	and.b32  	%r124, %r123, 1;
	setp.eq.s32	%p98, %r124, 0;
	@%p98 bra 	BB3_105;
	bra.uni 	BB3_104;

BB3_105:
	mov.f32 	%f381, 0f3C08839E;
	mov.f32 	%f382, 0fB94CA1F9;
	fma.rn.f32 	%f610, %f382, %f115, %f381;
	bra.uni 	BB3_106;

BB3_104:
	mov.f32 	%f379, 0fBAB6061A;
	mov.f32 	%f380, 0f37CCF5CE;
	fma.rn.f32 	%f610, %f380, %f115, %f379;

BB3_106:
	@%p98 bra 	BB3_108;
	bra.uni 	BB3_107;

BB3_108:
	mov.f32 	%f386, 0fBE2AAAA3;
	fma.rn.f32 	%f387, %f610, %f115, %f386;
	mov.f32 	%f388, 0f00000000;
	fma.rn.f32 	%f611, %f387, %f115, %f388;
	bra.uni 	BB3_109;

BB3_107:
	mov.f32 	%f383, 0f3D2AAAA5;
	fma.rn.f32 	%f384, %f610, %f115, %f383;
	mov.f32 	%f385, 0fBF000000;
	fma.rn.f32 	%f611, %f384, %f115, %f385;

BB3_109:
	fma.rn.f32 	%f612, %f611, %f609, %f609;
	@%p98 bra 	BB3_111;

	fma.rn.f32 	%f612, %f611, %f115, %f331;

BB3_111:
	and.b32  	%r424, %r123, 2;
	setp.eq.s32	%p101, %r424, 0;
	@%p101 bra 	BB3_113;

	mov.f32 	%f390, 0f00000000;
	mov.f32 	%f391, 0fBF800000;
	fma.rn.f32 	%f612, %f612, %f391, %f390;

BB3_113:
	mov.f32 	%f626, %f101;
	@%p89 bra 	BB3_115;

	mov.f32 	%f392, 0f00000000;
	mul.rn.f32 	%f626, %f101, %f392;

BB3_115:
	mul.f32 	%f393, %f626, 0f3F22F983;
	cvt.rni.s32.f32	%r620, %f393;
	cvt.rn.f32.s32	%f394, %r620;
	neg.f32 	%f395, %f394;
	fma.rn.f32 	%f397, %f395, %f210, %f626;
	fma.rn.f32 	%f399, %f395, %f212, %f397;
	fma.rn.f32 	%f613, %f395, %f214, %f399;
	abs.f32 	%f401, %f626;
	setp.leu.f32	%p103, %f401, 0f47CE4780;
	@%p103 bra 	BB3_125;

	mov.b32 	 %r126, %f626;
	shr.u32 	%r127, %r126, 23;
	bfe.u32 	%r427, %r126, 23, 8;
	add.s32 	%r428, %r427, -128;
	shl.b32 	%r429, %r126, 8;
	or.b32  	%r128, %r429, -2147483648;
	shr.u32 	%r129, %r428, 5;
	mov.u32 	%r612, 0;
	mov.u64 	%rd62, __cudart_i2opi_f;
	mov.u32 	%r611, -6;
	mov.u64 	%rd73, %rd1;

BB3_117:
	.pragma "nounroll";
	ld.const.u32 	%r432, [%rd62];
	// inline asm
	{
	mad.lo.cc.u32   %r430, %r432, %r128, %r612;
	madc.hi.u32     %r431, %r432, %r128,  0;
	}
	// inline asm
	mov.u32 	%r612, %r431;
	st.local.u32 	[%rd73], %r430;
	add.s64 	%rd73, %rd73, 4;
	add.s64 	%rd62, %rd62, 4;
	add.s32 	%r611, %r611, 1;
	setp.ne.s32	%p104, %r611, 0;
	@%p104 bra 	BB3_117;

	and.b32  	%r134, %r126, -2147483648;
	st.local.u32 	[%rd1+24], %r431;
	mov.u32 	%r435, 6;
	sub.s32 	%r436, %r435, %r129;
	mul.wide.s32 	%rd52, %r436, 4;
	add.s64 	%rd31, %rd1, %rd52;
	ld.local.u32 	%r613, [%rd31];
	ld.local.u32 	%r614, [%rd31+-4];
	and.b32  	%r137, %r127, 31;
	setp.eq.s32	%p105, %r137, 0;
	@%p105 bra 	BB3_120;

	mov.u32 	%r437, 32;
	sub.s32 	%r438, %r437, %r137;
	shr.u32 	%r439, %r614, %r438;
	shl.b32 	%r440, %r613, %r137;
	add.s32 	%r613, %r439, %r440;
	ld.local.u32 	%r441, [%rd31+-8];
	shr.u32 	%r442, %r441, %r438;
	shl.b32 	%r443, %r614, %r137;
	add.s32 	%r614, %r442, %r443;

BB3_120:
	shr.u32 	%r444, %r614, 30;
	shl.b32 	%r445, %r613, 2;
	add.s32 	%r615, %r444, %r445;
	shl.b32 	%r143, %r614, 2;
	shr.u32 	%r446, %r615, 31;
	shr.u32 	%r447, %r613, 30;
	add.s32 	%r144, %r446, %r447;
	setp.eq.s32	%p106, %r446, 0;
	mov.u32 	%r616, %r134;
	mov.u32 	%r617, %r143;
	@%p106 bra 	BB3_122;

	not.b32 	%r448, %r615;
	neg.s32 	%r145, %r143;
	setp.eq.s32	%p107, %r143, 0;
	selp.u32	%r449, 1, 0, %p107;
	add.s32 	%r615, %r449, %r448;
	xor.b32  	%r147, %r134, -2147483648;
	mov.u32 	%r616, %r147;
	mov.u32 	%r617, %r145;

BB3_122:
	mov.u32 	%r149, %r616;
	neg.s32 	%r450, %r144;
	setp.eq.s32	%p108, %r134, 0;
	selp.b32	%r620, %r144, %r450, %p108;
	clz.b32 	%r619, %r615;
	setp.eq.s32	%p109, %r619, 0;
	shl.b32 	%r451, %r615, %r619;
	mov.u32 	%r452, 32;
	sub.s32 	%r453, %r452, %r619;
	shr.u32 	%r454, %r617, %r453;
	add.s32 	%r455, %r454, %r451;
	selp.b32	%r153, %r615, %r455, %p109;
	mov.u32 	%r456, -921707870;
	mul.hi.u32 	%r618, %r153, %r456;
	setp.lt.s32	%p110, %r618, 1;
	@%p110 bra 	BB3_124;

	mul.lo.s32 	%r457, %r153, -921707870;
	shr.u32 	%r458, %r457, 31;
	shl.b32 	%r459, %r618, 1;
	add.s32 	%r618, %r458, %r459;
	add.s32 	%r619, %r619, 1;

BB3_124:
	mov.u32 	%r460, 126;
	sub.s32 	%r461, %r460, %r619;
	shl.b32 	%r462, %r461, 23;
	add.s32 	%r463, %r618, 1;
	shr.u32 	%r464, %r463, 7;
	add.s32 	%r465, %r464, 1;
	shr.u32 	%r466, %r465, 1;
	add.s32 	%r467, %r466, %r462;
	or.b32  	%r468, %r467, %r149;
	mov.b32 	 %f613, %r468;

BB3_125:
	mul.rn.f32 	%f132, %f613, %f613;
	and.b32  	%r160, %r620, 1;
	setp.eq.s32	%p111, %r160, 0;
	@%p111 bra 	BB3_127;
	bra.uni 	BB3_126;

BB3_127:
	mov.f32 	%f404, 0f3C08839E;
	mov.f32 	%f405, 0fB94CA1F9;
	fma.rn.f32 	%f614, %f405, %f132, %f404;
	bra.uni 	BB3_128;

BB3_126:
	mov.f32 	%f402, 0fBAB6061A;
	mov.f32 	%f403, 0f37CCF5CE;
	fma.rn.f32 	%f614, %f403, %f132, %f402;

BB3_128:
	@%p111 bra 	BB3_130;
	bra.uni 	BB3_129;

BB3_130:
	mov.f32 	%f409, 0fBE2AAAA3;
	fma.rn.f32 	%f410, %f614, %f132, %f409;
	mov.f32 	%f411, 0f00000000;
	fma.rn.f32 	%f615, %f410, %f132, %f411;
	bra.uni 	BB3_131;

BB3_129:
	mov.f32 	%f406, 0f3D2AAAA5;
	fma.rn.f32 	%f407, %f614, %f132, %f406;
	mov.f32 	%f408, 0fBF000000;
	fma.rn.f32 	%f615, %f407, %f132, %f408;

BB3_131:
	fma.rn.f32 	%f616, %f615, %f613, %f613;
	@%p111 bra 	BB3_133;

	fma.rn.f32 	%f616, %f615, %f132, %f331;

BB3_133:
	and.b32  	%r469, %r620, 2;
	setp.eq.s32	%p114, %r469, 0;
	@%p114 bra 	BB3_135;

	mov.f32 	%f413, 0f00000000;
	mov.f32 	%f414, 0fBF800000;
	fma.rn.f32 	%f616, %f616, %f414, %f413;

BB3_135:
	mul.f32 	%f415, %f109, %f616;
	fma.rn.f32 	%f607, %f108, %f612, %f415;
	mov.f32 	%f625, %f101;
	@%p89 bra 	BB3_137;

	mov.f32 	%f416, 0f00000000;
	mul.rn.f32 	%f625, %f101, %f416;

BB3_137:
	mul.f32 	%f417, %f625, 0f3F22F983;
	cvt.rni.s32.f32	%r630, %f417;
	cvt.rn.f32.s32	%f418, %r630;
	neg.f32 	%f419, %f418;
	fma.rn.f32 	%f421, %f419, %f210, %f625;
	fma.rn.f32 	%f423, %f419, %f212, %f421;
	fma.rn.f32 	%f617, %f419, %f214, %f423;
	abs.f32 	%f425, %f625;
	setp.leu.f32	%p116, %f425, 0f47CE4780;
	@%p116 bra 	BB3_147;

	mov.b32 	 %r162, %f625;
	shr.u32 	%r163, %r162, 23;
	bfe.u32 	%r472, %r162, 23, 8;
	add.s32 	%r473, %r472, -128;
	shl.b32 	%r474, %r162, 8;
	or.b32  	%r164, %r474, -2147483648;
	shr.u32 	%r165, %r473, 5;
	mov.u32 	%r622, 0;
	mov.u64 	%rd63, __cudart_i2opi_f;
	mov.u32 	%r621, -6;
	mov.u64 	%rd72, %rd1;

BB3_139:
	.pragma "nounroll";
	ld.const.u32 	%r477, [%rd63];
	// inline asm
	{
	mad.lo.cc.u32   %r475, %r477, %r164, %r622;
	madc.hi.u32     %r476, %r477, %r164,  0;
	}
	// inline asm
	mov.u32 	%r622, %r476;
	st.local.u32 	[%rd72], %r475;
	add.s64 	%rd72, %rd72, 4;
	add.s64 	%rd63, %rd63, 4;
	add.s32 	%r621, %r621, 1;
	setp.ne.s32	%p117, %r621, 0;
	@%p117 bra 	BB3_139;

	and.b32  	%r170, %r162, -2147483648;
	st.local.u32 	[%rd1+24], %r476;
	mov.u32 	%r480, 6;
	sub.s32 	%r481, %r480, %r165;
	mul.wide.s32 	%rd54, %r481, 4;
	add.s64 	%rd36, %rd1, %rd54;
	ld.local.u32 	%r623, [%rd36];
	ld.local.u32 	%r624, [%rd36+-4];
	and.b32  	%r173, %r163, 31;
	setp.eq.s32	%p118, %r173, 0;
	@%p118 bra 	BB3_142;

	mov.u32 	%r482, 32;
	sub.s32 	%r483, %r482, %r173;
	shr.u32 	%r484, %r624, %r483;
	shl.b32 	%r485, %r623, %r173;
	add.s32 	%r623, %r484, %r485;
	ld.local.u32 	%r486, [%rd36+-8];
	shr.u32 	%r487, %r486, %r483;
	shl.b32 	%r488, %r624, %r173;
	add.s32 	%r624, %r487, %r488;

BB3_142:
	shr.u32 	%r489, %r624, 30;
	shl.b32 	%r490, %r623, 2;
	add.s32 	%r625, %r489, %r490;
	shl.b32 	%r179, %r624, 2;
	shr.u32 	%r491, %r625, 31;
	shr.u32 	%r492, %r623, 30;
	add.s32 	%r180, %r491, %r492;
	setp.eq.s32	%p119, %r491, 0;
	mov.u32 	%r626, %r170;
	mov.u32 	%r627, %r179;
	@%p119 bra 	BB3_144;

	not.b32 	%r493, %r625;
	neg.s32 	%r181, %r179;
	setp.eq.s32	%p120, %r179, 0;
	selp.u32	%r494, 1, 0, %p120;
	add.s32 	%r625, %r494, %r493;
	xor.b32  	%r183, %r170, -2147483648;
	mov.u32 	%r626, %r183;
	mov.u32 	%r627, %r181;

BB3_144:
	mov.u32 	%r185, %r626;
	neg.s32 	%r495, %r180;
	setp.eq.s32	%p121, %r170, 0;
	selp.b32	%r630, %r180, %r495, %p121;
	clz.b32 	%r629, %r625;
	setp.eq.s32	%p122, %r629, 0;
	shl.b32 	%r496, %r625, %r629;
	mov.u32 	%r497, 32;
	sub.s32 	%r498, %r497, %r629;
	shr.u32 	%r499, %r627, %r498;
	add.s32 	%r500, %r499, %r496;
	selp.b32	%r189, %r625, %r500, %p122;
	mov.u32 	%r501, -921707870;
	mul.hi.u32 	%r628, %r189, %r501;
	setp.lt.s32	%p123, %r628, 1;
	@%p123 bra 	BB3_146;

	mul.lo.s32 	%r502, %r189, -921707870;
	shr.u32 	%r503, %r502, 31;
	shl.b32 	%r504, %r628, 1;
	add.s32 	%r628, %r503, %r504;
	add.s32 	%r629, %r629, 1;

BB3_146:
	mov.u32 	%r505, 126;
	sub.s32 	%r506, %r505, %r629;
	shl.b32 	%r507, %r506, 23;
	add.s32 	%r508, %r628, 1;
	shr.u32 	%r509, %r508, 7;
	add.s32 	%r510, %r509, 1;
	shr.u32 	%r511, %r510, 1;
	add.s32 	%r512, %r511, %r507;
	or.b32  	%r513, %r512, %r185;
	mov.b32 	 %f617, %r513;

BB3_147:
	mul.rn.f32 	%f150, %f617, %f617;
	and.b32  	%r196, %r630, 1;
	setp.eq.s32	%p124, %r196, 0;
	@%p124 bra 	BB3_149;
	bra.uni 	BB3_148;

BB3_149:
	mov.f32 	%f428, 0f3C08839E;
	mov.f32 	%f429, 0fB94CA1F9;
	fma.rn.f32 	%f618, %f429, %f150, %f428;
	bra.uni 	BB3_150;

BB3_148:
	mov.f32 	%f426, 0fBAB6061A;
	mov.f32 	%f427, 0f37CCF5CE;
	fma.rn.f32 	%f618, %f427, %f150, %f426;

BB3_150:
	@%p124 bra 	BB3_152;
	bra.uni 	BB3_151;

BB3_152:
	mov.f32 	%f433, 0fBE2AAAA3;
	fma.rn.f32 	%f434, %f618, %f150, %f433;
	mov.f32 	%f435, 0f00000000;
	fma.rn.f32 	%f619, %f434, %f150, %f435;
	bra.uni 	BB3_153;

BB3_151:
	mov.f32 	%f430, 0f3D2AAAA5;
	fma.rn.f32 	%f431, %f618, %f150, %f430;
	mov.f32 	%f432, 0fBF000000;
	fma.rn.f32 	%f619, %f431, %f150, %f432;

BB3_153:
	fma.rn.f32 	%f620, %f619, %f617, %f617;
	@%p124 bra 	BB3_155;

	fma.rn.f32 	%f620, %f619, %f150, %f331;

BB3_155:
	and.b32  	%r514, %r630, 2;
	setp.eq.s32	%p127, %r514, 0;
	@%p127 bra 	BB3_157;

	mov.f32 	%f437, 0f00000000;
	mov.f32 	%f438, 0fBF800000;
	fma.rn.f32 	%f620, %f620, %f438, %f437;

BB3_157:
	mul.f32 	%f162, %f108, %f620;
	mov.f32 	%f624, %f101;
	@%p89 bra 	BB3_159;

	mov.f32 	%f439, 0f00000000;
	mul.rn.f32 	%f624, %f101, %f439;

BB3_159:
	mul.f32 	%f440, %f624, 0f3F22F983;
	cvt.rni.s32.f32	%r640, %f440;
	cvt.rn.f32.s32	%f441, %r640;
	neg.f32 	%f442, %f441;
	fma.rn.f32 	%f444, %f442, %f210, %f624;
	fma.rn.f32 	%f446, %f442, %f212, %f444;
	fma.rn.f32 	%f628, %f442, %f214, %f446;
	abs.f32 	%f448, %f624;
	setp.leu.f32	%p129, %f448, 0f47CE4780;
	@%p129 bra 	BB3_169;

	mov.b32 	 %r198, %f624;
	shr.u32 	%r199, %r198, 23;
	bfe.u32 	%r517, %r198, 23, 8;
	add.s32 	%r518, %r517, -128;
	shl.b32 	%r519, %r198, 8;
	or.b32  	%r200, %r519, -2147483648;
	shr.u32 	%r201, %r518, 5;
	mov.u32 	%r632, 0;
	mov.u64 	%rd64, __cudart_i2opi_f;
	mov.u32 	%r631, -6;
	mov.u64 	%rd71, %rd1;

BB3_161:
	.pragma "nounroll";
	ld.const.u32 	%r522, [%rd64];
	// inline asm
	{
	mad.lo.cc.u32   %r520, %r522, %r200, %r632;
	madc.hi.u32     %r521, %r522, %r200,  0;
	}
	// inline asm
	mov.u32 	%r632, %r521;
	st.local.u32 	[%rd71], %r520;
	add.s64 	%rd71, %rd71, 4;
	add.s64 	%rd64, %rd64, 4;
	add.s32 	%r631, %r631, 1;
	setp.ne.s32	%p130, %r631, 0;
	@%p130 bra 	BB3_161;

	and.b32  	%r206, %r198, -2147483648;
	st.local.u32 	[%rd1+24], %r521;
	mov.u32 	%r525, 6;
	sub.s32 	%r526, %r525, %r201;
	mul.wide.s32 	%rd56, %r526, 4;
	add.s64 	%rd41, %rd1, %rd56;
	ld.local.u32 	%r633, [%rd41];
	ld.local.u32 	%r634, [%rd41+-4];
	and.b32  	%r209, %r199, 31;
	setp.eq.s32	%p131, %r209, 0;
	@%p131 bra 	BB3_164;

	mov.u32 	%r527, 32;
	sub.s32 	%r528, %r527, %r209;
	shr.u32 	%r529, %r634, %r528;
	shl.b32 	%r530, %r633, %r209;
	add.s32 	%r633, %r529, %r530;
	ld.local.u32 	%r531, [%rd41+-8];
	shr.u32 	%r532, %r531, %r528;
	shl.b32 	%r533, %r634, %r209;
	add.s32 	%r634, %r532, %r533;

BB3_164:
	shr.u32 	%r534, %r634, 30;
	shl.b32 	%r535, %r633, 2;
	add.s32 	%r635, %r534, %r535;
	shl.b32 	%r215, %r634, 2;
	shr.u32 	%r536, %r635, 31;
	shr.u32 	%r537, %r633, 30;
	add.s32 	%r216, %r536, %r537;
	setp.eq.s32	%p132, %r536, 0;
	mov.u32 	%r636, %r206;
	mov.u32 	%r637, %r215;
	@%p132 bra 	BB3_166;

	not.b32 	%r538, %r635;
	neg.s32 	%r217, %r215;
	setp.eq.s32	%p133, %r215, 0;
	selp.u32	%r539, 1, 0, %p133;
	add.s32 	%r635, %r539, %r538;
	xor.b32  	%r219, %r206, -2147483648;
	mov.u32 	%r636, %r219;
	mov.u32 	%r637, %r217;

BB3_166:
	mov.u32 	%r221, %r636;
	neg.s32 	%r540, %r216;
	setp.eq.s32	%p134, %r206, 0;
	selp.b32	%r640, %r216, %r540, %p134;
	clz.b32 	%r639, %r635;
	setp.eq.s32	%p135, %r639, 0;
	shl.b32 	%r541, %r635, %r639;
	mov.u32 	%r542, 32;
	sub.s32 	%r543, %r542, %r639;
	shr.u32 	%r544, %r637, %r543;
	add.s32 	%r545, %r544, %r541;
	selp.b32	%r225, %r635, %r545, %p135;
	mov.u32 	%r546, -921707870;
	mul.hi.u32 	%r638, %r225, %r546;
	setp.lt.s32	%p136, %r638, 1;
	@%p136 bra 	BB3_168;

	mul.lo.s32 	%r547, %r225, -921707870;
	shr.u32 	%r548, %r547, 31;
	shl.b32 	%r549, %r638, 1;
	add.s32 	%r638, %r548, %r549;
	add.s32 	%r639, %r639, 1;

BB3_168:
	mov.u32 	%r550, 126;
	sub.s32 	%r551, %r550, %r639;
	shl.b32 	%r552, %r551, 23;
	add.s32 	%r553, %r638, 1;
	shr.u32 	%r554, %r553, 7;
	add.s32 	%r555, %r554, 1;
	shr.u32 	%r556, %r555, 1;
	add.s32 	%r557, %r556, %r552;
	or.b32  	%r558, %r557, %r221;
	mov.b32 	 %f628, %r558;

BB3_169:
	mul.rn.f32 	%f168, %f628, %f628;
	add.s32 	%r232, %r640, 1;
	and.b32  	%r233, %r232, 1;
	setp.eq.s32	%p137, %r233, 0;
	@%p137 bra 	BB3_171;
	bra.uni 	BB3_170;

BB3_171:
	mov.f32 	%f451, 0f3C08839E;
	mov.f32 	%f452, 0fB94CA1F9;
	fma.rn.f32 	%f629, %f452, %f168, %f451;
	bra.uni 	BB3_172;

BB3_170:
	mov.f32 	%f449, 0fBAB6061A;
	mov.f32 	%f450, 0f37CCF5CE;
	fma.rn.f32 	%f629, %f450, %f168, %f449;

BB3_172:
	@%p137 bra 	BB3_174;
	bra.uni 	BB3_173;

BB3_174:
	mov.f32 	%f456, 0fBE2AAAA3;
	fma.rn.f32 	%f457, %f629, %f168, %f456;
	mov.f32 	%f458, 0f00000000;
	fma.rn.f32 	%f630, %f457, %f168, %f458;
	bra.uni 	BB3_175;

BB3_173:
	mov.f32 	%f453, 0f3D2AAAA5;
	fma.rn.f32 	%f454, %f629, %f168, %f453;
	mov.f32 	%f455, 0fBF000000;
	fma.rn.f32 	%f630, %f454, %f168, %f455;

BB3_175:
	fma.rn.f32 	%f631, %f630, %f628, %f628;
	@%p137 bra 	BB3_177;

	fma.rn.f32 	%f631, %f630, %f168, %f331;

BB3_177:
	and.b32  	%r559, %r232, 2;
	setp.eq.s32	%p140, %r559, 0;
	@%p140 bra 	BB3_179;

	mov.f32 	%f460, 0f00000000;
	mov.f32 	%f461, 0fBF800000;
	fma.rn.f32 	%f631, %f631, %f461, %f460;

BB3_179:
	mul.f32 	%f463, %f109, %f631;
	sub.f32 	%f606, %f463, %f162;
	mul.f32 	%f464, %f607, %f607;
	fma.rn.f32 	%f465, %f608, %f608, %f464;
	fma.rn.f32 	%f466, %f606, %f606, %f465;
	sqrt.rn.f32 	%f181, %f466;
	add.s32 	%r600, %r600, 1;
	cvt.rn.f32.s32	%f182, %r600;
	neg.f32 	%f183, %f182;
	mul.f32 	%f467, %f182, 0fBF000000;
	cvt.rzi.f32.f32	%f468, %f467;
	mul.f32 	%f469, %f468, 0fC0000000;
	sub.f32 	%f470, %f469, %f182;
	abs.f32 	%f184, %f470;
	setp.eq.f32	%p141, %f182, 0f80000000;
	setp.eq.f32	%p142, %f98, 0f3F800000;
	or.pred  	%p143, %p142, %p141;
	mov.f32 	%f633, %f331;
	@%p143 bra 	BB3_194;

	abs.f32 	%f185, %f98;
	setp.gtu.f32	%p144, %f185, 0f7F800000;
	@%p144 bra 	BB3_193;

	abs.f32 	%f186, %f183;
	setp.gtu.f32	%p145, %f186, 0f7F800000;
	@%p145 bra 	BB3_193;
	bra.uni 	BB3_182;

BB3_193:
	sub.f32 	%f195, %f98, %f182;
	mov.f32 	%f633, %f195;

BB3_194:
	mov.f32 	%f196, %f633;
	mul.f32 	%f550, %f181, %f196;
	min.f32 	%f634, %f634, %f550;
	setp.lt.u32	%p170, %r600, %r86;
	@%p170 bra 	BB3_91;

BB3_195:
	ld.param.u64 	%rd57, [_ZN10TunnelTest12evalDistanceE6float3_param_0];
	ld.param.f32 	%f580, [_ZN10TunnelTest12evalDistanceE6float3_param_1+8];
	abs.f32 	%f579, %f580;
	ld.param.f32 	%f578, [_ZN10TunnelTest12evalDistanceE6float3_param_1+4];
	ld.param.f32 	%f577, [_ZN10TunnelTest12evalDistanceE6float3_param_1];
	abs.f32 	%f576, %f577;
	ld.f32 	%f551, [%rd57+128];
	mul.f32 	%f552, %f634, %f551;
	add.f32 	%f553, %f578, 0f3F800000;
	abs.f32 	%f554, %f553;
	ld.v2.f32 	{%f555, %f556}, [%rd57+160];
	ld.f32 	%f559, [%rd57+156];
	sub.f32 	%f560, %f576, %f559;
	sub.f32 	%f561, %f554, %f555;
	sub.f32 	%f562, %f579, %f556;
	max.f32 	%f563, %f561, %f562;
	max.f32 	%f564, %f560, %f563;
	mov.f32 	%f565, 0f00000000;
	min.f32 	%f566, %f564, %f565;
	max.f32 	%f567, %f560, %f565;
	max.f32 	%f568, %f561, %f565;
	max.f32 	%f569, %f562, %f565;
	mul.f32 	%f570, %f568, %f568;
	fma.rn.f32 	%f571, %f567, %f567, %f570;
	fma.rn.f32 	%f572, %f569, %f569, %f571;
	sqrt.rn.f32 	%f573, %f572;
	add.f32 	%f574, %f566, %f573;
	max.f32 	%f575, %f552, %f574;
	st.param.f32	[func_retval0+0], %f575;
	ret;
}

	// .globl	_Z12insideSphere6float3S_fPf
.visible .func  (.param .b32 func_retval0) _Z12insideSphere6float3S_fPf(
	.param .align 4 .b8 _Z12insideSphere6float3S_fPf_param_0[12],
	.param .align 4 .b8 _Z12insideSphere6float3S_fPf_param_1[12],
	.param .b32 _Z12insideSphere6float3S_fPf_param_2,
	.param .b64 _Z12insideSphere6float3S_fPf_param_3
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<16>;
	.reg .s32 	%r<2>;
	.reg .s64 	%rd<2>;


	ld.param.f32 	%f1, [_Z12insideSphere6float3S_fPf_param_0+8];
	ld.param.f32 	%f2, [_Z12insideSphere6float3S_fPf_param_0+4];
	ld.param.f32 	%f3, [_Z12insideSphere6float3S_fPf_param_0];
	ld.param.f32 	%f4, [_Z12insideSphere6float3S_fPf_param_1+8];
	ld.param.f32 	%f5, [_Z12insideSphere6float3S_fPf_param_1+4];
	ld.param.f32 	%f6, [_Z12insideSphere6float3S_fPf_param_1];
	ld.param.f32 	%f7, [_Z12insideSphere6float3S_fPf_param_2];
	ld.param.u64 	%rd1, [_Z12insideSphere6float3S_fPf_param_3];
	sub.f32 	%f8, %f3, %f6;
	sub.f32 	%f9, %f2, %f5;
	sub.f32 	%f10, %f1, %f4;
	mul.f32 	%f11, %f9, %f9;
	fma.rn.f32 	%f12, %f8, %f8, %f11;
	fma.rn.f32 	%f13, %f10, %f10, %f12;
	sqrt.rn.f32 	%f14, %f13;
	sqrt.rn.f32 	%f15, %f7;
	st.f32 	[%rd1], %f14;
	setp.le.f32	%p1, %f14, %f15;
	selp.u32	%r1, 1, 0, %p1;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	_Z7degreesf
.visible .func  (.param .b32 func_retval0) _Z7degreesf(
	.param .b32 _Z7degreesf_param_0
)
{
	.reg .f32 	%f<3>;
	.reg .f64 	%fd<3>;


	ld.param.f32 	%f1, [_Z7degreesf_param_0];
	cvt.f64.f32	%fd1, %f1;
	mul.f64 	%fd2, %fd1, 0d404CA5DC1A63C1F8;
	cvt.rn.f32.f64	%f2, %fd2;
	st.param.f32	[func_retval0+0], %f2;
	ret;
}

	// .globl	_Z7radiansf
.visible .func  (.param .b32 func_retval0) _Z7radiansf(
	.param .b32 _Z7radiansf_param_0
)
{
	.reg .f32 	%f<3>;
	.reg .f64 	%fd<3>;


	ld.param.f32 	%f1, [_Z7radiansf_param_0];
	cvt.f64.f32	%fd1, %f1;
	mul.f64 	%fd2, %fd1, 0d3F91DF46A2529D39;
	cvt.rn.f32.f64	%f2, %fd2;
	st.param.f32	[func_retval0+0], %f2;
	ret;
}

	// .globl	_Z8sdfCross6float3
.visible .func  (.param .b32 func_retval0) _Z8sdfCross6float3(
	.param .align 4 .b8 _Z8sdfCross6float3_param_0[12]
)
{
	.reg .f32 	%f<46>;


	ld.param.f32 	%f1, [_Z8sdfCross6float3_param_0+8];
	ld.param.f32 	%f2, [_Z8sdfCross6float3_param_0+4];
	ld.param.f32 	%f3, [_Z8sdfCross6float3_param_0];
	abs.f32 	%f4, %f3;
	abs.f32 	%f5, %f2;
	abs.f32 	%f6, %f1;
	add.f32 	%f7, %f4, 0fC61C4000;
	add.f32 	%f8, %f5, 0fBF800000;
	add.f32 	%f9, %f6, 0fBF800000;
	max.f32 	%f10, %f8, %f9;
	max.f32 	%f11, %f7, %f10;
	mov.f32 	%f12, 0f00000000;
	min.f32 	%f13, %f11, %f12;
	max.f32 	%f14, %f7, %f12;
	max.f32 	%f15, %f8, %f12;
	max.f32 	%f16, %f9, %f12;
	mul.f32 	%f17, %f15, %f15;
	fma.rn.f32 	%f18, %f14, %f14, %f17;
	fma.rn.f32 	%f19, %f16, %f16, %f18;
	sqrt.rn.f32 	%f20, %f19;
	add.f32 	%f21, %f13, %f20;
	add.f32 	%f22, %f6, 0fC61C4000;
	add.f32 	%f23, %f4, 0fBF800000;
	max.f32 	%f24, %f22, %f23;
	max.f32 	%f25, %f8, %f24;
	min.f32 	%f26, %f25, %f12;
	max.f32 	%f27, %f22, %f12;
	max.f32 	%f28, %f23, %f12;
	mul.f32 	%f29, %f27, %f27;
	fma.rn.f32 	%f30, %f15, %f15, %f29;
	mul.f32 	%f31, %f28, %f28;
	add.f32 	%f32, %f30, %f31;
	sqrt.rn.f32 	%f33, %f32;
	add.f32 	%f34, %f26, %f33;
	add.f32 	%f35, %f5, 0fC61C4000;
	max.f32 	%f36, %f23, %f35;
	max.f32 	%f37, %f9, %f36;
	min.f32 	%f38, %f37, %f12;
	max.f32 	%f39, %f35, %f12;
	fma.rn.f32 	%f40, %f16, %f16, %f31;
	fma.rn.f32 	%f41, %f39, %f39, %f40;
	sqrt.rn.f32 	%f42, %f41;
	add.f32 	%f43, %f38, %f42;
	min.f32 	%f44, %f34, %f43;
	min.f32 	%f45, %f21, %f44;
	st.param.f32	[func_retval0+0], %f45;
	ret;
}

	// .globl	_Z6rotate6float2f
.visible .func  (.param .align 8 .b8 func_retval0[8]) _Z6rotate6float2f(
	.param .align 8 .b8 _Z6rotate6float2f_param_0[8],
	.param .b32 _Z6rotate6float2f_param_1
)
{
	.local .align 4 .b8 	__local_depot8[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<53>;
	.reg .f32 	%f<193>;
	.reg .s32 	%r<366>;
	.reg .s64 	%rd<45>;


	mov.u64 	%rd44, __local_depot8;
	cvta.local.u64 	%SP, %rd44;
	ld.param.f32 	%f72, [_Z6rotate6float2f_param_0+4];
	ld.param.f32 	%f71, [_Z6rotate6float2f_param_0];
	ld.param.f32 	%f73, [_Z6rotate6float2f_param_1];
	add.u64 	%rd24, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd24;
	abs.f32 	%f1, %f73;
	setp.neu.f32	%p1, %f1, 0f7F800000;
	mov.f32 	%f188, %f73;
	@%p1 bra 	BB8_2;

	mov.f32 	%f74, 0f00000000;
	mul.rn.f32 	%f2, %f73, %f74;
	mov.f32 	%f188, %f2;

BB8_2:
	mov.f32 	%f3, %f188;
	mul.f32 	%f75, %f3, 0f3F22F983;
	cvt.rni.s32.f32	%r335, %f75;
	cvt.rn.f32.s32	%f76, %r335;
	neg.f32 	%f77, %f76;
	mov.f32 	%f78, 0f3FC90FDA;
	fma.rn.f32 	%f79, %f77, %f78, %f3;
	mov.f32 	%f80, 0f33A22168;
	fma.rn.f32 	%f81, %f77, %f80, %f79;
	mov.f32 	%f82, 0f27C234C5;
	fma.rn.f32 	%f170, %f77, %f82, %f81;
	abs.f32 	%f83, %f3;
	setp.leu.f32	%p2, %f83, 0f47CE4780;
	@%p2 bra 	BB8_12;

	mov.b32 	 %r2, %f3;
	shl.b32 	%r147, %r2, 8;
	or.b32  	%r3, %r147, -2147483648;
	mov.u32 	%r327, 0;
	mov.u64 	%rd33, __cudart_i2opi_f;
	mov.u32 	%r326, -6;
	mov.u64 	%rd43, %rd1;

BB8_4:
	.pragma "nounroll";
	mov.u64 	%rd3, %rd43;
	ld.const.u32 	%r150, [%rd33];
	// inline asm
	{
	mad.lo.cc.u32   %r148, %r150, %r3, %r327;
	madc.hi.u32     %r149, %r150, %r3,  0;
	}
	// inline asm
	mov.u32 	%r327, %r149;
	st.local.u32 	[%rd3], %r148;
	add.s64 	%rd4, %rd3, 4;
	add.s64 	%rd33, %rd33, 4;
	add.s32 	%r326, %r326, 1;
	setp.ne.s32	%p3, %r326, 0;
	mov.u64 	%rd43, %rd4;
	@%p3 bra 	BB8_4;

	and.b32  	%r8, %r2, -2147483648;
	bfe.u32 	%r153, %r2, 23, 8;
	add.s32 	%r154, %r153, -128;
	shr.u32 	%r155, %r154, 5;
	st.local.u32 	[%rd1+24], %r149;
	bfe.u32 	%r9, %r2, 23, 5;
	mov.u32 	%r156, 6;
	sub.s32 	%r157, %r156, %r155;
	mul.wide.s32 	%rd26, %r157, 4;
	add.s64 	%rd6, %rd1, %rd26;
	ld.local.u32 	%r328, [%rd6];
	ld.local.u32 	%r329, [%rd6+-4];
	setp.eq.s32	%p4, %r9, 0;
	@%p4 bra 	BB8_7;

	mov.u32 	%r158, 32;
	sub.s32 	%r159, %r158, %r9;
	shr.u32 	%r160, %r329, %r159;
	shl.b32 	%r161, %r328, %r9;
	add.s32 	%r328, %r160, %r161;
	ld.local.u32 	%r162, [%rd6+-8];
	shr.u32 	%r163, %r162, %r159;
	shl.b32 	%r164, %r329, %r9;
	add.s32 	%r329, %r163, %r164;

BB8_7:
	shr.u32 	%r165, %r329, 30;
	shl.b32 	%r166, %r328, 2;
	add.s32 	%r330, %r165, %r166;
	shl.b32 	%r17, %r329, 2;
	shr.u32 	%r167, %r330, 31;
	shr.u32 	%r168, %r328, 30;
	add.s32 	%r18, %r167, %r168;
	setp.eq.s32	%p5, %r167, 0;
	mov.u32 	%r331, %r8;
	mov.u32 	%r332, %r17;
	@%p5 bra 	BB8_9;

	not.b32 	%r169, %r330;
	neg.s32 	%r19, %r17;
	setp.eq.s32	%p6, %r17, 0;
	selp.u32	%r170, 1, 0, %p6;
	add.s32 	%r330, %r170, %r169;
	xor.b32  	%r21, %r8, -2147483648;
	mov.u32 	%r331, %r21;
	mov.u32 	%r332, %r19;

BB8_9:
	mov.u32 	%r23, %r331;
	neg.s32 	%r171, %r18;
	setp.eq.s32	%p7, %r8, 0;
	selp.b32	%r335, %r18, %r171, %p7;
	clz.b32 	%r334, %r330;
	setp.eq.s32	%p8, %r334, 0;
	shl.b32 	%r172, %r330, %r334;
	mov.u32 	%r173, 32;
	sub.s32 	%r174, %r173, %r334;
	shr.u32 	%r175, %r332, %r174;
	add.s32 	%r176, %r175, %r172;
	selp.b32	%r27, %r330, %r176, %p8;
	mov.u32 	%r177, -921707870;
	mul.hi.u32 	%r333, %r27, %r177;
	setp.lt.s32	%p9, %r333, 1;
	@%p9 bra 	BB8_11;

	mul.lo.s32 	%r178, %r27, -921707870;
	shr.u32 	%r179, %r178, 31;
	shl.b32 	%r180, %r333, 1;
	add.s32 	%r333, %r179, %r180;
	add.s32 	%r334, %r334, 1;

BB8_11:
	mov.u32 	%r181, 126;
	sub.s32 	%r182, %r181, %r334;
	shl.b32 	%r183, %r182, 23;
	add.s32 	%r184, %r333, 1;
	shr.u32 	%r185, %r184, 7;
	add.s32 	%r186, %r185, 1;
	shr.u32 	%r187, %r186, 1;
	add.s32 	%r188, %r187, %r183;
	or.b32  	%r189, %r188, %r23;
	mov.b32 	 %f170, %r189;

BB8_12:
	mul.rn.f32 	%f7, %f170, %f170;
	add.s32 	%r34, %r335, 1;
	and.b32  	%r35, %r34, 1;
	setp.eq.s32	%p10, %r35, 0;
	@%p10 bra 	BB8_14;

	mov.f32 	%f84, 0fBAB6061A;
	mov.f32 	%f85, 0f37CCF5CE;
	fma.rn.f32 	%f171, %f85, %f7, %f84;
	bra.uni 	BB8_15;

BB8_14:
	mov.f32 	%f86, 0f3C08839E;
	mov.f32 	%f87, 0fB94CA1F9;
	fma.rn.f32 	%f171, %f87, %f7, %f86;

BB8_15:
	@%p10 bra 	BB8_17;

	mov.f32 	%f88, 0f3D2AAAA5;
	fma.rn.f32 	%f89, %f171, %f7, %f88;
	mov.f32 	%f90, 0fBF000000;
	fma.rn.f32 	%f172, %f89, %f7, %f90;
	bra.uni 	BB8_18;

BB8_17:
	mov.f32 	%f91, 0fBE2AAAA3;
	fma.rn.f32 	%f92, %f171, %f7, %f91;
	mov.f32 	%f93, 0f00000000;
	fma.rn.f32 	%f172, %f92, %f7, %f93;

BB8_18:
	fma.rn.f32 	%f173, %f172, %f170, %f170;
	@%p10 bra 	BB8_20;

	mov.f32 	%f94, 0f3F800000;
	fma.rn.f32 	%f173, %f172, %f7, %f94;

BB8_20:
	and.b32  	%r190, %r34, 2;
	setp.eq.s32	%p13, %r190, 0;
	@%p13 bra 	BB8_22;

	mov.f32 	%f95, 0f00000000;
	mov.f32 	%f96, 0fBF800000;
	fma.rn.f32 	%f173, %f173, %f96, %f95;

BB8_22:
	mov.f32 	%f187, %f73;
	@%p1 bra 	BB8_24;

	mov.f32 	%f97, 0f00000000;
	mul.rn.f32 	%f187, %f73, %f97;

BB8_24:
	mul.f32 	%f98, %f187, 0f3F22F983;
	cvt.rni.s32.f32	%r345, %f98;
	cvt.rn.f32.s32	%f99, %r345;
	neg.f32 	%f100, %f99;
	fma.rn.f32 	%f102, %f100, %f78, %f187;
	fma.rn.f32 	%f104, %f100, %f80, %f102;
	fma.rn.f32 	%f174, %f100, %f82, %f104;
	abs.f32 	%f106, %f187;
	setp.leu.f32	%p15, %f106, 0f47CE4780;
	@%p15 bra 	BB8_34;

	mov.b32 	 %r37, %f187;
	shr.u32 	%r38, %r37, 23;
	bfe.u32 	%r193, %r37, 23, 8;
	add.s32 	%r194, %r193, -128;
	shl.b32 	%r195, %r37, 8;
	or.b32  	%r39, %r195, -2147483648;
	shr.u32 	%r40, %r194, 5;
	mov.u32 	%r337, 0;
	mov.u64 	%rd34, __cudart_i2opi_f;
	mov.u32 	%r336, -6;
	mov.u64 	%rd42, %rd1;

BB8_26:
	.pragma "nounroll";
	ld.const.u32 	%r198, [%rd34];
	// inline asm
	{
	mad.lo.cc.u32   %r196, %r198, %r39, %r337;
	madc.hi.u32     %r197, %r198, %r39,  0;
	}
	// inline asm
	mov.u32 	%r337, %r197;
	st.local.u32 	[%rd42], %r196;
	add.s64 	%rd42, %rd42, 4;
	add.s64 	%rd34, %rd34, 4;
	add.s32 	%r336, %r336, 1;
	setp.ne.s32	%p16, %r336, 0;
	@%p16 bra 	BB8_26;

	and.b32  	%r45, %r37, -2147483648;
	st.local.u32 	[%rd1+24], %r197;
	mov.u32 	%r201, 6;
	sub.s32 	%r202, %r201, %r40;
	mul.wide.s32 	%rd28, %r202, 4;
	add.s64 	%rd11, %rd1, %rd28;
	ld.local.u32 	%r338, [%rd11];
	ld.local.u32 	%r339, [%rd11+-4];
	and.b32  	%r48, %r38, 31;
	setp.eq.s32	%p17, %r48, 0;
	@%p17 bra 	BB8_29;

	mov.u32 	%r203, 32;
	sub.s32 	%r204, %r203, %r48;
	shr.u32 	%r205, %r339, %r204;
	shl.b32 	%r206, %r338, %r48;
	add.s32 	%r338, %r205, %r206;
	ld.local.u32 	%r207, [%rd11+-8];
	shr.u32 	%r208, %r207, %r204;
	shl.b32 	%r209, %r339, %r48;
	add.s32 	%r339, %r208, %r209;

BB8_29:
	shr.u32 	%r210, %r339, 30;
	shl.b32 	%r211, %r338, 2;
	add.s32 	%r340, %r210, %r211;
	shl.b32 	%r54, %r339, 2;
	shr.u32 	%r212, %r340, 31;
	shr.u32 	%r213, %r338, 30;
	add.s32 	%r55, %r212, %r213;
	setp.eq.s32	%p18, %r212, 0;
	mov.u32 	%r341, %r45;
	mov.u32 	%r342, %r54;
	@%p18 bra 	BB8_31;

	not.b32 	%r214, %r340;
	neg.s32 	%r56, %r54;
	setp.eq.s32	%p19, %r54, 0;
	selp.u32	%r215, 1, 0, %p19;
	add.s32 	%r340, %r215, %r214;
	xor.b32  	%r58, %r45, -2147483648;
	mov.u32 	%r341, %r58;
	mov.u32 	%r342, %r56;

BB8_31:
	mov.u32 	%r60, %r341;
	neg.s32 	%r216, %r55;
	setp.eq.s32	%p20, %r45, 0;
	selp.b32	%r345, %r55, %r216, %p20;
	clz.b32 	%r344, %r340;
	setp.eq.s32	%p21, %r344, 0;
	shl.b32 	%r217, %r340, %r344;
	mov.u32 	%r218, 32;
	sub.s32 	%r219, %r218, %r344;
	shr.u32 	%r220, %r342, %r219;
	add.s32 	%r221, %r220, %r217;
	selp.b32	%r64, %r340, %r221, %p21;
	mov.u32 	%r222, -921707870;
	mul.hi.u32 	%r343, %r64, %r222;
	setp.lt.s32	%p22, %r343, 1;
	@%p22 bra 	BB8_33;

	mul.lo.s32 	%r223, %r64, -921707870;
	shr.u32 	%r224, %r223, 31;
	shl.b32 	%r225, %r343, 1;
	add.s32 	%r343, %r224, %r225;
	add.s32 	%r344, %r344, 1;

BB8_33:
	mov.u32 	%r226, 126;
	sub.s32 	%r227, %r226, %r344;
	shl.b32 	%r228, %r227, 23;
	add.s32 	%r229, %r343, 1;
	shr.u32 	%r230, %r229, 7;
	add.s32 	%r231, %r230, 1;
	shr.u32 	%r232, %r231, 1;
	add.s32 	%r233, %r232, %r228;
	or.b32  	%r234, %r233, %r60;
	mov.b32 	 %f174, %r234;

BB8_34:
	mul.rn.f32 	%f24, %f174, %f174;
	and.b32  	%r71, %r345, 1;
	setp.eq.s32	%p23, %r71, 0;
	@%p23 bra 	BB8_36;

	mov.f32 	%f107, 0fBAB6061A;
	mov.f32 	%f108, 0f37CCF5CE;
	fma.rn.f32 	%f175, %f108, %f24, %f107;
	bra.uni 	BB8_37;

BB8_36:
	mov.f32 	%f109, 0f3C08839E;
	mov.f32 	%f110, 0fB94CA1F9;
	fma.rn.f32 	%f175, %f110, %f24, %f109;

BB8_37:
	@%p23 bra 	BB8_39;

	mov.f32 	%f111, 0f3D2AAAA5;
	fma.rn.f32 	%f112, %f175, %f24, %f111;
	mov.f32 	%f113, 0fBF000000;
	fma.rn.f32 	%f176, %f112, %f24, %f113;
	bra.uni 	BB8_40;

BB8_39:
	mov.f32 	%f114, 0fBE2AAAA3;
	fma.rn.f32 	%f115, %f175, %f24, %f114;
	mov.f32 	%f116, 0f00000000;
	fma.rn.f32 	%f176, %f115, %f24, %f116;

BB8_40:
	fma.rn.f32 	%f177, %f176, %f174, %f174;
	@%p23 bra 	BB8_42;

	mov.f32 	%f117, 0f3F800000;
	fma.rn.f32 	%f177, %f176, %f24, %f117;

BB8_42:
	and.b32  	%r235, %r345, 2;
	setp.eq.s32	%p26, %r235, 0;
	@%p26 bra 	BB8_44;

	mov.f32 	%f118, 0f00000000;
	mov.f32 	%f119, 0fBF800000;
	fma.rn.f32 	%f177, %f177, %f119, %f118;

BB8_44:
	mul.f32 	%f120, %f72, %f177;
	fma.rn.f32 	%f36, %f71, %f173, %f120;
	mov.f32 	%f186, %f73;
	@%p1 bra 	BB8_46;

	mov.f32 	%f121, 0f00000000;
	mul.rn.f32 	%f186, %f73, %f121;

BB8_46:
	mul.f32 	%f122, %f186, 0f3F22F983;
	cvt.rni.s32.f32	%r355, %f122;
	cvt.rn.f32.s32	%f123, %r355;
	neg.f32 	%f124, %f123;
	fma.rn.f32 	%f126, %f124, %f78, %f186;
	fma.rn.f32 	%f128, %f124, %f80, %f126;
	fma.rn.f32 	%f178, %f124, %f82, %f128;
	abs.f32 	%f130, %f186;
	setp.leu.f32	%p28, %f130, 0f47CE4780;
	@%p28 bra 	BB8_56;

	mov.b32 	 %r73, %f186;
	shr.u32 	%r74, %r73, 23;
	bfe.u32 	%r238, %r73, 23, 8;
	add.s32 	%r239, %r238, -128;
	shl.b32 	%r240, %r73, 8;
	or.b32  	%r75, %r240, -2147483648;
	shr.u32 	%r76, %r239, 5;
	mov.u32 	%r347, 0;
	mov.u64 	%rd35, __cudart_i2opi_f;
	mov.u32 	%r346, -6;
	mov.u64 	%rd41, %rd1;

BB8_48:
	.pragma "nounroll";
	ld.const.u32 	%r243, [%rd35];
	// inline asm
	{
	mad.lo.cc.u32   %r241, %r243, %r75, %r347;
	madc.hi.u32     %r242, %r243, %r75,  0;
	}
	// inline asm
	mov.u32 	%r347, %r242;
	st.local.u32 	[%rd41], %r241;
	add.s64 	%rd41, %rd41, 4;
	add.s64 	%rd35, %rd35, 4;
	add.s32 	%r346, %r346, 1;
	setp.ne.s32	%p29, %r346, 0;
	@%p29 bra 	BB8_48;

	and.b32  	%r81, %r73, -2147483648;
	st.local.u32 	[%rd1+24], %r242;
	mov.u32 	%r246, 6;
	sub.s32 	%r247, %r246, %r76;
	mul.wide.s32 	%rd30, %r247, 4;
	add.s64 	%rd17, %rd1, %rd30;
	ld.local.u32 	%r348, [%rd17];
	ld.local.u32 	%r349, [%rd17+-4];
	and.b32  	%r84, %r74, 31;
	setp.eq.s32	%p30, %r84, 0;
	@%p30 bra 	BB8_51;

	mov.u32 	%r248, 32;
	sub.s32 	%r249, %r248, %r84;
	shr.u32 	%r250, %r349, %r249;
	shl.b32 	%r251, %r348, %r84;
	add.s32 	%r348, %r250, %r251;
	ld.local.u32 	%r252, [%rd17+-8];
	shr.u32 	%r253, %r252, %r249;
	shl.b32 	%r254, %r349, %r84;
	add.s32 	%r349, %r253, %r254;

BB8_51:
	shr.u32 	%r255, %r349, 30;
	shl.b32 	%r256, %r348, 2;
	add.s32 	%r350, %r255, %r256;
	shl.b32 	%r90, %r349, 2;
	shr.u32 	%r257, %r350, 31;
	shr.u32 	%r258, %r348, 30;
	add.s32 	%r91, %r257, %r258;
	setp.eq.s32	%p31, %r257, 0;
	mov.u32 	%r351, %r81;
	mov.u32 	%r352, %r90;
	@%p31 bra 	BB8_53;

	not.b32 	%r259, %r350;
	neg.s32 	%r92, %r90;
	setp.eq.s32	%p32, %r90, 0;
	selp.u32	%r260, 1, 0, %p32;
	add.s32 	%r350, %r260, %r259;
	xor.b32  	%r94, %r81, -2147483648;
	mov.u32 	%r351, %r94;
	mov.u32 	%r352, %r92;

BB8_53:
	mov.u32 	%r96, %r351;
	neg.s32 	%r261, %r91;
	setp.eq.s32	%p33, %r81, 0;
	selp.b32	%r355, %r91, %r261, %p33;
	clz.b32 	%r354, %r350;
	setp.eq.s32	%p34, %r354, 0;
	shl.b32 	%r262, %r350, %r354;
	mov.u32 	%r263, 32;
	sub.s32 	%r264, %r263, %r354;
	shr.u32 	%r265, %r352, %r264;
	add.s32 	%r266, %r265, %r262;
	selp.b32	%r100, %r350, %r266, %p34;
	mov.u32 	%r267, -921707870;
	mul.hi.u32 	%r353, %r100, %r267;
	setp.lt.s32	%p35, %r353, 1;
	@%p35 bra 	BB8_55;

	mul.lo.s32 	%r268, %r100, -921707870;
	shr.u32 	%r269, %r268, 31;
	shl.b32 	%r270, %r353, 1;
	add.s32 	%r353, %r269, %r270;
	add.s32 	%r354, %r354, 1;

BB8_55:
	mov.u32 	%r271, 126;
	sub.s32 	%r272, %r271, %r354;
	shl.b32 	%r273, %r272, 23;
	add.s32 	%r274, %r353, 1;
	shr.u32 	%r275, %r274, 7;
	add.s32 	%r276, %r275, 1;
	shr.u32 	%r277, %r276, 1;
	add.s32 	%r278, %r277, %r273;
	or.b32  	%r279, %r278, %r96;
	mov.b32 	 %f178, %r279;

BB8_56:
	mul.rn.f32 	%f42, %f178, %f178;
	and.b32  	%r107, %r355, 1;
	setp.eq.s32	%p36, %r107, 0;
	@%p36 bra 	BB8_58;

	mov.f32 	%f131, 0fBAB6061A;
	mov.f32 	%f132, 0f37CCF5CE;
	fma.rn.f32 	%f179, %f132, %f42, %f131;
	bra.uni 	BB8_59;

BB8_58:
	mov.f32 	%f133, 0f3C08839E;
	mov.f32 	%f134, 0fB94CA1F9;
	fma.rn.f32 	%f179, %f134, %f42, %f133;

BB8_59:
	@%p36 bra 	BB8_61;

	mov.f32 	%f135, 0f3D2AAAA5;
	fma.rn.f32 	%f136, %f179, %f42, %f135;
	mov.f32 	%f137, 0fBF000000;
	fma.rn.f32 	%f180, %f136, %f42, %f137;
	bra.uni 	BB8_62;

BB8_61:
	mov.f32 	%f138, 0fBE2AAAA3;
	fma.rn.f32 	%f139, %f179, %f42, %f138;
	mov.f32 	%f140, 0f00000000;
	fma.rn.f32 	%f180, %f139, %f42, %f140;

BB8_62:
	fma.rn.f32 	%f181, %f180, %f178, %f178;
	@%p36 bra 	BB8_64;

	mov.f32 	%f141, 0f3F800000;
	fma.rn.f32 	%f181, %f180, %f42, %f141;

BB8_64:
	and.b32  	%r280, %r355, 2;
	setp.eq.s32	%p39, %r280, 0;
	@%p39 bra 	BB8_66;

	mov.f32 	%f142, 0f00000000;
	mov.f32 	%f143, 0fBF800000;
	fma.rn.f32 	%f181, %f181, %f143, %f142;

BB8_66:
	mov.f32 	%f185, %f73;
	@%p1 bra 	BB8_68;

	mov.f32 	%f144, 0f00000000;
	mul.rn.f32 	%f185, %f73, %f144;

BB8_68:
	mul.f32 	%f145, %f185, 0f3F22F983;
	cvt.rni.s32.f32	%r365, %f145;
	cvt.rn.f32.s32	%f146, %r365;
	neg.f32 	%f147, %f146;
	fma.rn.f32 	%f149, %f147, %f78, %f185;
	fma.rn.f32 	%f151, %f147, %f80, %f149;
	fma.rn.f32 	%f189, %f147, %f82, %f151;
	abs.f32 	%f153, %f185;
	setp.leu.f32	%p41, %f153, 0f47CE4780;
	@%p41 bra 	BB8_78;

	mov.b32 	 %r109, %f185;
	shr.u32 	%r110, %r109, 23;
	bfe.u32 	%r283, %r109, 23, 8;
	add.s32 	%r284, %r283, -128;
	shl.b32 	%r285, %r109, 8;
	or.b32  	%r111, %r285, -2147483648;
	shr.u32 	%r112, %r284, 5;
	mov.u32 	%r357, 0;
	mov.u64 	%rd36, __cudart_i2opi_f;
	mov.u32 	%r356, -6;
	mov.u64 	%rd40, %rd1;

BB8_70:
	.pragma "nounroll";
	ld.const.u32 	%r288, [%rd36];
	// inline asm
	{
	mad.lo.cc.u32   %r286, %r288, %r111, %r357;
	madc.hi.u32     %r287, %r288, %r111,  0;
	}
	// inline asm
	mov.u32 	%r357, %r287;
	st.local.u32 	[%rd40], %r286;
	add.s64 	%rd40, %rd40, 4;
	add.s64 	%rd36, %rd36, 4;
	add.s32 	%r356, %r356, 1;
	setp.ne.s32	%p42, %r356, 0;
	@%p42 bra 	BB8_70;

	and.b32  	%r117, %r109, -2147483648;
	st.local.u32 	[%rd1+24], %r287;
	mov.u32 	%r291, 6;
	sub.s32 	%r292, %r291, %r112;
	mul.wide.s32 	%rd32, %r292, 4;
	add.s64 	%rd23, %rd1, %rd32;
	ld.local.u32 	%r358, [%rd23];
	ld.local.u32 	%r359, [%rd23+-4];
	and.b32  	%r120, %r110, 31;
	setp.eq.s32	%p43, %r120, 0;
	@%p43 bra 	BB8_73;

	mov.u32 	%r293, 32;
	sub.s32 	%r294, %r293, %r120;
	shr.u32 	%r295, %r359, %r294;
	shl.b32 	%r296, %r358, %r120;
	add.s32 	%r358, %r295, %r296;
	ld.local.u32 	%r297, [%rd23+-8];
	shr.u32 	%r298, %r297, %r294;
	shl.b32 	%r299, %r359, %r120;
	add.s32 	%r359, %r298, %r299;

BB8_73:
	shr.u32 	%r300, %r359, 30;
	shl.b32 	%r301, %r358, 2;
	add.s32 	%r360, %r300, %r301;
	shl.b32 	%r126, %r359, 2;
	shr.u32 	%r302, %r360, 31;
	shr.u32 	%r303, %r358, 30;
	add.s32 	%r127, %r302, %r303;
	setp.eq.s32	%p44, %r302, 0;
	mov.u32 	%r361, %r117;
	mov.u32 	%r362, %r126;
	@%p44 bra 	BB8_75;

	not.b32 	%r304, %r360;
	neg.s32 	%r128, %r126;
	setp.eq.s32	%p45, %r126, 0;
	selp.u32	%r305, 1, 0, %p45;
	add.s32 	%r360, %r305, %r304;
	xor.b32  	%r130, %r117, -2147483648;
	mov.u32 	%r361, %r130;
	mov.u32 	%r362, %r128;

BB8_75:
	mov.u32 	%r132, %r361;
	neg.s32 	%r306, %r127;
	setp.eq.s32	%p46, %r117, 0;
	selp.b32	%r365, %r127, %r306, %p46;
	clz.b32 	%r364, %r360;
	setp.eq.s32	%p47, %r364, 0;
	shl.b32 	%r307, %r360, %r364;
	mov.u32 	%r308, 32;
	sub.s32 	%r309, %r308, %r364;
	shr.u32 	%r310, %r362, %r309;
	add.s32 	%r311, %r310, %r307;
	selp.b32	%r136, %r360, %r311, %p47;
	mov.u32 	%r312, -921707870;
	mul.hi.u32 	%r363, %r136, %r312;
	setp.lt.s32	%p48, %r363, 1;
	@%p48 bra 	BB8_77;

	mul.lo.s32 	%r313, %r136, -921707870;
	shr.u32 	%r314, %r313, 31;
	shl.b32 	%r315, %r363, 1;
	add.s32 	%r363, %r314, %r315;
	add.s32 	%r364, %r364, 1;

BB8_77:
	mov.u32 	%r316, 126;
	sub.s32 	%r317, %r316, %r364;
	shl.b32 	%r318, %r317, 23;
	add.s32 	%r319, %r363, 1;
	shr.u32 	%r320, %r319, 7;
	add.s32 	%r321, %r320, 1;
	shr.u32 	%r322, %r321, 1;
	add.s32 	%r323, %r322, %r318;
	or.b32  	%r324, %r323, %r132;
	mov.b32 	 %f189, %r324;

BB8_78:
	mul.rn.f32 	%f59, %f189, %f189;
	add.s32 	%r143, %r365, 1;
	and.b32  	%r144, %r143, 1;
	setp.eq.s32	%p49, %r144, 0;
	@%p49 bra 	BB8_80;

	mov.f32 	%f154, 0fBAB6061A;
	mov.f32 	%f155, 0f37CCF5CE;
	fma.rn.f32 	%f190, %f155, %f59, %f154;
	bra.uni 	BB8_81;

BB8_80:
	mov.f32 	%f156, 0f3C08839E;
	mov.f32 	%f157, 0fB94CA1F9;
	fma.rn.f32 	%f190, %f157, %f59, %f156;

BB8_81:
	@%p49 bra 	BB8_83;

	mov.f32 	%f158, 0f3D2AAAA5;
	fma.rn.f32 	%f159, %f190, %f59, %f158;
	mov.f32 	%f160, 0fBF000000;
	fma.rn.f32 	%f191, %f159, %f59, %f160;
	bra.uni 	BB8_84;

BB8_83:
	mov.f32 	%f161, 0fBE2AAAA3;
	fma.rn.f32 	%f162, %f190, %f59, %f161;
	mov.f32 	%f163, 0f00000000;
	fma.rn.f32 	%f191, %f162, %f59, %f163;

BB8_84:
	fma.rn.f32 	%f192, %f191, %f189, %f189;
	@%p49 bra 	BB8_86;

	mov.f32 	%f164, 0f3F800000;
	fma.rn.f32 	%f192, %f191, %f59, %f164;

BB8_86:
	and.b32  	%r325, %r143, 2;
	setp.eq.s32	%p52, %r325, 0;
	@%p52 bra 	BB8_88;

	mov.f32 	%f165, 0f00000000;
	mov.f32 	%f166, 0fBF800000;
	fma.rn.f32 	%f192, %f192, %f166, %f165;

BB8_88:
	mul.f32 	%f167, %f71, %f181;
	mul.f32 	%f168, %f72, %f192;
	sub.f32 	%f169, %f168, %f167;
	st.param.f32	[func_retval0+0], %f36;
	st.param.f32	[func_retval0+4], %f169;
	ret;
}

	// .globl	_Z3hit6float3jf
.visible .func  (.param .b32 func_retval0) _Z3hit6float3jf(
	.param .align 4 .b8 _Z3hit6float3jf_param_0[12],
	.param .b32 _Z3hit6float3jf_param_1,
	.param .b32 _Z3hit6float3jf_param_2
)
{
	.local .align 4 .b8 	__local_depot9[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<157>;
	.reg .f32 	%f<613>;
	.reg .s32 	%r<632>;
	.reg .f64 	%fd<3>;
	.reg .s64 	%rd<76>;


	mov.u64 	%rd75, __local_depot9;
	cvta.local.u64 	%SP, %rd75;
	ld.param.f32 	%f199, [_Z3hit6float3jf_param_0+8];
	ld.param.f32 	%f198, [_Z3hit6float3jf_param_0+4];
	ld.param.f32 	%f197, [_Z3hit6float3jf_param_0];
	ld.param.u32 	%r234, [_Z3hit6float3jf_param_1];
	ld.param.f32 	%f200, [_Z3hit6float3jf_param_2];
	add.u64 	%rd41, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd41;
	div.rn.f32 	%f553, %f200, 0f41900000;
	abs.f32 	%f201, %f553;
	setp.neu.f32	%p1, %f201, 0f7F800000;
	@%p1 bra 	BB9_2;

	mov.f32 	%f202, 0f00000000;
	mul.rn.f32 	%f553, %f553, %f202;

BB9_2:
	abs.f32 	%f203, %f553;
	add.s64 	%rd2, %rd1, 24;
	setp.leu.f32	%p2, %f203, 0f47CE4780;
	@%p2 bra 	BB9_6;

	mov.b32 	 %r237, %f553;
	shl.b32 	%r238, %r237, 8;
	or.b32  	%r1, %r238, -2147483648;
	mov.u32 	%r570, 0;
	mov.u64 	%rd55, __cudart_i2opi_f;
	mov.u32 	%r569, -6;
	mov.u64 	%rd74, %rd1;

BB9_4:
	.pragma "nounroll";
	ld.const.u32 	%r241, [%rd55];
	// inline asm
	{
	mad.lo.cc.u32   %r239, %r241, %r1, %r570;
	madc.hi.u32     %r240, %r241, %r1,  0;
	}
	// inline asm
	mov.u32 	%r570, %r240;
	st.local.u32 	[%rd74], %r239;
	add.s64 	%rd74, %rd74, 4;
	add.s64 	%rd55, %rd55, 4;
	add.s32 	%r569, %r569, 1;
	setp.ne.s32	%p3, %r569, 0;
	@%p3 bra 	BB9_4;

	st.local.u32 	[%rd2], %r240;

BB9_6:
	div.rn.f32 	%f554, %f200, 0f40B66666;
	abs.f32 	%f204, %f554;
	setp.neu.f32	%p4, %f204, 0f7F800000;
	@%p4 bra 	BB9_8;

	mov.f32 	%f205, 0f00000000;
	mul.rn.f32 	%f554, %f554, %f205;

BB9_8:
	mul.f32 	%f206, %f554, 0f3F22F983;
	cvt.rni.s32.f32	%r580, %f206;
	cvt.rn.f32.s32	%f207, %r580;
	neg.f32 	%f208, %f207;
	mov.f32 	%f209, 0f3FC90FDA;
	fma.rn.f32 	%f210, %f208, %f209, %f554;
	mov.f32 	%f211, 0f33A22168;
	fma.rn.f32 	%f212, %f208, %f211, %f210;
	mov.f32 	%f213, 0f27C234C5;
	fma.rn.f32 	%f555, %f208, %f213, %f212;
	abs.f32 	%f214, %f554;
	setp.leu.f32	%p5, %f214, 0f47CE4780;
	@%p5 bra 	BB9_18;

	mov.b32 	 %r7, %f554;
	shr.u32 	%r8, %r7, 23;
	bfe.u32 	%r246, %r7, 23, 8;
	add.s32 	%r247, %r246, -128;
	shl.b32 	%r248, %r7, 8;
	or.b32  	%r9, %r248, -2147483648;
	shr.u32 	%r10, %r247, 5;
	mov.u32 	%r572, 0;
	mov.u64 	%rd56, __cudart_i2opi_f;
	mov.u32 	%r571, -6;
	mov.u64 	%rd73, %rd1;

BB9_10:
	.pragma "nounroll";
	ld.const.u32 	%r251, [%rd56];
	// inline asm
	{
	mad.lo.cc.u32   %r249, %r251, %r9, %r572;
	madc.hi.u32     %r250, %r251, %r9,  0;
	}
	// inline asm
	mov.u32 	%r572, %r250;
	st.local.u32 	[%rd73], %r249;
	add.s64 	%rd73, %rd73, 4;
	add.s64 	%rd56, %rd56, 4;
	add.s32 	%r571, %r571, 1;
	setp.ne.s32	%p6, %r571, 0;
	@%p6 bra 	BB9_10;

	and.b32  	%r15, %r7, -2147483648;
	st.local.u32 	[%rd2], %r250;
	mov.u32 	%r254, 6;
	sub.s32 	%r255, %r254, %r10;
	mul.wide.s32 	%rd44, %r255, 4;
	add.s64 	%rd13, %rd1, %rd44;
	ld.local.u32 	%r573, [%rd13];
	ld.local.u32 	%r574, [%rd13+-4];
	and.b32  	%r18, %r8, 31;
	setp.eq.s32	%p7, %r18, 0;
	@%p7 bra 	BB9_13;

	mov.u32 	%r256, 32;
	sub.s32 	%r257, %r256, %r18;
	shr.u32 	%r258, %r574, %r257;
	shl.b32 	%r259, %r573, %r18;
	add.s32 	%r573, %r258, %r259;
	ld.local.u32 	%r260, [%rd13+-8];
	shr.u32 	%r261, %r260, %r257;
	shl.b32 	%r262, %r574, %r18;
	add.s32 	%r574, %r261, %r262;

BB9_13:
	shr.u32 	%r263, %r574, 30;
	shl.b32 	%r264, %r573, 2;
	add.s32 	%r575, %r263, %r264;
	shl.b32 	%r24, %r574, 2;
	shr.u32 	%r265, %r575, 31;
	shr.u32 	%r266, %r573, 30;
	add.s32 	%r25, %r265, %r266;
	setp.eq.s32	%p8, %r265, 0;
	mov.u32 	%r576, %r15;
	mov.u32 	%r577, %r24;
	@%p8 bra 	BB9_15;

	not.b32 	%r267, %r575;
	neg.s32 	%r26, %r24;
	setp.eq.s32	%p9, %r24, 0;
	selp.u32	%r268, 1, 0, %p9;
	add.s32 	%r575, %r268, %r267;
	xor.b32  	%r28, %r15, -2147483648;
	mov.u32 	%r576, %r28;
	mov.u32 	%r577, %r26;

BB9_15:
	mov.u32 	%r30, %r576;
	neg.s32 	%r269, %r25;
	setp.eq.s32	%p10, %r15, 0;
	selp.b32	%r580, %r25, %r269, %p10;
	clz.b32 	%r579, %r575;
	setp.eq.s32	%p11, %r579, 0;
	shl.b32 	%r270, %r575, %r579;
	mov.u32 	%r271, 32;
	sub.s32 	%r272, %r271, %r579;
	shr.u32 	%r273, %r577, %r272;
	add.s32 	%r274, %r273, %r270;
	selp.b32	%r34, %r575, %r274, %p11;
	mov.u32 	%r275, -921707870;
	mul.hi.u32 	%r578, %r34, %r275;
	setp.lt.s32	%p12, %r578, 1;
	@%p12 bra 	BB9_17;

	mul.lo.s32 	%r276, %r34, -921707870;
	shr.u32 	%r277, %r276, 31;
	shl.b32 	%r278, %r578, 1;
	add.s32 	%r578, %r277, %r278;
	add.s32 	%r579, %r579, 1;

BB9_17:
	mov.u32 	%r279, 126;
	sub.s32 	%r280, %r279, %r579;
	shl.b32 	%r281, %r280, 23;
	add.s32 	%r282, %r578, 1;
	shr.u32 	%r283, %r282, 7;
	add.s32 	%r284, %r283, 1;
	shr.u32 	%r285, %r284, 1;
	add.s32 	%r286, %r285, %r281;
	or.b32  	%r287, %r286, %r30;
	mov.b32 	 %f555, %r287;

BB9_18:
	mul.rn.f32 	%f10, %f555, %f555;
	add.s32 	%r41, %r580, 1;
	and.b32  	%r42, %r41, 1;
	setp.eq.s32	%p13, %r42, 0;
	@%p13 bra 	BB9_20;

	mov.f32 	%f215, 0fBAB6061A;
	mov.f32 	%f216, 0f37CCF5CE;
	fma.rn.f32 	%f556, %f216, %f10, %f215;
	bra.uni 	BB9_21;

BB9_20:
	mov.f32 	%f217, 0f3C08839E;
	mov.f32 	%f218, 0fB94CA1F9;
	fma.rn.f32 	%f556, %f218, %f10, %f217;

BB9_21:
	@%p13 bra 	BB9_23;

	mov.f32 	%f219, 0f3D2AAAA5;
	fma.rn.f32 	%f220, %f556, %f10, %f219;
	mov.f32 	%f221, 0fBF000000;
	fma.rn.f32 	%f557, %f220, %f10, %f221;
	bra.uni 	BB9_24;

BB9_23:
	mov.f32 	%f222, 0fBE2AAAA3;
	fma.rn.f32 	%f223, %f556, %f10, %f222;
	mov.f32 	%f224, 0f00000000;
	fma.rn.f32 	%f557, %f223, %f10, %f224;

BB9_24:
	fma.rn.f32 	%f558, %f557, %f555, %f555;
	@%p13 bra 	BB9_26;

	mov.f32 	%f225, 0f3F800000;
	fma.rn.f32 	%f558, %f557, %f10, %f225;

BB9_26:
	and.b32  	%r288, %r41, 2;
	setp.eq.s32	%p16, %r288, 0;
	@%p16 bra 	BB9_28;

	mov.f32 	%f226, 0f00000000;
	mov.f32 	%f227, 0fBF800000;
	fma.rn.f32 	%f558, %f558, %f227, %f226;

BB9_28:
	div.rn.f32 	%f559, %f200, 0f3FD9999A;
	abs.f32 	%f228, %f559;
	setp.neu.f32	%p17, %f228, 0f7F800000;
	@%p17 bra 	BB9_30;

	mov.f32 	%f229, 0f00000000;
	mul.rn.f32 	%f559, %f559, %f229;

BB9_30:
	mul.f32 	%f230, %f559, 0f3F22F983;
	cvt.rni.s32.f32	%r590, %f230;
	cvt.rn.f32.s32	%f231, %r590;
	neg.f32 	%f232, %f231;
	fma.rn.f32 	%f234, %f232, %f209, %f559;
	fma.rn.f32 	%f236, %f232, %f211, %f234;
	fma.rn.f32 	%f560, %f232, %f213, %f236;
	abs.f32 	%f238, %f559;
	setp.leu.f32	%p18, %f238, 0f47CE4780;
	@%p18 bra 	BB9_40;

	mov.b32 	 %r44, %f559;
	shr.u32 	%r45, %r44, 23;
	bfe.u32 	%r291, %r44, 23, 8;
	add.s32 	%r292, %r291, -128;
	shl.b32 	%r293, %r44, 8;
	or.b32  	%r46, %r293, -2147483648;
	shr.u32 	%r47, %r292, 5;
	mov.u32 	%r582, 0;
	mov.u64 	%rd57, __cudart_i2opi_f;
	mov.u32 	%r581, -6;
	mov.u64 	%rd72, %rd1;

BB9_32:
	.pragma "nounroll";
	ld.const.u32 	%r296, [%rd57];
	// inline asm
	{
	mad.lo.cc.u32   %r294, %r296, %r46, %r582;
	madc.hi.u32     %r295, %r296, %r46,  0;
	}
	// inline asm
	mov.u32 	%r582, %r295;
	st.local.u32 	[%rd72], %r294;
	add.s64 	%rd72, %rd72, 4;
	add.s64 	%rd57, %rd57, 4;
	add.s32 	%r581, %r581, 1;
	setp.ne.s32	%p19, %r581, 0;
	@%p19 bra 	BB9_32;

	and.b32  	%r52, %r44, -2147483648;
	st.local.u32 	[%rd2], %r295;
	mov.u32 	%r299, 6;
	sub.s32 	%r300, %r299, %r47;
	mul.wide.s32 	%rd46, %r300, 4;
	add.s64 	%rd19, %rd1, %rd46;
	ld.local.u32 	%r583, [%rd19];
	ld.local.u32 	%r584, [%rd19+-4];
	and.b32  	%r55, %r45, 31;
	setp.eq.s32	%p20, %r55, 0;
	@%p20 bra 	BB9_35;

	mov.u32 	%r301, 32;
	sub.s32 	%r302, %r301, %r55;
	shr.u32 	%r303, %r584, %r302;
	shl.b32 	%r304, %r583, %r55;
	add.s32 	%r583, %r303, %r304;
	ld.local.u32 	%r305, [%rd19+-8];
	shr.u32 	%r306, %r305, %r302;
	shl.b32 	%r307, %r584, %r55;
	add.s32 	%r584, %r306, %r307;

BB9_35:
	shr.u32 	%r308, %r584, 30;
	shl.b32 	%r309, %r583, 2;
	add.s32 	%r585, %r308, %r309;
	shl.b32 	%r61, %r584, 2;
	shr.u32 	%r310, %r585, 31;
	shr.u32 	%r311, %r583, 30;
	add.s32 	%r62, %r310, %r311;
	setp.eq.s32	%p21, %r310, 0;
	mov.u32 	%r586, %r52;
	mov.u32 	%r587, %r61;
	@%p21 bra 	BB9_37;

	not.b32 	%r312, %r585;
	neg.s32 	%r63, %r61;
	setp.eq.s32	%p22, %r61, 0;
	selp.u32	%r313, 1, 0, %p22;
	add.s32 	%r585, %r313, %r312;
	xor.b32  	%r65, %r52, -2147483648;
	mov.u32 	%r586, %r65;
	mov.u32 	%r587, %r63;

BB9_37:
	mov.u32 	%r67, %r586;
	neg.s32 	%r314, %r62;
	setp.eq.s32	%p23, %r52, 0;
	selp.b32	%r590, %r62, %r314, %p23;
	clz.b32 	%r589, %r585;
	setp.eq.s32	%p24, %r589, 0;
	shl.b32 	%r315, %r585, %r589;
	mov.u32 	%r316, 32;
	sub.s32 	%r317, %r316, %r589;
	shr.u32 	%r318, %r587, %r317;
	add.s32 	%r319, %r318, %r315;
	selp.b32	%r71, %r585, %r319, %p24;
	mov.u32 	%r320, -921707870;
	mul.hi.u32 	%r588, %r71, %r320;
	setp.lt.s32	%p25, %r588, 1;
	@%p25 bra 	BB9_39;

	mul.lo.s32 	%r321, %r71, -921707870;
	shr.u32 	%r322, %r321, 31;
	shl.b32 	%r323, %r588, 1;
	add.s32 	%r588, %r322, %r323;
	add.s32 	%r589, %r589, 1;

BB9_39:
	mov.u32 	%r324, 126;
	sub.s32 	%r325, %r324, %r589;
	shl.b32 	%r326, %r325, 23;
	add.s32 	%r327, %r588, 1;
	shr.u32 	%r328, %r327, 7;
	add.s32 	%r329, %r328, 1;
	shr.u32 	%r330, %r329, 1;
	add.s32 	%r331, %r330, %r326;
	or.b32  	%r332, %r331, %r67;
	mov.b32 	 %f560, %r332;

BB9_40:
	mul.rn.f32 	%f28, %f560, %f560;
	add.s32 	%r78, %r590, 1;
	and.b32  	%r79, %r78, 1;
	setp.eq.s32	%p26, %r79, 0;
	@%p26 bra 	BB9_42;

	mov.f32 	%f239, 0fBAB6061A;
	mov.f32 	%f240, 0f37CCF5CE;
	fma.rn.f32 	%f561, %f240, %f28, %f239;
	bra.uni 	BB9_43;

BB9_42:
	mov.f32 	%f241, 0f3C08839E;
	mov.f32 	%f242, 0fB94CA1F9;
	fma.rn.f32 	%f561, %f242, %f28, %f241;

BB9_43:
	@%p26 bra 	BB9_45;

	mov.f32 	%f243, 0f3D2AAAA5;
	fma.rn.f32 	%f244, %f561, %f28, %f243;
	mov.f32 	%f245, 0fBF000000;
	fma.rn.f32 	%f562, %f244, %f28, %f245;
	bra.uni 	BB9_46;

BB9_45:
	mov.f32 	%f246, 0fBE2AAAA3;
	fma.rn.f32 	%f247, %f561, %f28, %f246;
	mov.f32 	%f248, 0f00000000;
	fma.rn.f32 	%f562, %f247, %f28, %f248;

BB9_46:
	fma.rn.f32 	%f563, %f562, %f560, %f560;
	@%p26 bra 	BB9_48;

	mov.f32 	%f249, 0f3F800000;
	fma.rn.f32 	%f563, %f562, %f28, %f249;

BB9_48:
	and.b32  	%r333, %r78, 2;
	setp.eq.s32	%p29, %r333, 0;
	@%p29 bra 	BB9_50;

	mov.f32 	%f250, 0f00000000;
	mov.f32 	%f251, 0fBF800000;
	fma.rn.f32 	%f563, %f563, %f251, %f250;

BB9_50:
	abs.f32 	%f41, %f197;
	setp.eq.f32	%p30, %f41, 0f7F800000;
	mov.f32 	%f253, 0f40000000;
	abs.f32 	%f42, %f253;
	setp.eq.f32	%p31, %f42, 0f00000000;
	or.pred  	%p32, %p30, %p31;
	mov.f32 	%f252, 0f7FFFFFFF;
	mov.f32 	%f583, %f252;
	@%p32 bra 	BB9_64;

	setp.ltu.f32	%p33, %f41, %f42;
	@%p33 bra 	BB9_63;
	bra.uni 	BB9_52;

BB9_63:
	setp.gtu.f32	%p46, %f42, 0f7F800000;
	add.f32 	%f274, %f197, 0f40000000;
	selp.f32	%f275, %f274, %f197, %p46;
	add.f32 	%f276, %f197, %f275;
	setp.leu.f32	%p47, %f41, 0f00000000;
	selp.f32	%f56, %f276, %f275, %p47;
	mov.f32 	%f583, %f56;
	bra.uni 	BB9_64;

BB9_52:
	lg2.approx.f32 	%f254, %f41;
	cvt.rzi.s32.f32	%r334, %f254;
	lg2.approx.f32 	%f255, %f42;
	cvt.rzi.s32.f32	%r335, %f255;
	sub.s32 	%r80, %r334, %r335;
	abs.f32 	%f43, %f42;
	setp.eq.f32	%p34, %f43, 0f00000000;
	setp.eq.f32	%p35, %f43, 0f7F800000;
	or.pred  	%p36, %p34, %p35;
	setp.eq.s32	%p37, %r334, %r335;
	or.pred  	%p38, %p36, %p37;
	@%p38 bra 	BB9_58;
	bra.uni 	BB9_53;

BB9_58:
	setp.leu.f32	%p41, %f43, 0f00000000;
	add.f32 	%f270, %f42, %f42;
	selp.f32	%f564, %f270, %f42, %p41;
	bra.uni 	BB9_59;

BB9_53:
	abs.s32 	%r81, %r80;
	setp.lt.s32	%p39, %r81, 126;
	@%p39 bra 	BB9_57;
	bra.uni 	BB9_54;

BB9_57:
	cvt.rn.f32.s32	%f269, %r80;
	// inline asm
	ex2.approx.ftz.f32 %f268,%f269;
	// inline asm
	mul.f32 	%f564, %f42, %f268;
	bra.uni 	BB9_59;

BB9_54:
	setp.lt.s32	%p40, %r81, 252;
	@%p40 bra 	BB9_56;
	bra.uni 	BB9_55;

BB9_56:
	shr.u32 	%r341, %r80, 31;
	add.s32 	%r342, %r80, %r341;
	shr.s32 	%r343, %r342, 1;
	cvt.rn.f32.s32	%f264, %r343;
	// inline asm
	ex2.approx.ftz.f32 %f263,%f264;
	// inline asm
	mul.f32 	%f267, %f42, %f263;
	sub.s32 	%r344, %r80, %r343;
	cvt.rn.f32.s32	%f266, %r344;
	// inline asm
	ex2.approx.ftz.f32 %f265,%f266;
	// inline asm
	mul.f32 	%f564, %f267, %f265;
	bra.uni 	BB9_59;

BB9_55:
	shr.s32 	%r336, %r80, 31;
	shr.u32 	%r337, %r336, 30;
	add.s32 	%r338, %r80, %r337;
	shr.s32 	%r339, %r338, 2;
	cvt.rn.f32.s32	%f257, %r339;
	// inline asm
	ex2.approx.ftz.f32 %f256,%f257;
	// inline asm
	mul.f32 	%f260, %f42, %f256;
	mul.f32 	%f261, %f256, %f260;
	mul.f32 	%f262, %f256, %f261;
	mad.lo.s32 	%r340, %r339, -3, %r80;
	cvt.rn.f32.s32	%f259, %r340;
	// inline asm
	ex2.approx.ftz.f32 %f258,%f259;
	// inline asm
	mul.f32 	%f564, %f258, %f262;

BB9_59:
	mul.f32 	%f271, %f41, 0f3F000000;
	setp.gtu.f32	%p42, %f564, %f271;
	add.f32 	%f272, %f564, %f564;
	selp.f32	%f565, %f564, %f272, %p42;
	setp.ltu.f32	%p43, %f565, %f42;
	mov.f32 	%f568, %f41;
	@%p43 bra 	BB9_62;

	mov.f32 	%f569, %f41;

BB9_61:
	sub.f32 	%f273, %f569, %f565;
	setp.ltu.f32	%p44, %f569, %f565;
	selp.f32	%f569, %f569, %f273, %p44;
	mul.f32 	%f565, %f565, 0f3F000000;
	setp.ge.f32	%p45, %f565, %f42;
	mov.f32 	%f567, %f569;
	mov.f32 	%f568, %f567;
	@%p45 bra 	BB9_61;

BB9_62:
	mov.f32 	%f54, %f568;
	mov.b32 	 %r345, %f197;
	and.b32  	%r346, %r345, -2147483648;
	mov.b32 	 %r347, %f54;
	or.b32  	%r348, %r347, %r346;
	mov.b32 	 %f55, %r348;
	mov.f32 	%f583, %f55;

BB9_64:
	mov.f32 	%f57, %f583;
	abs.f32 	%f59, %f57;
	abs.f32 	%f572, %f198;
	setp.eq.f32	%p48, %f572, 0f7F800000;
	or.pred  	%p50, %p48, %p31;
	mov.f32 	%f582, %f252;
	@%p50 bra 	BB9_77;

	setp.ltu.f32	%p51, %f572, %f42;
	@%p51 bra 	BB9_76;
	bra.uni 	BB9_66;

BB9_76:
	setp.gtu.f32	%p64, %f42, 0f7F800000;
	add.f32 	%f298, %f198, 0f40000000;
	selp.f32	%f299, %f298, %f198, %p64;
	add.f32 	%f300, %f198, %f299;
	setp.leu.f32	%p65, %f572, 0f00000000;
	selp.f32	%f582, %f300, %f299, %p65;
	bra.uni 	BB9_77;

BB9_66:
	lg2.approx.f32 	%f278, %f572;
	cvt.rzi.s32.f32	%r349, %f278;
	lg2.approx.f32 	%f279, %f42;
	cvt.rzi.s32.f32	%r350, %f279;
	sub.s32 	%r82, %r349, %r350;
	abs.f32 	%f61, %f42;
	setp.eq.f32	%p52, %f61, 0f00000000;
	setp.eq.f32	%p53, %f61, 0f7F800000;
	or.pred  	%p54, %p52, %p53;
	setp.eq.s32	%p55, %r349, %r350;
	or.pred  	%p56, %p54, %p55;
	@%p56 bra 	BB9_72;
	bra.uni 	BB9_67;

BB9_72:
	setp.leu.f32	%p59, %f61, 0f00000000;
	add.f32 	%f294, %f42, %f42;
	selp.f32	%f570, %f294, %f42, %p59;
	bra.uni 	BB9_73;

BB9_67:
	abs.s32 	%r83, %r82;
	setp.lt.s32	%p57, %r83, 126;
	@%p57 bra 	BB9_71;
	bra.uni 	BB9_68;

BB9_71:
	cvt.rn.f32.s32	%f293, %r82;
	// inline asm
	ex2.approx.ftz.f32 %f292,%f293;
	// inline asm
	mul.f32 	%f570, %f42, %f292;
	bra.uni 	BB9_73;

BB9_68:
	setp.lt.s32	%p58, %r83, 252;
	@%p58 bra 	BB9_70;
	bra.uni 	BB9_69;

BB9_70:
	shr.u32 	%r356, %r82, 31;
	add.s32 	%r357, %r82, %r356;
	shr.s32 	%r358, %r357, 1;
	cvt.rn.f32.s32	%f288, %r358;
	// inline asm
	ex2.approx.ftz.f32 %f287,%f288;
	// inline asm
	mul.f32 	%f291, %f42, %f287;
	sub.s32 	%r359, %r82, %r358;
	cvt.rn.f32.s32	%f290, %r359;
	// inline asm
	ex2.approx.ftz.f32 %f289,%f290;
	// inline asm
	mul.f32 	%f570, %f291, %f289;
	bra.uni 	BB9_73;

BB9_69:
	shr.s32 	%r351, %r82, 31;
	shr.u32 	%r352, %r351, 30;
	add.s32 	%r353, %r82, %r352;
	shr.s32 	%r354, %r353, 2;
	cvt.rn.f32.s32	%f281, %r354;
	// inline asm
	ex2.approx.ftz.f32 %f280,%f281;
	// inline asm
	mul.f32 	%f284, %f42, %f280;
	mul.f32 	%f285, %f280, %f284;
	mul.f32 	%f286, %f280, %f285;
	mad.lo.s32 	%r355, %r354, -3, %r82;
	cvt.rn.f32.s32	%f283, %r355;
	// inline asm
	ex2.approx.ftz.f32 %f282,%f283;
	// inline asm
	mul.f32 	%f570, %f282, %f286;

BB9_73:
	mul.f32 	%f295, %f572, 0f3F000000;
	setp.gtu.f32	%p60, %f570, %f295;
	add.f32 	%f296, %f570, %f570;
	selp.f32	%f571, %f570, %f296, %p60;
	setp.ltu.f32	%p61, %f571, %f42;
	@%p61 bra 	BB9_75;

BB9_74:
	sub.f32 	%f297, %f572, %f571;
	setp.ltu.f32	%p62, %f572, %f571;
	selp.f32	%f572, %f572, %f297, %p62;
	mul.f32 	%f571, %f571, 0f3F000000;
	setp.ge.f32	%p63, %f571, %f42;
	@%p63 bra 	BB9_74;

BB9_75:
	mov.b32 	 %r360, %f198;
	and.b32  	%r361, %r360, -2147483648;
	mov.b32 	 %r362, %f572;
	or.b32  	%r363, %r362, %r361;
	mov.b32 	 %f582, %r363;

BB9_77:
	abs.f32 	%f77, %f582;
	abs.f32 	%f78, %f199;
	setp.eq.f32	%p66, %f78, 0f7F800000;
	or.pred  	%p68, %p66, %p31;
	mov.f32 	%f581, %f252;
	@%p68 bra 	BB9_91;

	setp.ltu.f32	%p69, %f78, %f42;
	@%p69 bra 	BB9_90;
	bra.uni 	BB9_79;

BB9_90:
	setp.gtu.f32	%p82, %f42, 0f7F800000;
	add.f32 	%f322, %f199, 0f40000000;
	selp.f32	%f323, %f322, %f199, %p82;
	add.f32 	%f324, %f199, %f323;
	setp.leu.f32	%p83, %f78, 0f00000000;
	selp.f32	%f581, %f324, %f323, %p83;
	bra.uni 	BB9_91;

BB9_79:
	lg2.approx.f32 	%f302, %f78;
	cvt.rzi.s32.f32	%r364, %f302;
	lg2.approx.f32 	%f303, %f42;
	cvt.rzi.s32.f32	%r365, %f303;
	sub.s32 	%r84, %r364, %r365;
	abs.f32 	%f79, %f42;
	setp.eq.f32	%p70, %f79, 0f00000000;
	setp.eq.f32	%p71, %f79, 0f7F800000;
	or.pred  	%p72, %p70, %p71;
	setp.eq.s32	%p73, %r364, %r365;
	or.pred  	%p74, %p72, %p73;
	@%p74 bra 	BB9_85;
	bra.uni 	BB9_80;

BB9_85:
	setp.leu.f32	%p77, %f79, 0f00000000;
	add.f32 	%f318, %f42, %f42;
	selp.f32	%f573, %f318, %f42, %p77;
	bra.uni 	BB9_86;

BB9_80:
	abs.s32 	%r85, %r84;
	setp.lt.s32	%p75, %r85, 126;
	@%p75 bra 	BB9_84;
	bra.uni 	BB9_81;

BB9_84:
	cvt.rn.f32.s32	%f317, %r84;
	// inline asm
	ex2.approx.ftz.f32 %f316,%f317;
	// inline asm
	mul.f32 	%f573, %f42, %f316;
	bra.uni 	BB9_86;

BB9_81:
	setp.lt.s32	%p76, %r85, 252;
	@%p76 bra 	BB9_83;
	bra.uni 	BB9_82;

BB9_83:
	shr.u32 	%r371, %r84, 31;
	add.s32 	%r372, %r84, %r371;
	shr.s32 	%r373, %r372, 1;
	cvt.rn.f32.s32	%f312, %r373;
	// inline asm
	ex2.approx.ftz.f32 %f311,%f312;
	// inline asm
	mul.f32 	%f315, %f42, %f311;
	sub.s32 	%r374, %r84, %r373;
	cvt.rn.f32.s32	%f314, %r374;
	// inline asm
	ex2.approx.ftz.f32 %f313,%f314;
	// inline asm
	mul.f32 	%f573, %f315, %f313;
	bra.uni 	BB9_86;

BB9_82:
	shr.s32 	%r366, %r84, 31;
	shr.u32 	%r367, %r366, 30;
	add.s32 	%r368, %r84, %r367;
	shr.s32 	%r369, %r368, 2;
	cvt.rn.f32.s32	%f305, %r369;
	// inline asm
	ex2.approx.ftz.f32 %f304,%f305;
	// inline asm
	mul.f32 	%f308, %f42, %f304;
	mul.f32 	%f309, %f304, %f308;
	mul.f32 	%f310, %f304, %f309;
	mad.lo.s32 	%r370, %r369, -3, %r84;
	cvt.rn.f32.s32	%f307, %r370;
	// inline asm
	ex2.approx.ftz.f32 %f306,%f307;
	// inline asm
	mul.f32 	%f573, %f306, %f310;

BB9_86:
	mul.f32 	%f319, %f78, 0f3F000000;
	setp.gtu.f32	%p78, %f573, %f319;
	add.f32 	%f320, %f573, %f573;
	selp.f32	%f574, %f573, %f320, %p78;
	setp.ltu.f32	%p79, %f574, %f42;
	mov.f32 	%f577, %f78;
	@%p79 bra 	BB9_89;

	mov.f32 	%f578, %f78;

BB9_88:
	sub.f32 	%f321, %f578, %f574;
	setp.ltu.f32	%p80, %f578, %f574;
	selp.f32	%f578, %f578, %f321, %p80;
	mul.f32 	%f574, %f574, 0f3F000000;
	setp.ge.f32	%p81, %f574, %f42;
	mov.f32 	%f576, %f578;
	mov.f32 	%f577, %f576;
	@%p81 bra 	BB9_88;

BB9_89:
	mov.f32 	%f90, %f577;
	mov.b32 	 %r375, %f199;
	and.b32  	%r376, %r375, -2147483648;
	mov.b32 	 %r377, %f90;
	or.b32  	%r378, %r377, %r376;
	mov.b32 	 %f581, %r378;

BB9_91:
	setp.eq.s32	%p84, %r234, 0;
	mov.f32 	%f612, 0f44480000;
	@%p84 bra 	BB9_193;

	fma.rn.f32 	%f94, %f558, 0f3E4CCCCD, 0f3F800000;
	mul.f32 	%f327, %f563, 0f3DCCCCCD;
	cvt.f64.f32	%fd1, %f327;
	add.f64 	%fd2, %fd1, 0d3FD3333333333333;
	cvt.rn.f32.f64	%f95, %fd2;
	mov.f32 	%f328, 0f3F800000;
	sub.f32 	%f329, %f328, %f59;
	sub.f32 	%f330, %f328, %f77;
	abs.f32 	%f331, %f581;
	sub.f32 	%f332, %f328, %f331;
	abs.f32 	%f585, %f332;
	abs.f32 	%f586, %f330;
	abs.f32 	%f587, %f329;
	div.rn.f32 	%f99, %f200, 0fC1900000;
	abs.f32 	%f100, %f99;
	setp.lt.f32	%p85, %f42, 0f00800000;
	selp.f32	%f333, 0fC3170000, 0fC2FE0000, %p85;
	mul.f32 	%f334, %f42, 0f4B800000;
	selp.f32	%f335, %f334, %f42, %p85;
	mov.b32 	 %r380, %f335;
	and.b32  	%r381, %r380, 8388607;
	or.b32  	%r382, %r381, 1065353216;
	mov.b32 	 %f336, %r382;
	shr.u32 	%r383, %r380, 23;
	cvt.rn.f32.u32	%f337, %r383;
	add.f32 	%f338, %f333, %f337;
	setp.gt.f32	%p86, %f336, 0f3FB504F3;
	mul.f32 	%f339, %f336, 0f3F000000;
	add.f32 	%f340, %f338, 0f3F800000;
	selp.f32	%f341, %f339, %f336, %p86;
	selp.f32	%f101, %f340, %f338, %p86;
	add.f32 	%f102, %f341, 0fBF800000;
	add.f32 	%f103, %f341, 0f3F800000;
	add.f32 	%f104, %f102, %f102;
	mov.f32 	%f584, 0f447A0000;
	mov.u32 	%r591, 0;
	// inline asm
	rcp.approx.ftz.f32 %f470,%f103;
	// inline asm
	mul.f32 	%f474, %f104, %f470;
	bra.uni 	BB9_93;

BB9_184:
	setp.eq.f32	%p146, %f186, 0f7F800000;
	@%p146 bra 	BB9_189;
	bra.uni 	BB9_185;

BB9_189:
	setp.gt.f32	%p154, %f184, 0f80000000;
	setp.gt.f32	%p155, %f42, 0f3F800000;
	selp.b32	%r566, 2139095040, 0, %p155;
	xor.b32  	%r567, %r566, 2139095040;
	selp.b32	%r568, %r567, %r566, %p154;
	mov.b32 	 %f191, %r568;
	mov.f32 	%f611, %f191;
	bra.uni 	BB9_191;

BB9_185:
	setp.eq.f32	%p147, %f42, 0f7F800000;
	@%p147 bra 	BB9_188;
	bra.uni 	BB9_186;

BB9_188:
	setp.gtu.f32	%p153, %f184, 0f80000000;
	selp.f32	%f190, 0f00000000, 0f7F800000, %p153;
	mov.f32 	%f611, %f190;
	bra.uni 	BB9_191;

BB9_186:
	mul.f32 	%f475, %f474, %f474;
	mov.f32 	%f476, 0f3C4CAF63;
	mov.f32 	%f477, 0f3B18F0FE;
	fma.rn.f32 	%f478, %f477, %f475, %f476;
	mov.f32 	%f479, 0f3DAAAABD;
	fma.rn.f32 	%f480, %f478, %f475, %f479;
	mul.rn.f32 	%f481, %f480, %f475;
	mul.rn.f32 	%f482, %f481, %f474;
	sub.f32 	%f483, %f102, %f474;
	add.f32 	%f484, %f483, %f483;
	neg.f32 	%f485, %f474;
	fma.rn.f32 	%f486, %f485, %f102, %f484;
	mul.rn.f32 	%f487, %f470, %f486;
	add.f32 	%f488, %f474, %f482;
	sub.f32 	%f489, %f474, %f488;
	add.f32 	%f490, %f482, %f489;
	add.f32 	%f491, %f487, %f490;
	add.f32 	%f492, %f488, %f491;
	sub.f32 	%f493, %f488, %f492;
	add.f32 	%f494, %f491, %f493;
	mov.f32 	%f495, 0f3F317200;
	mul.rn.f32 	%f496, %f101, %f495;
	add.f32 	%f497, %f496, %f492;
	sub.f32 	%f498, %f496, %f497;
	add.f32 	%f499, %f492, %f498;
	add.f32 	%f500, %f494, %f499;
	mov.f32 	%f501, 0f35BFBE8E;
	mul.rn.f32 	%f502, %f101, %f501;
	add.f32 	%f503, %f502, %f500;
	add.f32 	%f504, %f497, %f503;
	sub.f32 	%f505, %f497, %f504;
	add.f32 	%f506, %f503, %f505;
	mul.f32 	%f507, %f185, 0f39000000;
	setp.gt.f32	%p148, %f186, 0f77F684DF;
	selp.f32	%f508, %f507, %f185, %p148;
	mul.rn.f32 	%f509, %f508, %f504;
	neg.f32 	%f510, %f509;
	fma.rn.f32 	%f511, %f508, %f504, %f510;
	fma.rn.f32 	%f512, %f508, %f506, %f511;
	mov.f32 	%f513, 0f00000000;
	fma.rn.f32 	%f514, %f513, %f504, %f512;
	add.rn.f32 	%f515, %f509, %f514;
	neg.f32 	%f516, %f515;
	add.rn.f32 	%f517, %f509, %f516;
	add.rn.f32 	%f518, %f517, %f514;
	mov.b32 	 %r564, %f515;
	setp.eq.s32	%p149, %r564, 1118925336;
	add.s32 	%r565, %r564, -1;
	mov.b32 	 %f519, %r565;
	add.f32 	%f520, %f518, 0f37000000;
	selp.f32	%f187, %f520, %f518, %p149;
	selp.f32	%f521, %f519, %f515, %p149;
	mul.f32 	%f522, %f521, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f523, %f522;
	mov.f32 	%f524, 0fBF317200;
	fma.rn.f32 	%f525, %f523, %f524, %f521;
	mov.f32 	%f526, 0fB5BFBE8E;
	fma.rn.f32 	%f527, %f523, %f526, %f525;
	mul.f32 	%f473, %f527, 0f3FB8AA3B;
	// inline asm
	ex2.approx.ftz.f32 %f472,%f473;
	// inline asm
	add.f32 	%f528, %f523, 0f00000000;
	ex2.approx.f32 	%f529, %f528;
	mul.f32 	%f530, %f472, %f529;
	setp.lt.f32	%p150, %f521, 0fC2D20000;
	selp.f32	%f531, 0f00000000, %f530, %p150;
	setp.gt.f32	%p151, %f521, 0f42D20000;
	selp.f32	%f188, 0f7F800000, %f531, %p151;
	setp.eq.f32	%p152, %f188, 0f7F800000;
	mov.f32 	%f611, %f188;
	@%p152 bra 	BB9_191;

	fma.rn.f32 	%f189, %f188, %f187, %f188;
	mov.f32 	%f611, %f189;
	bra.uni 	BB9_191;

BB9_93:
	add.f32 	%f342, %f587, %f586;
	setp.lt.f32	%p87, %f342, 0f00000000;
	neg.f32 	%f343, %f586;
	selp.f32	%f344, %f343, %f587, %p87;
	neg.f32 	%f345, %f587;
	selp.f32	%f346, %f345, %f586, %p87;
	abs.f32 	%f347, %f344;
	abs.f32 	%f348, %f346;
	abs.f32 	%f349, %f585;
	add.f32 	%f350, %f347, %f349;
	setp.lt.f32	%p88, %f350, 0f00000000;
	neg.f32 	%f351, %f349;
	neg.f32 	%f352, %f347;
	selp.f32	%f353, %f351, %f347, %p88;
	selp.f32	%f354, %f352, %f349, %p88;
	abs.f32 	%f355, %f353;
	abs.f32 	%f356, %f348;
	abs.f32 	%f357, %f354;
	sub.f32 	%f358, %f355, %f356;
	setp.lt.f32	%p89, %f358, 0f00000000;
	selp.f32	%f359, %f356, %f355, %p89;
	selp.f32	%f360, %f355, %f356, %p89;
	abs.f32 	%f361, %f359;
	abs.f32 	%f362, %f360;
	abs.f32 	%f363, %f357;
	sub.f32 	%f364, %f361, %f363;
	setp.lt.f32	%p90, %f364, 0f00000000;
	selp.f32	%f365, %f363, %f361, %p90;
	selp.f32	%f366, %f361, %f363, %p90;
	abs.f32 	%f367, %f365;
	abs.f32 	%f368, %f362;
	abs.f32 	%f369, %f366;
	add.f32 	%f370, %f367, %f367;
	add.f32 	%f371, %f369, %f369;
	sub.f32 	%f587, %f370, %f94;
	fma.rn.f32 	%f110, %f368, 0f40000000, 0fBF800000;
	sub.f32 	%f111, %f371, %f95;
	setp.neu.f32	%p91, %f100, 0f7F800000;
	mov.f32 	%f606, %f99;
	@%p91 bra 	BB9_95;

	mov.f32 	%f372, 0f00000000;
	mul.rn.f32 	%f112, %f99, %f372;
	mov.f32 	%f606, %f112;

BB9_95:
	mov.f32 	%f113, %f606;
	mul.f32 	%f373, %f113, 0f3F22F983;
	cvt.rni.s32.f32	%r601, %f373;
	cvt.rn.f32.s32	%f374, %r601;
	neg.f32 	%f375, %f374;
	fma.rn.f32 	%f377, %f375, %f209, %f113;
	fma.rn.f32 	%f379, %f375, %f211, %f377;
	fma.rn.f32 	%f588, %f375, %f213, %f379;
	abs.f32 	%f381, %f113;
	setp.leu.f32	%p92, %f381, 0f47CE4780;
	@%p92 bra 	BB9_105;

	mov.b32 	 %r88, %f113;
	shr.u32 	%r89, %r88, 23;
	bfe.u32 	%r386, %r88, 23, 8;
	add.s32 	%r387, %r386, -128;
	shl.b32 	%r388, %r88, 8;
	or.b32  	%r90, %r388, -2147483648;
	shr.u32 	%r91, %r387, 5;
	mov.u32 	%r593, 0;
	mov.u64 	%rd58, __cudart_i2opi_f;
	mov.u32 	%r592, -6;
	mov.u64 	%rd71, %rd1;

BB9_97:
	.pragma "nounroll";
	mov.u64 	%rd22, %rd71;
	ld.const.u32 	%r391, [%rd58];
	// inline asm
	{
	mad.lo.cc.u32   %r389, %r391, %r90, %r593;
	madc.hi.u32     %r390, %r391, %r90,  0;
	}
	// inline asm
	mov.u32 	%r593, %r390;
	st.local.u32 	[%rd22], %r389;
	add.s64 	%rd23, %rd22, 4;
	add.s64 	%rd58, %rd58, 4;
	add.s32 	%r592, %r592, 1;
	setp.ne.s32	%p93, %r592, 0;
	mov.u64 	%rd71, %rd23;
	@%p93 bra 	BB9_97;

	and.b32  	%r96, %r88, -2147483648;
	st.local.u32 	[%rd1+24], %r390;
	mov.u32 	%r394, 6;
	sub.s32 	%r395, %r394, %r91;
	mul.wide.s32 	%rd48, %r395, 4;
	add.s64 	%rd25, %rd1, %rd48;
	ld.local.u32 	%r594, [%rd25];
	ld.local.u32 	%r595, [%rd25+-4];
	and.b32  	%r99, %r89, 31;
	setp.eq.s32	%p94, %r99, 0;
	@%p94 bra 	BB9_100;

	mov.u32 	%r396, 32;
	sub.s32 	%r397, %r396, %r99;
	shr.u32 	%r398, %r595, %r397;
	shl.b32 	%r399, %r594, %r99;
	add.s32 	%r594, %r398, %r399;
	ld.local.u32 	%r400, [%rd25+-8];
	shr.u32 	%r401, %r400, %r397;
	shl.b32 	%r402, %r595, %r99;
	add.s32 	%r595, %r401, %r402;

BB9_100:
	shr.u32 	%r403, %r595, 30;
	shl.b32 	%r404, %r594, 2;
	add.s32 	%r596, %r403, %r404;
	shl.b32 	%r105, %r595, 2;
	shr.u32 	%r405, %r596, 31;
	shr.u32 	%r406, %r594, 30;
	add.s32 	%r106, %r405, %r406;
	setp.eq.s32	%p95, %r405, 0;
	mov.u32 	%r597, %r96;
	mov.u32 	%r598, %r105;
	@%p95 bra 	BB9_102;

	not.b32 	%r407, %r596;
	neg.s32 	%r107, %r105;
	setp.eq.s32	%p96, %r105, 0;
	selp.u32	%r408, 1, 0, %p96;
	add.s32 	%r596, %r408, %r407;
	xor.b32  	%r109, %r96, -2147483648;
	mov.u32 	%r597, %r109;
	mov.u32 	%r598, %r107;

BB9_102:
	mov.u32 	%r111, %r597;
	neg.s32 	%r409, %r106;
	setp.eq.s32	%p97, %r96, 0;
	selp.b32	%r601, %r106, %r409, %p97;
	clz.b32 	%r600, %r596;
	setp.eq.s32	%p98, %r600, 0;
	shl.b32 	%r410, %r596, %r600;
	mov.u32 	%r411, 32;
	sub.s32 	%r412, %r411, %r600;
	shr.u32 	%r413, %r598, %r412;
	add.s32 	%r414, %r413, %r410;
	selp.b32	%r115, %r596, %r414, %p98;
	mov.u32 	%r415, -921707870;
	mul.hi.u32 	%r599, %r115, %r415;
	setp.lt.s32	%p99, %r599, 1;
	@%p99 bra 	BB9_104;

	mul.lo.s32 	%r416, %r115, -921707870;
	shr.u32 	%r417, %r416, 31;
	shl.b32 	%r418, %r599, 1;
	add.s32 	%r599, %r417, %r418;
	add.s32 	%r600, %r600, 1;

BB9_104:
	mov.u32 	%r419, 126;
	sub.s32 	%r420, %r419, %r600;
	shl.b32 	%r421, %r420, 23;
	add.s32 	%r422, %r599, 1;
	shr.u32 	%r423, %r422, 7;
	add.s32 	%r424, %r423, 1;
	shr.u32 	%r425, %r424, 1;
	add.s32 	%r426, %r425, %r421;
	or.b32  	%r427, %r426, %r111;
	mov.b32 	 %f588, %r427;

BB9_105:
	mul.rn.f32 	%f117, %f588, %f588;
	add.s32 	%r122, %r601, 1;
	and.b32  	%r123, %r122, 1;
	setp.eq.s32	%p100, %r123, 0;
	@%p100 bra 	BB9_107;
	bra.uni 	BB9_106;

BB9_107:
	mov.f32 	%f384, 0f3C08839E;
	mov.f32 	%f385, 0fB94CA1F9;
	fma.rn.f32 	%f589, %f385, %f117, %f384;
	bra.uni 	BB9_108;

BB9_106:
	mov.f32 	%f382, 0fBAB6061A;
	mov.f32 	%f383, 0f37CCF5CE;
	fma.rn.f32 	%f589, %f383, %f117, %f382;

BB9_108:
	@%p100 bra 	BB9_110;
	bra.uni 	BB9_109;

BB9_110:
	mov.f32 	%f389, 0fBE2AAAA3;
	fma.rn.f32 	%f390, %f589, %f117, %f389;
	mov.f32 	%f391, 0f00000000;
	fma.rn.f32 	%f590, %f390, %f117, %f391;
	bra.uni 	BB9_111;

BB9_109:
	mov.f32 	%f386, 0f3D2AAAA5;
	fma.rn.f32 	%f387, %f589, %f117, %f386;
	mov.f32 	%f388, 0fBF000000;
	fma.rn.f32 	%f590, %f387, %f117, %f388;

BB9_111:
	fma.rn.f32 	%f591, %f590, %f588, %f588;
	@%p100 bra 	BB9_113;

	fma.rn.f32 	%f591, %f590, %f117, %f328;

BB9_113:
	and.b32  	%r428, %r122, 2;
	setp.eq.s32	%p103, %r428, 0;
	@%p103 bra 	BB9_115;

	mov.f32 	%f393, 0f00000000;
	mov.f32 	%f394, 0fBF800000;
	fma.rn.f32 	%f591, %f591, %f394, %f393;

BB9_115:
	mov.f32 	%f605, %f99;
	@%p91 bra 	BB9_117;

	mov.f32 	%f395, 0f00000000;
	mul.rn.f32 	%f605, %f99, %f395;

BB9_117:
	mul.f32 	%f396, %f605, 0f3F22F983;
	cvt.rni.s32.f32	%r611, %f396;
	cvt.rn.f32.s32	%f397, %r611;
	neg.f32 	%f398, %f397;
	fma.rn.f32 	%f400, %f398, %f209, %f605;
	fma.rn.f32 	%f402, %f398, %f211, %f400;
	fma.rn.f32 	%f592, %f398, %f213, %f402;
	abs.f32 	%f404, %f605;
	setp.leu.f32	%p105, %f404, 0f47CE4780;
	@%p105 bra 	BB9_127;

	mov.b32 	 %r125, %f605;
	shr.u32 	%r126, %r125, 23;
	bfe.u32 	%r431, %r125, 23, 8;
	add.s32 	%r432, %r431, -128;
	shl.b32 	%r433, %r125, 8;
	or.b32  	%r127, %r433, -2147483648;
	shr.u32 	%r128, %r432, 5;
	mov.u32 	%r603, 0;
	mov.u64 	%rd59, __cudart_i2opi_f;
	mov.u32 	%r602, -6;
	mov.u64 	%rd70, %rd1;

BB9_119:
	.pragma "nounroll";
	ld.const.u32 	%r436, [%rd59];
	// inline asm
	{
	mad.lo.cc.u32   %r434, %r436, %r127, %r603;
	madc.hi.u32     %r435, %r436, %r127,  0;
	}
	// inline asm
	mov.u32 	%r603, %r435;
	st.local.u32 	[%rd70], %r434;
	add.s64 	%rd70, %rd70, 4;
	add.s64 	%rd59, %rd59, 4;
	add.s32 	%r602, %r602, 1;
	setp.ne.s32	%p106, %r602, 0;
	@%p106 bra 	BB9_119;

	and.b32  	%r133, %r125, -2147483648;
	st.local.u32 	[%rd1+24], %r435;
	mov.u32 	%r439, 6;
	sub.s32 	%r440, %r439, %r128;
	mul.wide.s32 	%rd50, %r440, 4;
	add.s64 	%rd30, %rd1, %rd50;
	ld.local.u32 	%r604, [%rd30];
	ld.local.u32 	%r605, [%rd30+-4];
	and.b32  	%r136, %r126, 31;
	setp.eq.s32	%p107, %r136, 0;
	@%p107 bra 	BB9_122;

	mov.u32 	%r441, 32;
	sub.s32 	%r442, %r441, %r136;
	shr.u32 	%r443, %r605, %r442;
	shl.b32 	%r444, %r604, %r136;
	add.s32 	%r604, %r443, %r444;
	ld.local.u32 	%r445, [%rd30+-8];
	shr.u32 	%r446, %r445, %r442;
	shl.b32 	%r447, %r605, %r136;
	add.s32 	%r605, %r446, %r447;

BB9_122:
	shr.u32 	%r448, %r605, 30;
	shl.b32 	%r449, %r604, 2;
	add.s32 	%r606, %r448, %r449;
	shl.b32 	%r142, %r605, 2;
	shr.u32 	%r450, %r606, 31;
	shr.u32 	%r451, %r604, 30;
	add.s32 	%r143, %r450, %r451;
	setp.eq.s32	%p108, %r450, 0;
	mov.u32 	%r607, %r133;
	mov.u32 	%r608, %r142;
	@%p108 bra 	BB9_124;

	not.b32 	%r452, %r606;
	neg.s32 	%r144, %r142;
	setp.eq.s32	%p109, %r142, 0;
	selp.u32	%r453, 1, 0, %p109;
	add.s32 	%r606, %r453, %r452;
	xor.b32  	%r146, %r133, -2147483648;
	mov.u32 	%r607, %r146;
	mov.u32 	%r608, %r144;

BB9_124:
	mov.u32 	%r148, %r607;
	neg.s32 	%r454, %r143;
	setp.eq.s32	%p110, %r133, 0;
	selp.b32	%r611, %r143, %r454, %p110;
	clz.b32 	%r610, %r606;
	setp.eq.s32	%p111, %r610, 0;
	shl.b32 	%r455, %r606, %r610;
	mov.u32 	%r456, 32;
	sub.s32 	%r457, %r456, %r610;
	shr.u32 	%r458, %r608, %r457;
	add.s32 	%r459, %r458, %r455;
	selp.b32	%r152, %r606, %r459, %p111;
	mov.u32 	%r460, -921707870;
	mul.hi.u32 	%r609, %r152, %r460;
	setp.lt.s32	%p112, %r609, 1;
	@%p112 bra 	BB9_126;

	mul.lo.s32 	%r461, %r152, -921707870;
	shr.u32 	%r462, %r461, 31;
	shl.b32 	%r463, %r609, 1;
	add.s32 	%r609, %r462, %r463;
	add.s32 	%r610, %r610, 1;

BB9_126:
	mov.u32 	%r464, 126;
	sub.s32 	%r465, %r464, %r610;
	shl.b32 	%r466, %r465, 23;
	add.s32 	%r467, %r609, 1;
	shr.u32 	%r468, %r467, 7;
	add.s32 	%r469, %r468, 1;
	shr.u32 	%r470, %r469, 1;
	add.s32 	%r471, %r470, %r466;
	or.b32  	%r472, %r471, %r148;
	mov.b32 	 %f592, %r472;

BB9_127:
	mul.rn.f32 	%f134, %f592, %f592;
	and.b32  	%r159, %r611, 1;
	setp.eq.s32	%p113, %r159, 0;
	@%p113 bra 	BB9_129;
	bra.uni 	BB9_128;

BB9_129:
	mov.f32 	%f407, 0f3C08839E;
	mov.f32 	%f408, 0fB94CA1F9;
	fma.rn.f32 	%f593, %f408, %f134, %f407;
	bra.uni 	BB9_130;

BB9_128:
	mov.f32 	%f405, 0fBAB6061A;
	mov.f32 	%f406, 0f37CCF5CE;
	fma.rn.f32 	%f593, %f406, %f134, %f405;

BB9_130:
	@%p113 bra 	BB9_132;
	bra.uni 	BB9_131;

BB9_132:
	mov.f32 	%f412, 0fBE2AAAA3;
	fma.rn.f32 	%f413, %f593, %f134, %f412;
	mov.f32 	%f414, 0f00000000;
	fma.rn.f32 	%f594, %f413, %f134, %f414;
	bra.uni 	BB9_133;

BB9_131:
	mov.f32 	%f409, 0f3D2AAAA5;
	fma.rn.f32 	%f410, %f593, %f134, %f409;
	mov.f32 	%f411, 0fBF000000;
	fma.rn.f32 	%f594, %f410, %f134, %f411;

BB9_133:
	fma.rn.f32 	%f595, %f594, %f592, %f592;
	@%p113 bra 	BB9_135;

	fma.rn.f32 	%f595, %f594, %f134, %f328;

BB9_135:
	and.b32  	%r473, %r611, 2;
	setp.eq.s32	%p116, %r473, 0;
	@%p116 bra 	BB9_137;

	mov.f32 	%f416, 0f00000000;
	mov.f32 	%f417, 0fBF800000;
	fma.rn.f32 	%f595, %f595, %f417, %f416;

BB9_137:
	mul.f32 	%f418, %f111, %f595;
	fma.rn.f32 	%f586, %f110, %f591, %f418;
	mov.f32 	%f604, %f99;
	@%p91 bra 	BB9_139;

	mov.f32 	%f419, 0f00000000;
	mul.rn.f32 	%f604, %f99, %f419;

BB9_139:
	mul.f32 	%f420, %f604, 0f3F22F983;
	cvt.rni.s32.f32	%r621, %f420;
	cvt.rn.f32.s32	%f421, %r621;
	neg.f32 	%f422, %f421;
	fma.rn.f32 	%f424, %f422, %f209, %f604;
	fma.rn.f32 	%f426, %f422, %f211, %f424;
	fma.rn.f32 	%f596, %f422, %f213, %f426;
	abs.f32 	%f428, %f604;
	setp.leu.f32	%p118, %f428, 0f47CE4780;
	@%p118 bra 	BB9_149;

	mov.b32 	 %r161, %f604;
	shr.u32 	%r162, %r161, 23;
	bfe.u32 	%r476, %r161, 23, 8;
	add.s32 	%r477, %r476, -128;
	shl.b32 	%r478, %r161, 8;
	or.b32  	%r163, %r478, -2147483648;
	shr.u32 	%r164, %r477, 5;
	mov.u32 	%r613, 0;
	mov.u64 	%rd60, __cudart_i2opi_f;
	mov.u32 	%r612, -6;
	mov.u64 	%rd69, %rd1;

BB9_141:
	.pragma "nounroll";
	ld.const.u32 	%r481, [%rd60];
	// inline asm
	{
	mad.lo.cc.u32   %r479, %r481, %r163, %r613;
	madc.hi.u32     %r480, %r481, %r163,  0;
	}
	// inline asm
	mov.u32 	%r613, %r480;
	st.local.u32 	[%rd69], %r479;
	add.s64 	%rd69, %rd69, 4;
	add.s64 	%rd60, %rd60, 4;
	add.s32 	%r612, %r612, 1;
	setp.ne.s32	%p119, %r612, 0;
	@%p119 bra 	BB9_141;

	and.b32  	%r169, %r161, -2147483648;
	st.local.u32 	[%rd1+24], %r480;
	mov.u32 	%r484, 6;
	sub.s32 	%r485, %r484, %r164;
	mul.wide.s32 	%rd52, %r485, 4;
	add.s64 	%rd35, %rd1, %rd52;
	ld.local.u32 	%r614, [%rd35];
	ld.local.u32 	%r615, [%rd35+-4];
	and.b32  	%r172, %r162, 31;
	setp.eq.s32	%p120, %r172, 0;
	@%p120 bra 	BB9_144;

	mov.u32 	%r486, 32;
	sub.s32 	%r487, %r486, %r172;
	shr.u32 	%r488, %r615, %r487;
	shl.b32 	%r489, %r614, %r172;
	add.s32 	%r614, %r488, %r489;
	ld.local.u32 	%r490, [%rd35+-8];
	shr.u32 	%r491, %r490, %r487;
	shl.b32 	%r492, %r615, %r172;
	add.s32 	%r615, %r491, %r492;

BB9_144:
	shr.u32 	%r493, %r615, 30;
	shl.b32 	%r494, %r614, 2;
	add.s32 	%r616, %r493, %r494;
	shl.b32 	%r178, %r615, 2;
	shr.u32 	%r495, %r616, 31;
	shr.u32 	%r496, %r614, 30;
	add.s32 	%r179, %r495, %r496;
	setp.eq.s32	%p121, %r495, 0;
	mov.u32 	%r617, %r169;
	mov.u32 	%r618, %r178;
	@%p121 bra 	BB9_146;

	not.b32 	%r497, %r616;
	neg.s32 	%r180, %r178;
	setp.eq.s32	%p122, %r178, 0;
	selp.u32	%r498, 1, 0, %p122;
	add.s32 	%r616, %r498, %r497;
	xor.b32  	%r182, %r169, -2147483648;
	mov.u32 	%r617, %r182;
	mov.u32 	%r618, %r180;

BB9_146:
	mov.u32 	%r184, %r617;
	neg.s32 	%r499, %r179;
	setp.eq.s32	%p123, %r169, 0;
	selp.b32	%r621, %r179, %r499, %p123;
	clz.b32 	%r620, %r616;
	setp.eq.s32	%p124, %r620, 0;
	shl.b32 	%r500, %r616, %r620;
	mov.u32 	%r501, 32;
	sub.s32 	%r502, %r501, %r620;
	shr.u32 	%r503, %r618, %r502;
	add.s32 	%r504, %r503, %r500;
	selp.b32	%r188, %r616, %r504, %p124;
	mov.u32 	%r505, -921707870;
	mul.hi.u32 	%r619, %r188, %r505;
	setp.lt.s32	%p125, %r619, 1;
	@%p125 bra 	BB9_148;

	mul.lo.s32 	%r506, %r188, -921707870;
	shr.u32 	%r507, %r506, 31;
	shl.b32 	%r508, %r619, 1;
	add.s32 	%r619, %r507, %r508;
	add.s32 	%r620, %r620, 1;

BB9_148:
	mov.u32 	%r509, 126;
	sub.s32 	%r510, %r509, %r620;
	shl.b32 	%r511, %r510, 23;
	add.s32 	%r512, %r619, 1;
	shr.u32 	%r513, %r512, 7;
	add.s32 	%r514, %r513, 1;
	shr.u32 	%r515, %r514, 1;
	add.s32 	%r516, %r515, %r511;
	or.b32  	%r517, %r516, %r184;
	mov.b32 	 %f596, %r517;

BB9_149:
	mul.rn.f32 	%f152, %f596, %f596;
	and.b32  	%r195, %r621, 1;
	setp.eq.s32	%p126, %r195, 0;
	@%p126 bra 	BB9_151;
	bra.uni 	BB9_150;

BB9_151:
	mov.f32 	%f431, 0f3C08839E;
	mov.f32 	%f432, 0fB94CA1F9;
	fma.rn.f32 	%f597, %f432, %f152, %f431;
	bra.uni 	BB9_152;

BB9_150:
	mov.f32 	%f429, 0fBAB6061A;
	mov.f32 	%f430, 0f37CCF5CE;
	fma.rn.f32 	%f597, %f430, %f152, %f429;

BB9_152:
	@%p126 bra 	BB9_154;
	bra.uni 	BB9_153;

BB9_154:
	mov.f32 	%f436, 0fBE2AAAA3;
	fma.rn.f32 	%f437, %f597, %f152, %f436;
	mov.f32 	%f438, 0f00000000;
	fma.rn.f32 	%f598, %f437, %f152, %f438;
	bra.uni 	BB9_155;

BB9_153:
	mov.f32 	%f433, 0f3D2AAAA5;
	fma.rn.f32 	%f434, %f597, %f152, %f433;
	mov.f32 	%f435, 0fBF000000;
	fma.rn.f32 	%f598, %f434, %f152, %f435;

BB9_155:
	fma.rn.f32 	%f599, %f598, %f596, %f596;
	@%p126 bra 	BB9_157;

	fma.rn.f32 	%f599, %f598, %f152, %f328;

BB9_157:
	and.b32  	%r518, %r621, 2;
	setp.eq.s32	%p129, %r518, 0;
	@%p129 bra 	BB9_159;

	mov.f32 	%f440, 0f00000000;
	mov.f32 	%f441, 0fBF800000;
	fma.rn.f32 	%f599, %f599, %f441, %f440;

BB9_159:
	mul.f32 	%f164, %f110, %f599;
	mov.f32 	%f603, %f99;
	@%p91 bra 	BB9_161;

	mov.f32 	%f442, 0f00000000;
	mul.rn.f32 	%f603, %f99, %f442;

BB9_161:
	mul.f32 	%f443, %f603, 0f3F22F983;
	cvt.rni.s32.f32	%r631, %f443;
	cvt.rn.f32.s32	%f444, %r631;
	neg.f32 	%f445, %f444;
	fma.rn.f32 	%f447, %f445, %f209, %f603;
	fma.rn.f32 	%f449, %f445, %f211, %f447;
	fma.rn.f32 	%f607, %f445, %f213, %f449;
	abs.f32 	%f451, %f603;
	setp.leu.f32	%p131, %f451, 0f47CE4780;
	@%p131 bra 	BB9_171;

	mov.b32 	 %r197, %f603;
	shr.u32 	%r198, %r197, 23;
	bfe.u32 	%r521, %r197, 23, 8;
	add.s32 	%r522, %r521, -128;
	shl.b32 	%r523, %r197, 8;
	or.b32  	%r199, %r523, -2147483648;
	shr.u32 	%r200, %r522, 5;
	mov.u32 	%r623, 0;
	mov.u64 	%rd61, __cudart_i2opi_f;
	mov.u32 	%r622, -6;
	mov.u64 	%rd68, %rd1;

BB9_163:
	.pragma "nounroll";
	ld.const.u32 	%r526, [%rd61];
	// inline asm
	{
	mad.lo.cc.u32   %r524, %r526, %r199, %r623;
	madc.hi.u32     %r525, %r526, %r199,  0;
	}
	// inline asm
	mov.u32 	%r623, %r525;
	st.local.u32 	[%rd68], %r524;
	add.s64 	%rd68, %rd68, 4;
	add.s64 	%rd61, %rd61, 4;
	add.s32 	%r622, %r622, 1;
	setp.ne.s32	%p132, %r622, 0;
	@%p132 bra 	BB9_163;

	and.b32  	%r205, %r197, -2147483648;
	st.local.u32 	[%rd1+24], %r525;
	mov.u32 	%r529, 6;
	sub.s32 	%r530, %r529, %r200;
	mul.wide.s32 	%rd54, %r530, 4;
	add.s64 	%rd40, %rd1, %rd54;
	ld.local.u32 	%r624, [%rd40];
	ld.local.u32 	%r625, [%rd40+-4];
	and.b32  	%r208, %r198, 31;
	setp.eq.s32	%p133, %r208, 0;
	@%p133 bra 	BB9_166;

	mov.u32 	%r531, 32;
	sub.s32 	%r532, %r531, %r208;
	shr.u32 	%r533, %r625, %r532;
	shl.b32 	%r534, %r624, %r208;
	add.s32 	%r624, %r533, %r534;
	ld.local.u32 	%r535, [%rd40+-8];
	shr.u32 	%r536, %r535, %r532;
	shl.b32 	%r537, %r625, %r208;
	add.s32 	%r625, %r536, %r537;

BB9_166:
	shr.u32 	%r538, %r625, 30;
	shl.b32 	%r539, %r624, 2;
	add.s32 	%r626, %r538, %r539;
	shl.b32 	%r214, %r625, 2;
	shr.u32 	%r540, %r626, 31;
	shr.u32 	%r541, %r624, 30;
	add.s32 	%r215, %r540, %r541;
	setp.eq.s32	%p134, %r540, 0;
	mov.u32 	%r627, %r205;
	mov.u32 	%r628, %r214;
	@%p134 bra 	BB9_168;

	not.b32 	%r542, %r626;
	neg.s32 	%r216, %r214;
	setp.eq.s32	%p135, %r214, 0;
	selp.u32	%r543, 1, 0, %p135;
	add.s32 	%r626, %r543, %r542;
	xor.b32  	%r218, %r205, -2147483648;
	mov.u32 	%r627, %r218;
	mov.u32 	%r628, %r216;

BB9_168:
	mov.u32 	%r220, %r627;
	neg.s32 	%r544, %r215;
	setp.eq.s32	%p136, %r205, 0;
	selp.b32	%r631, %r215, %r544, %p136;
	clz.b32 	%r630, %r626;
	setp.eq.s32	%p137, %r630, 0;
	shl.b32 	%r545, %r626, %r630;
	mov.u32 	%r546, 32;
	sub.s32 	%r547, %r546, %r630;
	shr.u32 	%r548, %r628, %r547;
	add.s32 	%r549, %r548, %r545;
	selp.b32	%r224, %r626, %r549, %p137;
	mov.u32 	%r550, -921707870;
	mul.hi.u32 	%r629, %r224, %r550;
	setp.lt.s32	%p138, %r629, 1;
	@%p138 bra 	BB9_170;

	mul.lo.s32 	%r551, %r224, -921707870;
	shr.u32 	%r552, %r551, 31;
	shl.b32 	%r553, %r629, 1;
	add.s32 	%r629, %r552, %r553;
	add.s32 	%r630, %r630, 1;

BB9_170:
	mov.u32 	%r554, 126;
	sub.s32 	%r555, %r554, %r630;
	shl.b32 	%r556, %r555, 23;
	add.s32 	%r557, %r629, 1;
	shr.u32 	%r558, %r557, 7;
	add.s32 	%r559, %r558, 1;
	shr.u32 	%r560, %r559, 1;
	add.s32 	%r561, %r560, %r556;
	or.b32  	%r562, %r561, %r220;
	mov.b32 	 %f607, %r562;

BB9_171:
	mul.rn.f32 	%f170, %f607, %f607;
	add.s32 	%r231, %r631, 1;
	and.b32  	%r232, %r231, 1;
	setp.eq.s32	%p139, %r232, 0;
	@%p139 bra 	BB9_173;
	bra.uni 	BB9_172;

BB9_173:
	mov.f32 	%f454, 0f3C08839E;
	mov.f32 	%f455, 0fB94CA1F9;
	fma.rn.f32 	%f608, %f455, %f170, %f454;
	bra.uni 	BB9_174;

BB9_172:
	mov.f32 	%f452, 0fBAB6061A;
	mov.f32 	%f453, 0f37CCF5CE;
	fma.rn.f32 	%f608, %f453, %f170, %f452;

BB9_174:
	@%p139 bra 	BB9_176;
	bra.uni 	BB9_175;

BB9_176:
	mov.f32 	%f459, 0fBE2AAAA3;
	fma.rn.f32 	%f460, %f608, %f170, %f459;
	mov.f32 	%f461, 0f00000000;
	fma.rn.f32 	%f609, %f460, %f170, %f461;
	bra.uni 	BB9_177;

BB9_175:
	mov.f32 	%f456, 0f3D2AAAA5;
	fma.rn.f32 	%f457, %f608, %f170, %f456;
	mov.f32 	%f458, 0fBF000000;
	fma.rn.f32 	%f609, %f457, %f170, %f458;

BB9_177:
	fma.rn.f32 	%f610, %f609, %f607, %f607;
	@%p139 bra 	BB9_179;

	fma.rn.f32 	%f610, %f609, %f170, %f328;

BB9_179:
	and.b32  	%r563, %r231, 2;
	setp.eq.s32	%p142, %r563, 0;
	@%p142 bra 	BB9_181;

	mov.f32 	%f463, 0f00000000;
	mov.f32 	%f464, 0fBF800000;
	fma.rn.f32 	%f610, %f610, %f464, %f463;

BB9_181:
	mul.f32 	%f466, %f111, %f610;
	sub.f32 	%f585, %f466, %f164;
	mul.f32 	%f467, %f586, %f586;
	fma.rn.f32 	%f468, %f587, %f587, %f467;
	fma.rn.f32 	%f469, %f585, %f585, %f468;
	sqrt.rn.f32 	%f183, %f469;
	add.s32 	%r591, %r591, 1;
	cvt.rn.f32.s32	%f184, %r591;
	neg.f32 	%f185, %f184;
	setp.eq.f32	%p143, %f184, 0f80000000;
	mov.f32 	%f611, %f328;
	@%p143 bra 	BB9_191;

	setp.gtu.f32	%p144, %f42, 0f7F800000;
	@%p144 bra 	BB9_190;

	abs.f32 	%f186, %f185;
	setp.gtu.f32	%p145, %f186, 0f7F800000;
	@%p145 bra 	BB9_190;
	bra.uni 	BB9_184;

BB9_190:
	sub.f32 	%f192, %f253, %f184;
	mov.f32 	%f611, %f192;

BB9_191:
	mov.f32 	%f193, %f611;
	mul.f32 	%f533, %f183, %f193;
	min.f32 	%f584, %f584, %f533;
	setp.lt.u32	%p156, %r591, %r234;
	@%p156 bra 	BB9_93;

	mul.f32 	%f612, %f584, 0f3F4CCCCD;

BB9_193:
	ld.param.f32 	%f552, [_Z3hit6float3jf_param_0+4];
	add.f32 	%f534, %f552, 0f3F800000;
	abs.f32 	%f535, %f534;
	add.f32 	%f536, %f535, 0fC0000000;
	add.f32 	%f537, %f78, 0fC0000000;
	max.f32 	%f538, %f536, %f537;
	add.f32 	%f539, %f41, 0fC0000000;
	max.f32 	%f540, %f539, %f538;
	mov.f32 	%f541, 0f00000000;
	min.f32 	%f542, %f540, %f541;
	max.f32 	%f543, %f539, %f541;
	max.f32 	%f544, %f536, %f541;
	max.f32 	%f545, %f537, %f541;
	mul.f32 	%f546, %f544, %f544;
	fma.rn.f32 	%f547, %f543, %f543, %f546;
	fma.rn.f32 	%f548, %f545, %f545, %f547;
	sqrt.rn.f32 	%f549, %f548;
	add.f32 	%f550, %f542, %f549;
	max.f32 	%f551, %f612, %f550;
	st.param.f32	[func_retval0+0], %f551;
	ret;
}

	// .globl	_ZN17DistanceEstimatorC1Ej
.visible .func _ZN17DistanceEstimatorC1Ej(
	.param .b64 _ZN17DistanceEstimatorC1Ej_param_0,
	.param .b32 _ZN17DistanceEstimatorC1Ej_param_1
)
{
	.reg .f32 	%f<2>;
	.reg .s32 	%r<4>;
	.reg .s64 	%rd<5>;


	ld.param.u64 	%rd1, [_ZN17DistanceEstimatorC1Ej_param_0];
	ld.param.u32 	%r1, [_ZN17DistanceEstimatorC1Ej_param_1];
	mov.u64 	%rd2, _ZTV17DistanceEstimator;
	add.s64 	%rd3, %rd2, 16;
	cvta.global.u64 	%rd4, %rd3;
	st.u64 	[%rd1], %rd4;
	st.u32 	[%rd1+8], %r1;
	mov.u32 	%r2, 0;
	st.u32 	[%rd1+12], %r2;
	mov.f32 	%f1, 0f3F800000;
	st.v2.f32 	[%rd1+16], {%f1, %f1};
	mov.u32 	%r3, 1065353216;
	st.u32 	[%rd1+24], %r3;
	st.u32 	[%rd1+28], %r3;
	st.u32 	[%rd1+32], %r3;
	st.u32 	[%rd1+36], %r3;
	st.u32 	[%rd1+52], %r2;
	st.u32 	[%rd1+60], %r2;
	st.u32 	[%rd1+56], %r2;
	st.u32 	[%rd1+64], %r2;
	st.u32 	[%rd1+68], %r2;
	st.u32 	[%rd1+72], %r2;
	st.u32 	[%rd1+40], %r3;
	st.u32 	[%rd1+44], %r3;
	st.u32 	[%rd1+48], %r3;
	st.u32 	[%rd1+88], %r2;
	st.u32 	[%rd1+96], %r2;
	st.u32 	[%rd1+92], %r2;
	st.u32 	[%rd1+100], %r2;
	st.u32 	[%rd1+104], %r2;
	st.u32 	[%rd1+108], %r2;
	st.u32 	[%rd1+76], %r2;
	st.u32 	[%rd1+80], %r2;
	st.u32 	[%rd1+84], %r2;
	st.u32 	[%rd1+120], %r2;
	st.u32 	[%rd1+116], %r2;
	st.u32 	[%rd1+112], %r2;
	ret;
}

	// .globl	_ZN10TunnelTest3mapE6float3
.visible .func  (.param .b32 func_retval0) _ZN10TunnelTest3mapE6float3(
	.param .b64 _ZN10TunnelTest3mapE6float3_param_0,
	.param .align 4 .b8 _ZN10TunnelTest3mapE6float3_param_1[12]
)
{
	.local .align 4 .b8 	__local_depot11[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<171>;
	.reg .f32 	%f<605>;
	.reg .s32 	%r<641>;
	.reg .f64 	%fd<3>;
	.reg .s64 	%rd<78>;


	mov.u64 	%rd77, __local_depot11;
	cvta.local.u64 	%SP, %rd77;
	ld.param.u64 	%rd42, [_ZN10TunnelTest3mapE6float3_param_0];
	ld.param.f32 	%f201, [_ZN10TunnelTest3mapE6float3_param_1+8];
	ld.param.f32 	%f200, [_ZN10TunnelTest3mapE6float3_param_1+4];
	ld.param.f32 	%f199, [_ZN10TunnelTest3mapE6float3_param_1];
	add.u64 	%rd43, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd43;
	add.s64 	%rd2, %rd42, 12;
	ld.f32 	%f1, [%rd42+12];
	div.rn.f32 	%f551, %f1, 0f41900000;
	abs.f32 	%f202, %f551;
	setp.neu.f32	%p1, %f202, 0f7F800000;
	@%p1 bra 	BB11_2;

	mov.f32 	%f203, 0f00000000;
	mul.rn.f32 	%f551, %f551, %f203;

BB11_2:
	abs.f32 	%f204, %f551;
	add.s64 	%rd3, %rd1, 24;
	setp.leu.f32	%p2, %f204, 0f47CE4780;
	@%p2 bra 	BB11_6;

	mov.b32 	 %r237, %f551;
	shl.b32 	%r238, %r237, 8;
	or.b32  	%r1, %r238, -2147483648;
	mov.u32 	%r579, 0;
	mov.u64 	%rd57, __cudart_i2opi_f;
	mov.u32 	%r578, -6;
	mov.u64 	%rd76, %rd1;

BB11_4:
	.pragma "nounroll";
	ld.const.u32 	%r241, [%rd57];
	// inline asm
	{
	mad.lo.cc.u32   %r239, %r241, %r1, %r579;
	madc.hi.u32     %r240, %r241, %r1,  0;
	}
	// inline asm
	mov.u32 	%r579, %r240;
	st.local.u32 	[%rd76], %r239;
	add.s64 	%rd76, %rd76, 4;
	add.s64 	%rd57, %rd57, 4;
	add.s32 	%r578, %r578, 1;
	setp.ne.s32	%p3, %r578, 0;
	@%p3 bra 	BB11_4;

	st.local.u32 	[%rd3], %r240;

BB11_6:
	div.rn.f32 	%f552, %f1, 0f40B66666;
	abs.f32 	%f205, %f552;
	setp.neu.f32	%p4, %f205, 0f7F800000;
	@%p4 bra 	BB11_8;

	mov.f32 	%f206, 0f00000000;
	mul.rn.f32 	%f552, %f552, %f206;

BB11_8:
	mul.f32 	%f207, %f552, 0f3F22F983;
	cvt.rni.s32.f32	%r589, %f207;
	cvt.rn.f32.s32	%f208, %r589;
	neg.f32 	%f209, %f208;
	mov.f32 	%f210, 0f3FC90FDA;
	fma.rn.f32 	%f211, %f209, %f210, %f552;
	mov.f32 	%f212, 0f33A22168;
	fma.rn.f32 	%f213, %f209, %f212, %f211;
	mov.f32 	%f214, 0f27C234C5;
	fma.rn.f32 	%f553, %f209, %f214, %f213;
	abs.f32 	%f215, %f552;
	setp.leu.f32	%p5, %f215, 0f47CE4780;
	@%p5 bra 	BB11_18;

	mov.b32 	 %r7, %f552;
	shr.u32 	%r8, %r7, 23;
	bfe.u32 	%r246, %r7, 23, 8;
	add.s32 	%r247, %r246, -128;
	shl.b32 	%r248, %r7, 8;
	or.b32  	%r9, %r248, -2147483648;
	shr.u32 	%r10, %r247, 5;
	mov.u32 	%r581, 0;
	mov.u64 	%rd58, __cudart_i2opi_f;
	mov.u32 	%r580, -6;
	mov.u64 	%rd75, %rd1;

BB11_10:
	.pragma "nounroll";
	ld.const.u32 	%r251, [%rd58];
	// inline asm
	{
	mad.lo.cc.u32   %r249, %r251, %r9, %r581;
	madc.hi.u32     %r250, %r251, %r9,  0;
	}
	// inline asm
	mov.u32 	%r581, %r250;
	st.local.u32 	[%rd75], %r249;
	add.s64 	%rd75, %rd75, 4;
	add.s64 	%rd58, %rd58, 4;
	add.s32 	%r580, %r580, 1;
	setp.ne.s32	%p6, %r580, 0;
	@%p6 bra 	BB11_10;

	and.b32  	%r15, %r7, -2147483648;
	st.local.u32 	[%rd3], %r250;
	mov.u32 	%r254, 6;
	sub.s32 	%r255, %r254, %r10;
	mul.wide.s32 	%rd46, %r255, 4;
	add.s64 	%rd14, %rd1, %rd46;
	ld.local.u32 	%r582, [%rd14];
	ld.local.u32 	%r583, [%rd14+-4];
	and.b32  	%r18, %r8, 31;
	setp.eq.s32	%p7, %r18, 0;
	@%p7 bra 	BB11_13;

	mov.u32 	%r256, 32;
	sub.s32 	%r257, %r256, %r18;
	shr.u32 	%r258, %r583, %r257;
	shl.b32 	%r259, %r582, %r18;
	add.s32 	%r582, %r258, %r259;
	ld.local.u32 	%r260, [%rd14+-8];
	shr.u32 	%r261, %r260, %r257;
	shl.b32 	%r262, %r583, %r18;
	add.s32 	%r583, %r261, %r262;

BB11_13:
	shr.u32 	%r263, %r583, 30;
	shl.b32 	%r264, %r582, 2;
	add.s32 	%r584, %r263, %r264;
	shl.b32 	%r24, %r583, 2;
	shr.u32 	%r265, %r584, 31;
	shr.u32 	%r266, %r582, 30;
	add.s32 	%r25, %r265, %r266;
	setp.eq.s32	%p8, %r265, 0;
	mov.u32 	%r585, %r15;
	mov.u32 	%r586, %r24;
	@%p8 bra 	BB11_15;

	not.b32 	%r267, %r584;
	neg.s32 	%r26, %r24;
	setp.eq.s32	%p9, %r24, 0;
	selp.u32	%r268, 1, 0, %p9;
	add.s32 	%r584, %r268, %r267;
	xor.b32  	%r28, %r15, -2147483648;
	mov.u32 	%r585, %r28;
	mov.u32 	%r586, %r26;

BB11_15:
	mov.u32 	%r30, %r585;
	neg.s32 	%r269, %r25;
	setp.eq.s32	%p10, %r15, 0;
	selp.b32	%r589, %r25, %r269, %p10;
	clz.b32 	%r588, %r584;
	setp.eq.s32	%p11, %r588, 0;
	shl.b32 	%r270, %r584, %r588;
	mov.u32 	%r271, 32;
	sub.s32 	%r272, %r271, %r588;
	shr.u32 	%r273, %r586, %r272;
	add.s32 	%r274, %r273, %r270;
	selp.b32	%r34, %r584, %r274, %p11;
	mov.u32 	%r275, -921707870;
	mul.hi.u32 	%r587, %r34, %r275;
	setp.lt.s32	%p12, %r587, 1;
	@%p12 bra 	BB11_17;

	mul.lo.s32 	%r276, %r34, -921707870;
	shr.u32 	%r277, %r276, 31;
	shl.b32 	%r278, %r587, 1;
	add.s32 	%r587, %r277, %r278;
	add.s32 	%r588, %r588, 1;

BB11_17:
	mov.u32 	%r279, 126;
	sub.s32 	%r280, %r279, %r588;
	shl.b32 	%r281, %r280, 23;
	add.s32 	%r282, %r587, 1;
	shr.u32 	%r283, %r282, 7;
	add.s32 	%r284, %r283, 1;
	shr.u32 	%r285, %r284, 1;
	add.s32 	%r286, %r285, %r281;
	or.b32  	%r287, %r286, %r30;
	mov.b32 	 %f553, %r287;

BB11_18:
	mul.rn.f32 	%f11, %f553, %f553;
	add.s32 	%r41, %r589, 1;
	and.b32  	%r42, %r41, 1;
	setp.eq.s32	%p13, %r42, 0;
	@%p13 bra 	BB11_20;

	mov.f32 	%f216, 0fBAB6061A;
	mov.f32 	%f217, 0f37CCF5CE;
	fma.rn.f32 	%f554, %f217, %f11, %f216;
	bra.uni 	BB11_21;

BB11_20:
	mov.f32 	%f218, 0f3C08839E;
	mov.f32 	%f219, 0fB94CA1F9;
	fma.rn.f32 	%f554, %f219, %f11, %f218;

BB11_21:
	@%p13 bra 	BB11_23;

	mov.f32 	%f220, 0f3D2AAAA5;
	fma.rn.f32 	%f221, %f554, %f11, %f220;
	mov.f32 	%f222, 0fBF000000;
	fma.rn.f32 	%f555, %f221, %f11, %f222;
	bra.uni 	BB11_24;

BB11_23:
	mov.f32 	%f223, 0fBE2AAAA3;
	fma.rn.f32 	%f224, %f554, %f11, %f223;
	mov.f32 	%f225, 0f00000000;
	fma.rn.f32 	%f555, %f224, %f11, %f225;

BB11_24:
	fma.rn.f32 	%f556, %f555, %f553, %f553;
	@%p13 bra 	BB11_26;

	mov.f32 	%f226, 0f3F800000;
	fma.rn.f32 	%f556, %f555, %f11, %f226;

BB11_26:
	and.b32  	%r288, %r41, 2;
	setp.eq.s32	%p16, %r288, 0;
	@%p16 bra 	BB11_28;

	mov.f32 	%f227, 0f00000000;
	mov.f32 	%f228, 0fBF800000;
	fma.rn.f32 	%f556, %f556, %f228, %f227;

BB11_28:
	div.rn.f32 	%f557, %f1, 0f3FD9999A;
	abs.f32 	%f229, %f557;
	setp.neu.f32	%p17, %f229, 0f7F800000;
	@%p17 bra 	BB11_30;

	mov.f32 	%f230, 0f00000000;
	mul.rn.f32 	%f557, %f557, %f230;

BB11_30:
	mul.f32 	%f231, %f557, 0f3F22F983;
	cvt.rni.s32.f32	%r599, %f231;
	cvt.rn.f32.s32	%f232, %r599;
	neg.f32 	%f233, %f232;
	fma.rn.f32 	%f235, %f233, %f210, %f557;
	fma.rn.f32 	%f237, %f233, %f212, %f235;
	fma.rn.f32 	%f558, %f233, %f214, %f237;
	abs.f32 	%f239, %f557;
	setp.leu.f32	%p18, %f239, 0f47CE4780;
	@%p18 bra 	BB11_40;

	mov.b32 	 %r44, %f557;
	shr.u32 	%r45, %r44, 23;
	bfe.u32 	%r291, %r44, 23, 8;
	add.s32 	%r292, %r291, -128;
	shl.b32 	%r293, %r44, 8;
	or.b32  	%r46, %r293, -2147483648;
	shr.u32 	%r47, %r292, 5;
	mov.u32 	%r591, 0;
	mov.u64 	%rd59, __cudart_i2opi_f;
	mov.u32 	%r590, -6;
	mov.u64 	%rd74, %rd1;

BB11_32:
	.pragma "nounroll";
	ld.const.u32 	%r296, [%rd59];
	// inline asm
	{
	mad.lo.cc.u32   %r294, %r296, %r46, %r591;
	madc.hi.u32     %r295, %r296, %r46,  0;
	}
	// inline asm
	mov.u32 	%r591, %r295;
	st.local.u32 	[%rd74], %r294;
	add.s64 	%rd74, %rd74, 4;
	add.s64 	%rd59, %rd59, 4;
	add.s32 	%r590, %r590, 1;
	setp.ne.s32	%p19, %r590, 0;
	@%p19 bra 	BB11_32;

	and.b32  	%r52, %r44, -2147483648;
	st.local.u32 	[%rd3], %r295;
	mov.u32 	%r299, 6;
	sub.s32 	%r300, %r299, %r47;
	mul.wide.s32 	%rd48, %r300, 4;
	add.s64 	%rd20, %rd1, %rd48;
	ld.local.u32 	%r592, [%rd20];
	ld.local.u32 	%r593, [%rd20+-4];
	and.b32  	%r55, %r45, 31;
	setp.eq.s32	%p20, %r55, 0;
	@%p20 bra 	BB11_35;

	mov.u32 	%r301, 32;
	sub.s32 	%r302, %r301, %r55;
	shr.u32 	%r303, %r593, %r302;
	shl.b32 	%r304, %r592, %r55;
	add.s32 	%r592, %r303, %r304;
	ld.local.u32 	%r305, [%rd20+-8];
	shr.u32 	%r306, %r305, %r302;
	shl.b32 	%r307, %r593, %r55;
	add.s32 	%r593, %r306, %r307;

BB11_35:
	shr.u32 	%r308, %r593, 30;
	shl.b32 	%r309, %r592, 2;
	add.s32 	%r594, %r308, %r309;
	shl.b32 	%r61, %r593, 2;
	shr.u32 	%r310, %r594, 31;
	shr.u32 	%r311, %r592, 30;
	add.s32 	%r62, %r310, %r311;
	setp.eq.s32	%p21, %r310, 0;
	mov.u32 	%r595, %r52;
	mov.u32 	%r596, %r61;
	@%p21 bra 	BB11_37;

	not.b32 	%r312, %r594;
	neg.s32 	%r63, %r61;
	setp.eq.s32	%p22, %r61, 0;
	selp.u32	%r313, 1, 0, %p22;
	add.s32 	%r594, %r313, %r312;
	xor.b32  	%r65, %r52, -2147483648;
	mov.u32 	%r595, %r65;
	mov.u32 	%r596, %r63;

BB11_37:
	mov.u32 	%r67, %r595;
	neg.s32 	%r314, %r62;
	setp.eq.s32	%p23, %r52, 0;
	selp.b32	%r599, %r62, %r314, %p23;
	clz.b32 	%r598, %r594;
	setp.eq.s32	%p24, %r598, 0;
	shl.b32 	%r315, %r594, %r598;
	mov.u32 	%r316, 32;
	sub.s32 	%r317, %r316, %r598;
	shr.u32 	%r318, %r596, %r317;
	add.s32 	%r319, %r318, %r315;
	selp.b32	%r71, %r594, %r319, %p24;
	mov.u32 	%r320, -921707870;
	mul.hi.u32 	%r597, %r71, %r320;
	setp.lt.s32	%p25, %r597, 1;
	@%p25 bra 	BB11_39;

	mul.lo.s32 	%r321, %r71, -921707870;
	shr.u32 	%r322, %r321, 31;
	shl.b32 	%r323, %r597, 1;
	add.s32 	%r597, %r322, %r323;
	add.s32 	%r598, %r598, 1;

BB11_39:
	mov.u32 	%r324, 126;
	sub.s32 	%r325, %r324, %r598;
	shl.b32 	%r326, %r325, 23;
	add.s32 	%r327, %r597, 1;
	shr.u32 	%r328, %r327, 7;
	add.s32 	%r329, %r328, 1;
	shr.u32 	%r330, %r329, 1;
	add.s32 	%r331, %r330, %r326;
	or.b32  	%r332, %r331, %r67;
	mov.b32 	 %f558, %r332;

BB11_40:
	mul.rn.f32 	%f29, %f558, %f558;
	add.s32 	%r78, %r599, 1;
	and.b32  	%r79, %r78, 1;
	setp.eq.s32	%p26, %r79, 0;
	@%p26 bra 	BB11_42;

	mov.f32 	%f240, 0fBAB6061A;
	mov.f32 	%f241, 0f37CCF5CE;
	fma.rn.f32 	%f559, %f241, %f29, %f240;
	bra.uni 	BB11_43;

BB11_42:
	mov.f32 	%f242, 0f3C08839E;
	mov.f32 	%f243, 0fB94CA1F9;
	fma.rn.f32 	%f559, %f243, %f29, %f242;

BB11_43:
	@%p26 bra 	BB11_45;

	mov.f32 	%f244, 0f3D2AAAA5;
	fma.rn.f32 	%f245, %f559, %f29, %f244;
	mov.f32 	%f246, 0fBF000000;
	fma.rn.f32 	%f560, %f245, %f29, %f246;
	bra.uni 	BB11_46;

BB11_45:
	mov.f32 	%f247, 0fBE2AAAA3;
	fma.rn.f32 	%f248, %f559, %f29, %f247;
	mov.f32 	%f249, 0f00000000;
	fma.rn.f32 	%f560, %f248, %f29, %f249;

BB11_46:
	fma.rn.f32 	%f561, %f560, %f558, %f558;
	@%p26 bra 	BB11_48;

	mov.f32 	%f250, 0f3F800000;
	fma.rn.f32 	%f561, %f560, %f29, %f250;

BB11_48:
	and.b32  	%r333, %r78, 2;
	setp.eq.s32	%p29, %r333, 0;
	@%p29 bra 	BB11_50;

	mov.f32 	%f251, 0f00000000;
	mov.f32 	%f252, 0fBF800000;
	fma.rn.f32 	%f561, %f561, %f252, %f251;

BB11_50:
	abs.f32 	%f564, %f199;
	setp.eq.f32	%p30, %f564, 0f7F800000;
	mov.f32 	%f254, 0f40000000;
	abs.f32 	%f43, %f254;
	setp.eq.f32	%p31, %f43, 0f00000000;
	or.pred  	%p32, %p30, %p31;
	mov.f32 	%f253, 0f7FFFFFFF;
	mov.f32 	%f575, %f253;
	@%p32 bra 	BB11_63;

	setp.ltu.f32	%p33, %f564, %f43;
	@%p33 bra 	BB11_62;
	bra.uni 	BB11_52;

BB11_62:
	setp.gtu.f32	%p46, %f43, 0f7F800000;
	add.f32 	%f275, %f199, 0f40000000;
	selp.f32	%f276, %f275, %f199, %p46;
	add.f32 	%f277, %f199, %f276;
	setp.leu.f32	%p47, %f564, 0f00000000;
	selp.f32	%f57, %f277, %f276, %p47;
	mov.f32 	%f575, %f57;
	bra.uni 	BB11_63;

BB11_52:
	lg2.approx.f32 	%f255, %f564;
	cvt.rzi.s32.f32	%r334, %f255;
	lg2.approx.f32 	%f256, %f43;
	cvt.rzi.s32.f32	%r335, %f256;
	sub.s32 	%r80, %r334, %r335;
	abs.f32 	%f44, %f43;
	setp.eq.f32	%p34, %f44, 0f00000000;
	setp.eq.f32	%p35, %f44, 0f7F800000;
	or.pred  	%p36, %p34, %p35;
	setp.eq.s32	%p37, %r334, %r335;
	or.pred  	%p38, %p36, %p37;
	@%p38 bra 	BB11_58;
	bra.uni 	BB11_53;

BB11_58:
	setp.leu.f32	%p41, %f44, 0f00000000;
	add.f32 	%f271, %f43, %f43;
	selp.f32	%f562, %f271, %f43, %p41;
	bra.uni 	BB11_59;

BB11_53:
	abs.s32 	%r81, %r80;
	setp.lt.s32	%p39, %r81, 126;
	@%p39 bra 	BB11_57;
	bra.uni 	BB11_54;

BB11_57:
	cvt.rn.f32.s32	%f270, %r80;
	// inline asm
	ex2.approx.ftz.f32 %f269,%f270;
	// inline asm
	mul.f32 	%f562, %f43, %f269;
	bra.uni 	BB11_59;

BB11_54:
	setp.lt.s32	%p40, %r81, 252;
	@%p40 bra 	BB11_56;
	bra.uni 	BB11_55;

BB11_56:
	shr.u32 	%r341, %r80, 31;
	add.s32 	%r342, %r80, %r341;
	shr.s32 	%r343, %r342, 1;
	cvt.rn.f32.s32	%f265, %r343;
	// inline asm
	ex2.approx.ftz.f32 %f264,%f265;
	// inline asm
	mul.f32 	%f268, %f43, %f264;
	sub.s32 	%r344, %r80, %r343;
	cvt.rn.f32.s32	%f267, %r344;
	// inline asm
	ex2.approx.ftz.f32 %f266,%f267;
	// inline asm
	mul.f32 	%f562, %f268, %f266;
	bra.uni 	BB11_59;

BB11_55:
	shr.s32 	%r336, %r80, 31;
	shr.u32 	%r337, %r336, 30;
	add.s32 	%r338, %r80, %r337;
	shr.s32 	%r339, %r338, 2;
	cvt.rn.f32.s32	%f258, %r339;
	// inline asm
	ex2.approx.ftz.f32 %f257,%f258;
	// inline asm
	mul.f32 	%f261, %f43, %f257;
	mul.f32 	%f262, %f257, %f261;
	mul.f32 	%f263, %f257, %f262;
	mad.lo.s32 	%r340, %r339, -3, %r80;
	cvt.rn.f32.s32	%f260, %r340;
	// inline asm
	ex2.approx.ftz.f32 %f259,%f260;
	// inline asm
	mul.f32 	%f562, %f259, %f263;

BB11_59:
	mul.f32 	%f272, %f564, 0f3F000000;
	setp.gtu.f32	%p42, %f562, %f272;
	add.f32 	%f273, %f562, %f562;
	selp.f32	%f563, %f562, %f273, %p42;
	setp.ltu.f32	%p43, %f563, %f43;
	@%p43 bra 	BB11_61;

BB11_60:
	sub.f32 	%f274, %f564, %f563;
	setp.ltu.f32	%p44, %f564, %f563;
	selp.f32	%f564, %f564, %f274, %p44;
	mul.f32 	%f563, %f563, 0f3F000000;
	setp.ge.f32	%p45, %f563, %f43;
	@%p45 bra 	BB11_60;

BB11_61:
	mov.b32 	 %r345, %f199;
	and.b32  	%r346, %r345, -2147483648;
	mov.b32 	 %r347, %f564;
	or.b32  	%r348, %r347, %r346;
	mov.b32 	 %f56, %r348;
	mov.f32 	%f575, %f56;

BB11_63:
	mov.f32 	%f58, %f575;
	abs.f32 	%f60, %f58;
	abs.f32 	%f567, %f200;
	setp.eq.f32	%p48, %f567, 0f7F800000;
	or.pred  	%p50, %p48, %p31;
	mov.f32 	%f574, %f253;
	@%p50 bra 	BB11_76;

	setp.ltu.f32	%p51, %f567, %f43;
	@%p51 bra 	BB11_75;
	bra.uni 	BB11_65;

BB11_75:
	setp.gtu.f32	%p64, %f43, 0f7F800000;
	add.f32 	%f299, %f200, 0f40000000;
	selp.f32	%f300, %f299, %f200, %p64;
	add.f32 	%f301, %f200, %f300;
	setp.leu.f32	%p65, %f567, 0f00000000;
	selp.f32	%f574, %f301, %f300, %p65;
	bra.uni 	BB11_76;

BB11_65:
	lg2.approx.f32 	%f279, %f567;
	cvt.rzi.s32.f32	%r349, %f279;
	lg2.approx.f32 	%f280, %f43;
	cvt.rzi.s32.f32	%r350, %f280;
	sub.s32 	%r82, %r349, %r350;
	abs.f32 	%f62, %f43;
	setp.eq.f32	%p52, %f62, 0f00000000;
	setp.eq.f32	%p53, %f62, 0f7F800000;
	or.pred  	%p54, %p52, %p53;
	setp.eq.s32	%p55, %r349, %r350;
	or.pred  	%p56, %p54, %p55;
	@%p56 bra 	BB11_71;
	bra.uni 	BB11_66;

BB11_71:
	setp.leu.f32	%p59, %f62, 0f00000000;
	add.f32 	%f295, %f43, %f43;
	selp.f32	%f565, %f295, %f43, %p59;
	bra.uni 	BB11_72;

BB11_66:
	abs.s32 	%r83, %r82;
	setp.lt.s32	%p57, %r83, 126;
	@%p57 bra 	BB11_70;
	bra.uni 	BB11_67;

BB11_70:
	cvt.rn.f32.s32	%f294, %r82;
	// inline asm
	ex2.approx.ftz.f32 %f293,%f294;
	// inline asm
	mul.f32 	%f565, %f43, %f293;
	bra.uni 	BB11_72;

BB11_67:
	setp.lt.s32	%p58, %r83, 252;
	@%p58 bra 	BB11_69;
	bra.uni 	BB11_68;

BB11_69:
	shr.u32 	%r356, %r82, 31;
	add.s32 	%r357, %r82, %r356;
	shr.s32 	%r358, %r357, 1;
	cvt.rn.f32.s32	%f289, %r358;
	// inline asm
	ex2.approx.ftz.f32 %f288,%f289;
	// inline asm
	mul.f32 	%f292, %f43, %f288;
	sub.s32 	%r359, %r82, %r358;
	cvt.rn.f32.s32	%f291, %r359;
	// inline asm
	ex2.approx.ftz.f32 %f290,%f291;
	// inline asm
	mul.f32 	%f565, %f292, %f290;
	bra.uni 	BB11_72;

BB11_68:
	shr.s32 	%r351, %r82, 31;
	shr.u32 	%r352, %r351, 30;
	add.s32 	%r353, %r82, %r352;
	shr.s32 	%r354, %r353, 2;
	cvt.rn.f32.s32	%f282, %r354;
	// inline asm
	ex2.approx.ftz.f32 %f281,%f282;
	// inline asm
	mul.f32 	%f285, %f43, %f281;
	mul.f32 	%f286, %f281, %f285;
	mul.f32 	%f287, %f281, %f286;
	mad.lo.s32 	%r355, %r354, -3, %r82;
	cvt.rn.f32.s32	%f284, %r355;
	// inline asm
	ex2.approx.ftz.f32 %f283,%f284;
	// inline asm
	mul.f32 	%f565, %f283, %f287;

BB11_72:
	mul.f32 	%f296, %f567, 0f3F000000;
	setp.gtu.f32	%p60, %f565, %f296;
	add.f32 	%f297, %f565, %f565;
	selp.f32	%f566, %f565, %f297, %p60;
	setp.ltu.f32	%p61, %f566, %f43;
	@%p61 bra 	BB11_74;

BB11_73:
	sub.f32 	%f298, %f567, %f566;
	setp.ltu.f32	%p62, %f567, %f566;
	selp.f32	%f567, %f567, %f298, %p62;
	mul.f32 	%f566, %f566, 0f3F000000;
	setp.ge.f32	%p63, %f566, %f43;
	@%p63 bra 	BB11_73;

BB11_74:
	mov.b32 	 %r360, %f200;
	and.b32  	%r361, %r360, -2147483648;
	mov.b32 	 %r362, %f567;
	or.b32  	%r363, %r362, %r361;
	mov.b32 	 %f574, %r363;

BB11_76:
	abs.f32 	%f78, %f574;
	abs.f32 	%f570, %f201;
	setp.eq.f32	%p66, %f570, 0f7F800000;
	or.pred  	%p68, %p66, %p31;
	mov.f32 	%f573, %f253;
	@%p68 bra 	BB11_89;

	setp.ltu.f32	%p69, %f570, %f43;
	@%p69 bra 	BB11_88;
	bra.uni 	BB11_78;

BB11_88:
	setp.gtu.f32	%p82, %f43, 0f7F800000;
	add.f32 	%f323, %f201, 0f40000000;
	selp.f32	%f324, %f323, %f201, %p82;
	add.f32 	%f325, %f201, %f324;
	setp.leu.f32	%p83, %f570, 0f00000000;
	selp.f32	%f573, %f325, %f324, %p83;
	bra.uni 	BB11_89;

BB11_78:
	lg2.approx.f32 	%f303, %f570;
	cvt.rzi.s32.f32	%r364, %f303;
	lg2.approx.f32 	%f304, %f43;
	cvt.rzi.s32.f32	%r365, %f304;
	sub.s32 	%r84, %r364, %r365;
	abs.f32 	%f80, %f43;
	setp.eq.f32	%p70, %f80, 0f00000000;
	setp.eq.f32	%p71, %f80, 0f7F800000;
	or.pred  	%p72, %p70, %p71;
	setp.eq.s32	%p73, %r364, %r365;
	or.pred  	%p74, %p72, %p73;
	@%p74 bra 	BB11_84;
	bra.uni 	BB11_79;

BB11_84:
	setp.leu.f32	%p77, %f80, 0f00000000;
	add.f32 	%f319, %f43, %f43;
	selp.f32	%f568, %f319, %f43, %p77;
	bra.uni 	BB11_85;

BB11_79:
	abs.s32 	%r85, %r84;
	setp.lt.s32	%p75, %r85, 126;
	@%p75 bra 	BB11_83;
	bra.uni 	BB11_80;

BB11_83:
	cvt.rn.f32.s32	%f318, %r84;
	// inline asm
	ex2.approx.ftz.f32 %f317,%f318;
	// inline asm
	mul.f32 	%f568, %f43, %f317;
	bra.uni 	BB11_85;

BB11_80:
	setp.lt.s32	%p76, %r85, 252;
	@%p76 bra 	BB11_82;
	bra.uni 	BB11_81;

BB11_82:
	shr.u32 	%r371, %r84, 31;
	add.s32 	%r372, %r84, %r371;
	shr.s32 	%r373, %r372, 1;
	cvt.rn.f32.s32	%f313, %r373;
	// inline asm
	ex2.approx.ftz.f32 %f312,%f313;
	// inline asm
	mul.f32 	%f316, %f43, %f312;
	sub.s32 	%r374, %r84, %r373;
	cvt.rn.f32.s32	%f315, %r374;
	// inline asm
	ex2.approx.ftz.f32 %f314,%f315;
	// inline asm
	mul.f32 	%f568, %f316, %f314;
	bra.uni 	BB11_85;

BB11_81:
	shr.s32 	%r366, %r84, 31;
	shr.u32 	%r367, %r366, 30;
	add.s32 	%r368, %r84, %r367;
	shr.s32 	%r369, %r368, 2;
	cvt.rn.f32.s32	%f306, %r369;
	// inline asm
	ex2.approx.ftz.f32 %f305,%f306;
	// inline asm
	mul.f32 	%f309, %f43, %f305;
	mul.f32 	%f310, %f305, %f309;
	mul.f32 	%f311, %f305, %f310;
	mad.lo.s32 	%r370, %r369, -3, %r84;
	cvt.rn.f32.s32	%f308, %r370;
	// inline asm
	ex2.approx.ftz.f32 %f307,%f308;
	// inline asm
	mul.f32 	%f568, %f307, %f311;

BB11_85:
	mul.f32 	%f320, %f570, 0f3F000000;
	setp.gtu.f32	%p78, %f568, %f320;
	add.f32 	%f321, %f568, %f568;
	selp.f32	%f569, %f568, %f321, %p78;
	setp.ltu.f32	%p79, %f569, %f43;
	@%p79 bra 	BB11_87;

BB11_86:
	sub.f32 	%f322, %f570, %f569;
	setp.ltu.f32	%p80, %f570, %f569;
	selp.f32	%f570, %f570, %f322, %p80;
	mul.f32 	%f569, %f569, 0f3F000000;
	setp.ge.f32	%p81, %f569, %f43;
	@%p81 bra 	BB11_86;

BB11_87:
	mov.b32 	 %r375, %f201;
	and.b32  	%r376, %r375, -2147483648;
	mov.b32 	 %r377, %f570;
	or.b32  	%r378, %r377, %r376;
	mov.b32 	 %f573, %r378;

BB11_89:
	ld.u32 	%r86, [%rd2+-4];
	setp.eq.s32	%p84, %r86, 0;
	mov.f32 	%f604, 0f447A0000;
	@%p84 bra 	BB11_195;

	fma.rn.f32 	%f328, %f556, 0f3E4CCCCD, 0f3F800000;
	mul.f32 	%f329, %f561, 0f3DCCCCCD;
	cvt.f64.f32	%fd1, %f329;
	add.f64 	%fd2, %fd1, 0d3FD3333333333333;
	cvt.rn.f32.f64	%f330, %fd2;
	mov.f32 	%f331, 0f3F800000;
	sub.f32 	%f332, %f331, %f60;
	sub.f32 	%f333, %f331, %f78;
	abs.f32 	%f334, %f573;
	sub.f32 	%f335, %f331, %f334;
	abs.f32 	%f576, %f335;
	abs.f32 	%f577, %f333;
	abs.f32 	%f578, %f332;
	ld.f32 	%f98, [%rd2+112];
	add.f32 	%f336, %f98, 0fBF800000;
	mul.f32 	%f99, %f328, %f336;
	mul.f32 	%f100, %f330, %f336;
	div.rn.f32 	%f101, %f1, 0fC1900000;
	abs.f32 	%f102, %f101;
	mov.f32 	%f604, 0f447A0000;
	mov.u32 	%r600, 0;
	bra.uni 	BB11_91;

BB11_182:
	setp.eq.f32	%p146, %f186, 0f7F800000;
	@%p146 bra 	BB11_192;
	bra.uni 	BB11_183;

BB11_192:
	setp.eq.f32	%p167, %f98, 0fBF800000;
	setp.gt.f32	%p168, %f185, 0f3F800000;
	selp.b32	%r575, 2139095040, 0, %p168;
	xor.b32  	%r576, %r575, 2139095040;
	setp.gt.f32	%p169, %f182, 0f80000000;
	selp.b32	%r577, %r576, %r575, %p169;
	mov.b32 	 %f549, %r577;
	selp.f32	%f194, 0f3F800000, %f549, %p167;
	mov.f32 	%f603, %f194;
	bra.uni 	BB11_194;

BB11_183:
	setp.eq.f32	%p147, %f185, 0f7F800000;
	@%p147 bra 	BB11_191;
	bra.uni 	BB11_184;

BB11_191:
	setp.eq.f32	%p163, %f184, 0f3F800000;
	setp.gtu.f32	%p164, %f182, 0f80000000;
	selp.b32	%r572, 0, 2139095040, %p164;
	setp.lt.f32	%p165, %f98, 0f00000000;
	and.pred  	%p166, %p165, %p163;
	or.b32  	%r573, %r572, -2147483648;
	selp.b32	%r574, %r573, %r572, %p166;
	mov.b32 	 %f193, %r574;
	mov.f32 	%f603, %f193;
	bra.uni 	BB11_194;

BB11_184:
	setp.eq.f32	%p148, %f98, 0f00000000;
	@%p148 bra 	BB11_190;
	bra.uni 	BB11_185;

BB11_190:
	setp.eq.f32	%p161, %f184, 0f3F800000;
	add.f32 	%f548, %f98, %f98;
	mov.b32 	 %r568, %f548;
	selp.b32	%r569, %r568, 0, %p161;
	or.b32  	%r570, %r569, 2139095040;
	setp.gt.f32	%p162, %f182, 0f80000000;
	selp.b32	%r571, %r570, %r569, %p162;
	mov.b32 	 %f192, %r571;
	mov.f32 	%f603, %f192;
	bra.uni 	BB11_194;

BB11_185:
	setp.geu.f32	%p149, %f98, 0f00000000;
	@%p149 bra 	BB11_187;

	cvt.rzi.f32.f32	%f472, %f183;
	setp.neu.f32	%p150, %f472, %f183;
	mov.f32 	%f471, 0f7FFFFFFF;
	mov.f32 	%f603, %f471;
	@%p150 bra 	BB11_194;

BB11_187:
	setp.lt.f32	%p151, %f185, 0f00800000;
	selp.f32	%f477, 0fC3170000, 0fC2FE0000, %p151;
	mul.f32 	%f478, %f185, 0f4B800000;
	selp.f32	%f479, %f478, %f185, %p151;
	mov.b32 	 %r560, %f479;
	and.b32  	%r561, %r560, 8388607;
	or.b32  	%r562, %r561, 1065353216;
	mov.b32 	 %f480, %r562;
	shr.u32 	%r563, %r560, 23;
	cvt.rn.f32.u32	%f481, %r563;
	add.f32 	%f482, %f477, %f481;
	setp.gt.f32	%p152, %f480, 0f3FB504F3;
	mul.f32 	%f483, %f480, 0f3F000000;
	add.f32 	%f484, %f482, 0f3F800000;
	selp.f32	%f485, %f483, %f480, %p152;
	selp.f32	%f486, %f484, %f482, %p152;
	add.f32 	%f487, %f485, 0fBF800000;
	add.f32 	%f474, %f485, 0f3F800000;
	// inline asm
	rcp.approx.ftz.f32 %f473,%f474;
	// inline asm
	add.f32 	%f488, %f487, %f487;
	mul.f32 	%f489, %f488, %f473;
	mul.f32 	%f490, %f489, %f489;
	mov.f32 	%f491, 0f3C4CAF63;
	mov.f32 	%f492, 0f3B18F0FE;
	fma.rn.f32 	%f493, %f492, %f490, %f491;
	mov.f32 	%f494, 0f3DAAAABD;
	fma.rn.f32 	%f495, %f493, %f490, %f494;
	mul.rn.f32 	%f496, %f495, %f490;
	mul.rn.f32 	%f497, %f496, %f489;
	sub.f32 	%f498, %f487, %f489;
	add.f32 	%f499, %f498, %f498;
	neg.f32 	%f500, %f489;
	fma.rn.f32 	%f501, %f500, %f487, %f499;
	mul.rn.f32 	%f502, %f473, %f501;
	add.f32 	%f503, %f489, %f497;
	sub.f32 	%f504, %f489, %f503;
	add.f32 	%f505, %f497, %f504;
	add.f32 	%f506, %f502, %f505;
	add.f32 	%f507, %f503, %f506;
	sub.f32 	%f508, %f503, %f507;
	add.f32 	%f509, %f506, %f508;
	mov.f32 	%f510, 0f3F317200;
	mul.rn.f32 	%f511, %f486, %f510;
	mov.f32 	%f512, 0f35BFBE8E;
	mul.rn.f32 	%f513, %f486, %f512;
	add.f32 	%f514, %f511, %f507;
	sub.f32 	%f515, %f511, %f514;
	add.f32 	%f516, %f507, %f515;
	add.f32 	%f517, %f509, %f516;
	add.f32 	%f518, %f513, %f517;
	add.f32 	%f519, %f514, %f518;
	sub.f32 	%f520, %f514, %f519;
	add.f32 	%f521, %f518, %f520;
	mul.f32 	%f522, %f183, 0f39000000;
	setp.gt.f32	%p153, %f186, 0f77F684DF;
	selp.f32	%f523, %f522, %f183, %p153;
	mul.rn.f32 	%f524, %f523, %f519;
	neg.f32 	%f525, %f524;
	fma.rn.f32 	%f526, %f523, %f519, %f525;
	fma.rn.f32 	%f527, %f523, %f521, %f526;
	mov.f32 	%f528, 0f00000000;
	fma.rn.f32 	%f529, %f528, %f519, %f527;
	add.rn.f32 	%f530, %f524, %f529;
	neg.f32 	%f531, %f530;
	add.rn.f32 	%f532, %f524, %f531;
	add.rn.f32 	%f533, %f532, %f529;
	mov.b32 	 %r564, %f530;
	setp.eq.s32	%p154, %r564, 1118925336;
	add.s32 	%r565, %r564, -1;
	mov.b32 	 %f534, %r565;
	add.f32 	%f535, %f533, 0f37000000;
	selp.f32	%f187, %f535, %f533, %p154;
	selp.f32	%f536, %f534, %f530, %p154;
	mul.f32 	%f537, %f536, 0f3FB8AA3B;
	cvt.rzi.f32.f32	%f538, %f537;
	mov.f32 	%f539, 0fBF317200;
	fma.rn.f32 	%f540, %f538, %f539, %f536;
	mov.f32 	%f541, 0fB5BFBE8E;
	fma.rn.f32 	%f542, %f538, %f541, %f540;
	mul.f32 	%f476, %f542, 0f3FB8AA3B;
	// inline asm
	ex2.approx.ftz.f32 %f475,%f476;
	// inline asm
	add.f32 	%f543, %f538, 0f00000000;
	ex2.approx.f32 	%f544, %f543;
	mul.f32 	%f545, %f475, %f544;
	setp.lt.f32	%p155, %f536, 0fC2D20000;
	selp.f32	%f546, 0f00000000, %f545, %p155;
	setp.gt.f32	%p156, %f536, 0f42D20000;
	selp.f32	%f602, 0f7F800000, %f546, %p156;
	setp.eq.f32	%p157, %f602, 0f7F800000;
	@%p157 bra 	BB11_189;

	fma.rn.f32 	%f602, %f602, %f187, %f602;

BB11_189:
	setp.lt.f32	%p158, %f98, 0f00000000;
	setp.eq.f32	%p159, %f184, 0f3F800000;
	and.pred  	%p160, %p158, %p159;
	mov.b32 	 %r566, %f602;
	xor.b32  	%r567, %r566, -2147483648;
	mov.b32 	 %f547, %r567;
	selp.f32	%f191, %f547, %f602, %p160;
	mov.f32 	%f603, %f191;
	bra.uni 	BB11_194;

BB11_91:
	add.f32 	%f337, %f578, %f577;
	setp.lt.f32	%p85, %f337, 0f00000000;
	neg.f32 	%f338, %f577;
	selp.f32	%f339, %f338, %f578, %p85;
	neg.f32 	%f340, %f578;
	selp.f32	%f341, %f340, %f577, %p85;
	abs.f32 	%f342, %f339;
	abs.f32 	%f343, %f341;
	abs.f32 	%f344, %f576;
	add.f32 	%f345, %f342, %f344;
	setp.lt.f32	%p86, %f345, 0f00000000;
	neg.f32 	%f346, %f344;
	neg.f32 	%f347, %f342;
	selp.f32	%f348, %f346, %f342, %p86;
	selp.f32	%f349, %f347, %f344, %p86;
	abs.f32 	%f350, %f348;
	abs.f32 	%f351, %f343;
	abs.f32 	%f352, %f349;
	sub.f32 	%f353, %f350, %f351;
	setp.lt.f32	%p87, %f353, 0f00000000;
	selp.f32	%f354, %f351, %f350, %p87;
	selp.f32	%f355, %f350, %f351, %p87;
	abs.f32 	%f356, %f354;
	abs.f32 	%f357, %f355;
	abs.f32 	%f358, %f352;
	sub.f32 	%f359, %f356, %f358;
	setp.lt.f32	%p88, %f359, 0f00000000;
	selp.f32	%f360, %f358, %f356, %p88;
	selp.f32	%f361, %f356, %f358, %p88;
	abs.f32 	%f362, %f360;
	abs.f32 	%f363, %f357;
	abs.f32 	%f364, %f361;
	mul.f32 	%f365, %f362, %f98;
	mul.f32 	%f366, %f363, %f98;
	mul.f32 	%f367, %f364, %f98;
	sub.f32 	%f578, %f365, %f99;
	sub.f32 	%f108, %f366, %f336;
	sub.f32 	%f109, %f367, %f100;
	setp.neu.f32	%p89, %f102, 0f7F800000;
	mov.f32 	%f597, %f101;
	@%p89 bra 	BB11_93;

	mov.f32 	%f369, 0f00000000;
	mul.rn.f32 	%f110, %f101, %f369;
	mov.f32 	%f597, %f110;

BB11_93:
	mov.f32 	%f111, %f597;
	mul.f32 	%f370, %f111, 0f3F22F983;
	cvt.rni.s32.f32	%r610, %f370;
	cvt.rn.f32.s32	%f371, %r610;
	neg.f32 	%f372, %f371;
	fma.rn.f32 	%f374, %f372, %f210, %f111;
	fma.rn.f32 	%f376, %f372, %f212, %f374;
	fma.rn.f32 	%f579, %f372, %f214, %f376;
	abs.f32 	%f378, %f111;
	setp.leu.f32	%p90, %f378, 0f47CE4780;
	@%p90 bra 	BB11_103;

	mov.b32 	 %r89, %f111;
	shr.u32 	%r90, %r89, 23;
	bfe.u32 	%r382, %r89, 23, 8;
	add.s32 	%r383, %r382, -128;
	shl.b32 	%r384, %r89, 8;
	or.b32  	%r91, %r384, -2147483648;
	shr.u32 	%r92, %r383, 5;
	mov.u32 	%r602, 0;
	mov.u64 	%rd60, __cudart_i2opi_f;
	mov.u32 	%r601, -6;
	mov.u64 	%rd73, %rd1;

BB11_95:
	.pragma "nounroll";
	mov.u64 	%rd23, %rd73;
	ld.const.u32 	%r387, [%rd60];
	// inline asm
	{
	mad.lo.cc.u32   %r385, %r387, %r91, %r602;
	madc.hi.u32     %r386, %r387, %r91,  0;
	}
	// inline asm
	mov.u32 	%r602, %r386;
	st.local.u32 	[%rd23], %r385;
	add.s64 	%rd24, %rd23, 4;
	add.s64 	%rd60, %rd60, 4;
	add.s32 	%r601, %r601, 1;
	setp.ne.s32	%p91, %r601, 0;
	mov.u64 	%rd73, %rd24;
	@%p91 bra 	BB11_95;

	and.b32  	%r97, %r89, -2147483648;
	st.local.u32 	[%rd1+24], %r386;
	mov.u32 	%r390, 6;
	sub.s32 	%r391, %r390, %r92;
	mul.wide.s32 	%rd50, %r391, 4;
	add.s64 	%rd26, %rd1, %rd50;
	ld.local.u32 	%r603, [%rd26];
	ld.local.u32 	%r604, [%rd26+-4];
	and.b32  	%r100, %r90, 31;
	setp.eq.s32	%p92, %r100, 0;
	@%p92 bra 	BB11_98;

	mov.u32 	%r392, 32;
	sub.s32 	%r393, %r392, %r100;
	shr.u32 	%r394, %r604, %r393;
	shl.b32 	%r395, %r603, %r100;
	add.s32 	%r603, %r394, %r395;
	ld.local.u32 	%r396, [%rd26+-8];
	shr.u32 	%r397, %r396, %r393;
	shl.b32 	%r398, %r604, %r100;
	add.s32 	%r604, %r397, %r398;

BB11_98:
	shr.u32 	%r399, %r604, 30;
	shl.b32 	%r400, %r603, 2;
	add.s32 	%r605, %r399, %r400;
	shl.b32 	%r106, %r604, 2;
	shr.u32 	%r401, %r605, 31;
	shr.u32 	%r402, %r603, 30;
	add.s32 	%r107, %r401, %r402;
	setp.eq.s32	%p93, %r401, 0;
	mov.u32 	%r606, %r97;
	mov.u32 	%r607, %r106;
	@%p93 bra 	BB11_100;

	not.b32 	%r403, %r605;
	neg.s32 	%r108, %r106;
	setp.eq.s32	%p94, %r106, 0;
	selp.u32	%r404, 1, 0, %p94;
	add.s32 	%r605, %r404, %r403;
	xor.b32  	%r110, %r97, -2147483648;
	mov.u32 	%r606, %r110;
	mov.u32 	%r607, %r108;

BB11_100:
	mov.u32 	%r112, %r606;
	neg.s32 	%r405, %r107;
	setp.eq.s32	%p95, %r97, 0;
	selp.b32	%r610, %r107, %r405, %p95;
	clz.b32 	%r609, %r605;
	setp.eq.s32	%p96, %r609, 0;
	shl.b32 	%r406, %r605, %r609;
	mov.u32 	%r407, 32;
	sub.s32 	%r408, %r407, %r609;
	shr.u32 	%r409, %r607, %r408;
	add.s32 	%r410, %r409, %r406;
	selp.b32	%r116, %r605, %r410, %p96;
	mov.u32 	%r411, -921707870;
	mul.hi.u32 	%r608, %r116, %r411;
	setp.lt.s32	%p97, %r608, 1;
	@%p97 bra 	BB11_102;

	mul.lo.s32 	%r412, %r116, -921707870;
	shr.u32 	%r413, %r412, 31;
	shl.b32 	%r414, %r608, 1;
	add.s32 	%r608, %r413, %r414;
	add.s32 	%r609, %r609, 1;

BB11_102:
	mov.u32 	%r415, 126;
	sub.s32 	%r416, %r415, %r609;
	shl.b32 	%r417, %r416, 23;
	add.s32 	%r418, %r608, 1;
	shr.u32 	%r419, %r418, 7;
	add.s32 	%r420, %r419, 1;
	shr.u32 	%r421, %r420, 1;
	add.s32 	%r422, %r421, %r417;
	or.b32  	%r423, %r422, %r112;
	mov.b32 	 %f579, %r423;

BB11_103:
	mul.rn.f32 	%f115, %f579, %f579;
	add.s32 	%r123, %r610, 1;
	and.b32  	%r124, %r123, 1;
	setp.eq.s32	%p98, %r124, 0;
	@%p98 bra 	BB11_105;
	bra.uni 	BB11_104;

BB11_105:
	mov.f32 	%f381, 0f3C08839E;
	mov.f32 	%f382, 0fB94CA1F9;
	fma.rn.f32 	%f580, %f382, %f115, %f381;
	bra.uni 	BB11_106;

BB11_104:
	mov.f32 	%f379, 0fBAB6061A;
	mov.f32 	%f380, 0f37CCF5CE;
	fma.rn.f32 	%f580, %f380, %f115, %f379;

BB11_106:
	@%p98 bra 	BB11_108;
	bra.uni 	BB11_107;

BB11_108:
	mov.f32 	%f386, 0fBE2AAAA3;
	fma.rn.f32 	%f387, %f580, %f115, %f386;
	mov.f32 	%f388, 0f00000000;
	fma.rn.f32 	%f581, %f387, %f115, %f388;
	bra.uni 	BB11_109;

BB11_107:
	mov.f32 	%f383, 0f3D2AAAA5;
	fma.rn.f32 	%f384, %f580, %f115, %f383;
	mov.f32 	%f385, 0fBF000000;
	fma.rn.f32 	%f581, %f384, %f115, %f385;

BB11_109:
	fma.rn.f32 	%f582, %f581, %f579, %f579;
	@%p98 bra 	BB11_111;

	fma.rn.f32 	%f582, %f581, %f115, %f331;

BB11_111:
	and.b32  	%r424, %r123, 2;
	setp.eq.s32	%p101, %r424, 0;
	@%p101 bra 	BB11_113;

	mov.f32 	%f390, 0f00000000;
	mov.f32 	%f391, 0fBF800000;
	fma.rn.f32 	%f582, %f582, %f391, %f390;

BB11_113:
	mov.f32 	%f596, %f101;
	@%p89 bra 	BB11_115;

	mov.f32 	%f392, 0f00000000;
	mul.rn.f32 	%f596, %f101, %f392;

BB11_115:
	mul.f32 	%f393, %f596, 0f3F22F983;
	cvt.rni.s32.f32	%r620, %f393;
	cvt.rn.f32.s32	%f394, %r620;
	neg.f32 	%f395, %f394;
	fma.rn.f32 	%f397, %f395, %f210, %f596;
	fma.rn.f32 	%f399, %f395, %f212, %f397;
	fma.rn.f32 	%f583, %f395, %f214, %f399;
	abs.f32 	%f401, %f596;
	setp.leu.f32	%p103, %f401, 0f47CE4780;
	@%p103 bra 	BB11_125;

	mov.b32 	 %r126, %f596;
	shr.u32 	%r127, %r126, 23;
	bfe.u32 	%r427, %r126, 23, 8;
	add.s32 	%r428, %r427, -128;
	shl.b32 	%r429, %r126, 8;
	or.b32  	%r128, %r429, -2147483648;
	shr.u32 	%r129, %r428, 5;
	mov.u32 	%r612, 0;
	mov.u64 	%rd61, __cudart_i2opi_f;
	mov.u32 	%r611, -6;
	mov.u64 	%rd72, %rd1;

BB11_117:
	.pragma "nounroll";
	ld.const.u32 	%r432, [%rd61];
	// inline asm
	{
	mad.lo.cc.u32   %r430, %r432, %r128, %r612;
	madc.hi.u32     %r431, %r432, %r128,  0;
	}
	// inline asm
	mov.u32 	%r612, %r431;
	st.local.u32 	[%rd72], %r430;
	add.s64 	%rd72, %rd72, 4;
	add.s64 	%rd61, %rd61, 4;
	add.s32 	%r611, %r611, 1;
	setp.ne.s32	%p104, %r611, 0;
	@%p104 bra 	BB11_117;

	and.b32  	%r134, %r126, -2147483648;
	st.local.u32 	[%rd1+24], %r431;
	mov.u32 	%r435, 6;
	sub.s32 	%r436, %r435, %r129;
	mul.wide.s32 	%rd52, %r436, 4;
	add.s64 	%rd31, %rd1, %rd52;
	ld.local.u32 	%r613, [%rd31];
	ld.local.u32 	%r614, [%rd31+-4];
	and.b32  	%r137, %r127, 31;
	setp.eq.s32	%p105, %r137, 0;
	@%p105 bra 	BB11_120;

	mov.u32 	%r437, 32;
	sub.s32 	%r438, %r437, %r137;
	shr.u32 	%r439, %r614, %r438;
	shl.b32 	%r440, %r613, %r137;
	add.s32 	%r613, %r439, %r440;
	ld.local.u32 	%r441, [%rd31+-8];
	shr.u32 	%r442, %r441, %r438;
	shl.b32 	%r443, %r614, %r137;
	add.s32 	%r614, %r442, %r443;

BB11_120:
	shr.u32 	%r444, %r614, 30;
	shl.b32 	%r445, %r613, 2;
	add.s32 	%r615, %r444, %r445;
	shl.b32 	%r143, %r614, 2;
	shr.u32 	%r446, %r615, 31;
	shr.u32 	%r447, %r613, 30;
	add.s32 	%r144, %r446, %r447;
	setp.eq.s32	%p106, %r446, 0;
	mov.u32 	%r616, %r134;
	mov.u32 	%r617, %r143;
	@%p106 bra 	BB11_122;

	not.b32 	%r448, %r615;
	neg.s32 	%r145, %r143;
	setp.eq.s32	%p107, %r143, 0;
	selp.u32	%r449, 1, 0, %p107;
	add.s32 	%r615, %r449, %r448;
	xor.b32  	%r147, %r134, -2147483648;
	mov.u32 	%r616, %r147;
	mov.u32 	%r617, %r145;

BB11_122:
	mov.u32 	%r149, %r616;
	neg.s32 	%r450, %r144;
	setp.eq.s32	%p108, %r134, 0;
	selp.b32	%r620, %r144, %r450, %p108;
	clz.b32 	%r619, %r615;
	setp.eq.s32	%p109, %r619, 0;
	shl.b32 	%r451, %r615, %r619;
	mov.u32 	%r452, 32;
	sub.s32 	%r453, %r452, %r619;
	shr.u32 	%r454, %r617, %r453;
	add.s32 	%r455, %r454, %r451;
	selp.b32	%r153, %r615, %r455, %p109;
	mov.u32 	%r456, -921707870;
	mul.hi.u32 	%r618, %r153, %r456;
	setp.lt.s32	%p110, %r618, 1;
	@%p110 bra 	BB11_124;

	mul.lo.s32 	%r457, %r153, -921707870;
	shr.u32 	%r458, %r457, 31;
	shl.b32 	%r459, %r618, 1;
	add.s32 	%r618, %r458, %r459;
	add.s32 	%r619, %r619, 1;

BB11_124:
	mov.u32 	%r460, 126;
	sub.s32 	%r461, %r460, %r619;
	shl.b32 	%r462, %r461, 23;
	add.s32 	%r463, %r618, 1;
	shr.u32 	%r464, %r463, 7;
	add.s32 	%r465, %r464, 1;
	shr.u32 	%r466, %r465, 1;
	add.s32 	%r467, %r466, %r462;
	or.b32  	%r468, %r467, %r149;
	mov.b32 	 %f583, %r468;

BB11_125:
	mul.rn.f32 	%f132, %f583, %f583;
	and.b32  	%r160, %r620, 1;
	setp.eq.s32	%p111, %r160, 0;
	@%p111 bra 	BB11_127;
	bra.uni 	BB11_126;

BB11_127:
	mov.f32 	%f404, 0f3C08839E;
	mov.f32 	%f405, 0fB94CA1F9;
	fma.rn.f32 	%f584, %f405, %f132, %f404;
	bra.uni 	BB11_128;

BB11_126:
	mov.f32 	%f402, 0fBAB6061A;
	mov.f32 	%f403, 0f37CCF5CE;
	fma.rn.f32 	%f584, %f403, %f132, %f402;

BB11_128:
	@%p111 bra 	BB11_130;
	bra.uni 	BB11_129;

BB11_130:
	mov.f32 	%f409, 0fBE2AAAA3;
	fma.rn.f32 	%f410, %f584, %f132, %f409;
	mov.f32 	%f411, 0f00000000;
	fma.rn.f32 	%f585, %f410, %f132, %f411;
	bra.uni 	BB11_131;

BB11_129:
	mov.f32 	%f406, 0f3D2AAAA5;
	fma.rn.f32 	%f407, %f584, %f132, %f406;
	mov.f32 	%f408, 0fBF000000;
	fma.rn.f32 	%f585, %f407, %f132, %f408;

BB11_131:
	fma.rn.f32 	%f586, %f585, %f583, %f583;
	@%p111 bra 	BB11_133;

	fma.rn.f32 	%f586, %f585, %f132, %f331;

BB11_133:
	and.b32  	%r469, %r620, 2;
	setp.eq.s32	%p114, %r469, 0;
	@%p114 bra 	BB11_135;

	mov.f32 	%f413, 0f00000000;
	mov.f32 	%f414, 0fBF800000;
	fma.rn.f32 	%f586, %f586, %f414, %f413;

BB11_135:
	mul.f32 	%f415, %f109, %f586;
	fma.rn.f32 	%f577, %f108, %f582, %f415;
	mov.f32 	%f595, %f101;
	@%p89 bra 	BB11_137;

	mov.f32 	%f416, 0f00000000;
	mul.rn.f32 	%f595, %f101, %f416;

BB11_137:
	mul.f32 	%f417, %f595, 0f3F22F983;
	cvt.rni.s32.f32	%r630, %f417;
	cvt.rn.f32.s32	%f418, %r630;
	neg.f32 	%f419, %f418;
	fma.rn.f32 	%f421, %f419, %f210, %f595;
	fma.rn.f32 	%f423, %f419, %f212, %f421;
	fma.rn.f32 	%f587, %f419, %f214, %f423;
	abs.f32 	%f425, %f595;
	setp.leu.f32	%p116, %f425, 0f47CE4780;
	@%p116 bra 	BB11_147;

	mov.b32 	 %r162, %f595;
	shr.u32 	%r163, %r162, 23;
	bfe.u32 	%r472, %r162, 23, 8;
	add.s32 	%r473, %r472, -128;
	shl.b32 	%r474, %r162, 8;
	or.b32  	%r164, %r474, -2147483648;
	shr.u32 	%r165, %r473, 5;
	mov.u32 	%r622, 0;
	mov.u64 	%rd62, __cudart_i2opi_f;
	mov.u32 	%r621, -6;
	mov.u64 	%rd71, %rd1;

BB11_139:
	.pragma "nounroll";
	ld.const.u32 	%r477, [%rd62];
	// inline asm
	{
	mad.lo.cc.u32   %r475, %r477, %r164, %r622;
	madc.hi.u32     %r476, %r477, %r164,  0;
	}
	// inline asm
	mov.u32 	%r622, %r476;
	st.local.u32 	[%rd71], %r475;
	add.s64 	%rd71, %rd71, 4;
	add.s64 	%rd62, %rd62, 4;
	add.s32 	%r621, %r621, 1;
	setp.ne.s32	%p117, %r621, 0;
	@%p117 bra 	BB11_139;

	and.b32  	%r170, %r162, -2147483648;
	st.local.u32 	[%rd1+24], %r476;
	mov.u32 	%r480, 6;
	sub.s32 	%r481, %r480, %r165;
	mul.wide.s32 	%rd54, %r481, 4;
	add.s64 	%rd36, %rd1, %rd54;
	ld.local.u32 	%r623, [%rd36];
	ld.local.u32 	%r624, [%rd36+-4];
	and.b32  	%r173, %r163, 31;
	setp.eq.s32	%p118, %r173, 0;
	@%p118 bra 	BB11_142;

	mov.u32 	%r482, 32;
	sub.s32 	%r483, %r482, %r173;
	shr.u32 	%r484, %r624, %r483;
	shl.b32 	%r485, %r623, %r173;
	add.s32 	%r623, %r484, %r485;
	ld.local.u32 	%r486, [%rd36+-8];
	shr.u32 	%r487, %r486, %r483;
	shl.b32 	%r488, %r624, %r173;
	add.s32 	%r624, %r487, %r488;

BB11_142:
	shr.u32 	%r489, %r624, 30;
	shl.b32 	%r490, %r623, 2;
	add.s32 	%r625, %r489, %r490;
	shl.b32 	%r179, %r624, 2;
	shr.u32 	%r491, %r625, 31;
	shr.u32 	%r492, %r623, 30;
	add.s32 	%r180, %r491, %r492;
	setp.eq.s32	%p119, %r491, 0;
	mov.u32 	%r626, %r170;
	mov.u32 	%r627, %r179;
	@%p119 bra 	BB11_144;

	not.b32 	%r493, %r625;
	neg.s32 	%r181, %r179;
	setp.eq.s32	%p120, %r179, 0;
	selp.u32	%r494, 1, 0, %p120;
	add.s32 	%r625, %r494, %r493;
	xor.b32  	%r183, %r170, -2147483648;
	mov.u32 	%r626, %r183;
	mov.u32 	%r627, %r181;

BB11_144:
	mov.u32 	%r185, %r626;
	neg.s32 	%r495, %r180;
	setp.eq.s32	%p121, %r170, 0;
	selp.b32	%r630, %r180, %r495, %p121;
	clz.b32 	%r629, %r625;
	setp.eq.s32	%p122, %r629, 0;
	shl.b32 	%r496, %r625, %r629;
	mov.u32 	%r497, 32;
	sub.s32 	%r498, %r497, %r629;
	shr.u32 	%r499, %r627, %r498;
	add.s32 	%r500, %r499, %r496;
	selp.b32	%r189, %r625, %r500, %p122;
	mov.u32 	%r501, -921707870;
	mul.hi.u32 	%r628, %r189, %r501;
	setp.lt.s32	%p123, %r628, 1;
	@%p123 bra 	BB11_146;

	mul.lo.s32 	%r502, %r189, -921707870;
	shr.u32 	%r503, %r502, 31;
	shl.b32 	%r504, %r628, 1;
	add.s32 	%r628, %r503, %r504;
	add.s32 	%r629, %r629, 1;

BB11_146:
	mov.u32 	%r505, 126;
	sub.s32 	%r506, %r505, %r629;
	shl.b32 	%r507, %r506, 23;
	add.s32 	%r508, %r628, 1;
	shr.u32 	%r509, %r508, 7;
	add.s32 	%r510, %r509, 1;
	shr.u32 	%r511, %r510, 1;
	add.s32 	%r512, %r511, %r507;
	or.b32  	%r513, %r512, %r185;
	mov.b32 	 %f587, %r513;

BB11_147:
	mul.rn.f32 	%f150, %f587, %f587;
	and.b32  	%r196, %r630, 1;
	setp.eq.s32	%p124, %r196, 0;
	@%p124 bra 	BB11_149;
	bra.uni 	BB11_148;

BB11_149:
	mov.f32 	%f428, 0f3C08839E;
	mov.f32 	%f429, 0fB94CA1F9;
	fma.rn.f32 	%f588, %f429, %f150, %f428;
	bra.uni 	BB11_150;

BB11_148:
	mov.f32 	%f426, 0fBAB6061A;
	mov.f32 	%f427, 0f37CCF5CE;
	fma.rn.f32 	%f588, %f427, %f150, %f426;

BB11_150:
	@%p124 bra 	BB11_152;
	bra.uni 	BB11_151;

BB11_152:
	mov.f32 	%f433, 0fBE2AAAA3;
	fma.rn.f32 	%f434, %f588, %f150, %f433;
	mov.f32 	%f435, 0f00000000;
	fma.rn.f32 	%f589, %f434, %f150, %f435;
	bra.uni 	BB11_153;

BB11_151:
	mov.f32 	%f430, 0f3D2AAAA5;
	fma.rn.f32 	%f431, %f588, %f150, %f430;
	mov.f32 	%f432, 0fBF000000;
	fma.rn.f32 	%f589, %f431, %f150, %f432;

BB11_153:
	fma.rn.f32 	%f590, %f589, %f587, %f587;
	@%p124 bra 	BB11_155;

	fma.rn.f32 	%f590, %f589, %f150, %f331;

BB11_155:
	and.b32  	%r514, %r630, 2;
	setp.eq.s32	%p127, %r514, 0;
	@%p127 bra 	BB11_157;

	mov.f32 	%f437, 0f00000000;
	mov.f32 	%f438, 0fBF800000;
	fma.rn.f32 	%f590, %f590, %f438, %f437;

BB11_157:
	mul.f32 	%f162, %f108, %f590;
	mov.f32 	%f594, %f101;
	@%p89 bra 	BB11_159;

	mov.f32 	%f439, 0f00000000;
	mul.rn.f32 	%f594, %f101, %f439;

BB11_159:
	mul.f32 	%f440, %f594, 0f3F22F983;
	cvt.rni.s32.f32	%r640, %f440;
	cvt.rn.f32.s32	%f441, %r640;
	neg.f32 	%f442, %f441;
	fma.rn.f32 	%f444, %f442, %f210, %f594;
	fma.rn.f32 	%f446, %f442, %f212, %f444;
	fma.rn.f32 	%f598, %f442, %f214, %f446;
	abs.f32 	%f448, %f594;
	setp.leu.f32	%p129, %f448, 0f47CE4780;
	@%p129 bra 	BB11_169;

	mov.b32 	 %r198, %f594;
	shr.u32 	%r199, %r198, 23;
	bfe.u32 	%r517, %r198, 23, 8;
	add.s32 	%r518, %r517, -128;
	shl.b32 	%r519, %r198, 8;
	or.b32  	%r200, %r519, -2147483648;
	shr.u32 	%r201, %r518, 5;
	mov.u32 	%r632, 0;
	mov.u64 	%rd63, __cudart_i2opi_f;
	mov.u32 	%r631, -6;
	mov.u64 	%rd70, %rd1;

BB11_161:
	.pragma "nounroll";
	ld.const.u32 	%r522, [%rd63];
	// inline asm
	{
	mad.lo.cc.u32   %r520, %r522, %r200, %r632;
	madc.hi.u32     %r521, %r522, %r200,  0;
	}
	// inline asm
	mov.u32 	%r632, %r521;
	st.local.u32 	[%rd70], %r520;
	add.s64 	%rd70, %rd70, 4;
	add.s64 	%rd63, %rd63, 4;
	add.s32 	%r631, %r631, 1;
	setp.ne.s32	%p130, %r631, 0;
	@%p130 bra 	BB11_161;

	and.b32  	%r206, %r198, -2147483648;
	st.local.u32 	[%rd1+24], %r521;
	mov.u32 	%r525, 6;
	sub.s32 	%r526, %r525, %r201;
	mul.wide.s32 	%rd56, %r526, 4;
	add.s64 	%rd41, %rd1, %rd56;
	ld.local.u32 	%r633, [%rd41];
	ld.local.u32 	%r634, [%rd41+-4];
	and.b32  	%r209, %r199, 31;
	setp.eq.s32	%p131, %r209, 0;
	@%p131 bra 	BB11_164;

	mov.u32 	%r527, 32;
	sub.s32 	%r528, %r527, %r209;
	shr.u32 	%r529, %r634, %r528;
	shl.b32 	%r530, %r633, %r209;
	add.s32 	%r633, %r529, %r530;
	ld.local.u32 	%r531, [%rd41+-8];
	shr.u32 	%r532, %r531, %r528;
	shl.b32 	%r533, %r634, %r209;
	add.s32 	%r634, %r532, %r533;

BB11_164:
	shr.u32 	%r534, %r634, 30;
	shl.b32 	%r535, %r633, 2;
	add.s32 	%r635, %r534, %r535;
	shl.b32 	%r215, %r634, 2;
	shr.u32 	%r536, %r635, 31;
	shr.u32 	%r537, %r633, 30;
	add.s32 	%r216, %r536, %r537;
	setp.eq.s32	%p132, %r536, 0;
	mov.u32 	%r636, %r206;
	mov.u32 	%r637, %r215;
	@%p132 bra 	BB11_166;

	not.b32 	%r538, %r635;
	neg.s32 	%r217, %r215;
	setp.eq.s32	%p133, %r215, 0;
	selp.u32	%r539, 1, 0, %p133;
	add.s32 	%r635, %r539, %r538;
	xor.b32  	%r219, %r206, -2147483648;
	mov.u32 	%r636, %r219;
	mov.u32 	%r637, %r217;

BB11_166:
	mov.u32 	%r221, %r636;
	neg.s32 	%r540, %r216;
	setp.eq.s32	%p134, %r206, 0;
	selp.b32	%r640, %r216, %r540, %p134;
	clz.b32 	%r639, %r635;
	setp.eq.s32	%p135, %r639, 0;
	shl.b32 	%r541, %r635, %r639;
	mov.u32 	%r542, 32;
	sub.s32 	%r543, %r542, %r639;
	shr.u32 	%r544, %r637, %r543;
	add.s32 	%r545, %r544, %r541;
	selp.b32	%r225, %r635, %r545, %p135;
	mov.u32 	%r546, -921707870;
	mul.hi.u32 	%r638, %r225, %r546;
	setp.lt.s32	%p136, %r638, 1;
	@%p136 bra 	BB11_168;

	mul.lo.s32 	%r547, %r225, -921707870;
	shr.u32 	%r548, %r547, 31;
	shl.b32 	%r549, %r638, 1;
	add.s32 	%r638, %r548, %r549;
	add.s32 	%r639, %r639, 1;

BB11_168:
	mov.u32 	%r550, 126;
	sub.s32 	%r551, %r550, %r639;
	shl.b32 	%r552, %r551, 23;
	add.s32 	%r553, %r638, 1;
	shr.u32 	%r554, %r553, 7;
	add.s32 	%r555, %r554, 1;
	shr.u32 	%r556, %r555, 1;
	add.s32 	%r557, %r556, %r552;
	or.b32  	%r558, %r557, %r221;
	mov.b32 	 %f598, %r558;

BB11_169:
	mul.rn.f32 	%f168, %f598, %f598;
	add.s32 	%r232, %r640, 1;
	and.b32  	%r233, %r232, 1;
	setp.eq.s32	%p137, %r233, 0;
	@%p137 bra 	BB11_171;
	bra.uni 	BB11_170;

BB11_171:
	mov.f32 	%f451, 0f3C08839E;
	mov.f32 	%f452, 0fB94CA1F9;
	fma.rn.f32 	%f599, %f452, %f168, %f451;
	bra.uni 	BB11_172;

BB11_170:
	mov.f32 	%f449, 0fBAB6061A;
	mov.f32 	%f450, 0f37CCF5CE;
	fma.rn.f32 	%f599, %f450, %f168, %f449;

BB11_172:
	@%p137 bra 	BB11_174;
	bra.uni 	BB11_173;

BB11_174:
	mov.f32 	%f456, 0fBE2AAAA3;
	fma.rn.f32 	%f457, %f599, %f168, %f456;
	mov.f32 	%f458, 0f00000000;
	fma.rn.f32 	%f600, %f457, %f168, %f458;
	bra.uni 	BB11_175;

BB11_173:
	mov.f32 	%f453, 0f3D2AAAA5;
	fma.rn.f32 	%f454, %f599, %f168, %f453;
	mov.f32 	%f455, 0fBF000000;
	fma.rn.f32 	%f600, %f454, %f168, %f455;

BB11_175:
	fma.rn.f32 	%f601, %f600, %f598, %f598;
	@%p137 bra 	BB11_177;

	fma.rn.f32 	%f601, %f600, %f168, %f331;

BB11_177:
	and.b32  	%r559, %r232, 2;
	setp.eq.s32	%p140, %r559, 0;
	@%p140 bra 	BB11_179;

	mov.f32 	%f460, 0f00000000;
	mov.f32 	%f461, 0fBF800000;
	fma.rn.f32 	%f601, %f601, %f461, %f460;

BB11_179:
	mul.f32 	%f463, %f109, %f601;
	sub.f32 	%f576, %f463, %f162;
	mul.f32 	%f464, %f577, %f577;
	fma.rn.f32 	%f465, %f578, %f578, %f464;
	fma.rn.f32 	%f466, %f576, %f576, %f465;
	sqrt.rn.f32 	%f181, %f466;
	add.s32 	%r600, %r600, 1;
	cvt.rn.f32.s32	%f182, %r600;
	neg.f32 	%f183, %f182;
	mul.f32 	%f467, %f182, 0fBF000000;
	cvt.rzi.f32.f32	%f468, %f467;
	mul.f32 	%f469, %f468, 0fC0000000;
	sub.f32 	%f470, %f469, %f182;
	abs.f32 	%f184, %f470;
	setp.eq.f32	%p141, %f182, 0f80000000;
	setp.eq.f32	%p142, %f98, 0f3F800000;
	or.pred  	%p143, %p142, %p141;
	mov.f32 	%f603, %f331;
	@%p143 bra 	BB11_194;

	abs.f32 	%f185, %f98;
	setp.gtu.f32	%p144, %f185, 0f7F800000;
	@%p144 bra 	BB11_193;

	abs.f32 	%f186, %f183;
	setp.gtu.f32	%p145, %f186, 0f7F800000;
	@%p145 bra 	BB11_193;
	bra.uni 	BB11_182;

BB11_193:
	sub.f32 	%f195, %f98, %f182;
	mov.f32 	%f603, %f195;

BB11_194:
	mov.f32 	%f196, %f603;
	mul.f32 	%f550, %f181, %f196;
	min.f32 	%f604, %f604, %f550;
	setp.lt.u32	%p170, %r600, %r86;
	@%p170 bra 	BB11_91;

BB11_195:
	st.param.f32	[func_retval0+0], %f604;
	ret;
}

	// .globl	_ZN6MatrixILj4ELj4EEC1EPKf
.visible .func _ZN6MatrixILj4ELj4EEC1EPKf(
	.param .b64 _ZN6MatrixILj4ELj4EEC1EPKf_param_0,
	.param .b64 _ZN6MatrixILj4ELj4EEC1EPKf_param_1
)
{
	.reg .f32 	%f<17>;
	.reg .s64 	%rd<3>;


	ld.param.u64 	%rd1, [_ZN6MatrixILj4ELj4EEC1EPKf_param_0];
	ld.param.u64 	%rd2, [_ZN6MatrixILj4ELj4EEC1EPKf_param_1];
	ld.f32 	%f1, [%rd2];
	st.f32 	[%rd1], %f1;
	ld.f32 	%f2, [%rd2+4];
	st.f32 	[%rd1+4], %f2;
	ld.f32 	%f3, [%rd2+8];
	st.f32 	[%rd1+8], %f3;
	ld.f32 	%f4, [%rd2+12];
	st.f32 	[%rd1+12], %f4;
	ld.f32 	%f5, [%rd2+16];
	st.f32 	[%rd1+16], %f5;
	ld.f32 	%f6, [%rd2+20];
	st.f32 	[%rd1+20], %f6;
	ld.f32 	%f7, [%rd2+24];
	st.f32 	[%rd1+24], %f7;
	ld.f32 	%f8, [%rd2+28];
	st.f32 	[%rd1+28], %f8;
	ld.f32 	%f9, [%rd2+32];
	st.f32 	[%rd1+32], %f9;
	ld.f32 	%f10, [%rd2+36];
	st.f32 	[%rd1+36], %f10;
	ld.f32 	%f11, [%rd2+40];
	st.f32 	[%rd1+40], %f11;
	ld.f32 	%f12, [%rd2+44];
	st.f32 	[%rd1+44], %f12;
	ld.f32 	%f13, [%rd2+48];
	st.f32 	[%rd1+48], %f13;
	ld.f32 	%f14, [%rd2+52];
	st.f32 	[%rd1+52], %f14;
	ld.f32 	%f15, [%rd2+56];
	st.f32 	[%rd1+56], %f15;
	ld.f32 	%f16, [%rd2+60];
	st.f32 	[%rd1+60], %f16;
	ret;
}

	// .globl	_ZN6MatrixILj4ELj4EEC2EPKf
.visible .func _ZN6MatrixILj4ELj4EEC2EPKf(
	.param .b64 _ZN6MatrixILj4ELj4EEC2EPKf_param_0,
	.param .b64 _ZN6MatrixILj4ELj4EEC2EPKf_param_1
)
{
	.reg .f32 	%f<17>;
	.reg .s64 	%rd<3>;


	ld.param.u64 	%rd1, [_ZN6MatrixILj4ELj4EEC2EPKf_param_0];
	ld.param.u64 	%rd2, [_ZN6MatrixILj4ELj4EEC2EPKf_param_1];
	ld.f32 	%f1, [%rd2];
	st.f32 	[%rd1], %f1;
	ld.f32 	%f2, [%rd2+4];
	st.f32 	[%rd1+4], %f2;
	ld.f32 	%f3, [%rd2+8];
	st.f32 	[%rd1+8], %f3;
	ld.f32 	%f4, [%rd2+12];
	st.f32 	[%rd1+12], %f4;
	ld.f32 	%f5, [%rd2+16];
	st.f32 	[%rd1+16], %f5;
	ld.f32 	%f6, [%rd2+20];
	st.f32 	[%rd1+20], %f6;
	ld.f32 	%f7, [%rd2+24];
	st.f32 	[%rd1+24], %f7;
	ld.f32 	%f8, [%rd2+28];
	st.f32 	[%rd1+28], %f8;
	ld.f32 	%f9, [%rd2+32];
	st.f32 	[%rd1+32], %f9;
	ld.f32 	%f10, [%rd2+36];
	st.f32 	[%rd1+36], %f10;
	ld.f32 	%f11, [%rd2+40];
	st.f32 	[%rd1+40], %f11;
	ld.f32 	%f12, [%rd2+44];
	st.f32 	[%rd1+44], %f12;
	ld.f32 	%f13, [%rd2+48];
	st.f32 	[%rd1+48], %f13;
	ld.f32 	%f14, [%rd2+52];
	st.f32 	[%rd1+52], %f14;
	ld.f32 	%f15, [%rd2+56];
	st.f32 	[%rd1+56], %f15;
	ld.f32 	%f16, [%rd2+60];
	st.f32 	[%rd1+60], %f16;
	ret;
}

	// .globl	_ZN17DistanceEstimator12setScaleHookEj6float3
.visible .func _ZN17DistanceEstimator12setScaleHookEj6float3(
	.param .b64 _ZN17DistanceEstimator12setScaleHookEj6float3_param_0,
	.param .b32 _ZN17DistanceEstimator12setScaleHookEj6float3_param_1,
	.param .align 4 .b8 _ZN17DistanceEstimator12setScaleHookEj6float3_param_2[12]
)
{
	.reg .f32 	%f<4>;
	.reg .s32 	%r<2>;
	.reg .s64 	%rd<4>;


	ld.param.u64 	%rd1, [_ZN17DistanceEstimator12setScaleHookEj6float3_param_0];
	ld.param.u32 	%r1, [_ZN17DistanceEstimator12setScaleHookEj6float3_param_1];
	ld.param.f32 	%f1, [_ZN17DistanceEstimator12setScaleHookEj6float3_param_2];
	ld.param.f32 	%f2, [_ZN17DistanceEstimator12setScaleHookEj6float3_param_2+4];
	ld.param.f32 	%f3, [_ZN17DistanceEstimator12setScaleHookEj6float3_param_2+8];
	mul.wide.u32 	%rd2, %r1, 12;
	add.s64 	%rd3, %rd1, %rd2;
	st.f32 	[%rd3+24], %f3;
	st.f32 	[%rd3+20], %f2;
	st.f32 	[%rd3+16], %f1;
	ret;
}

	// .globl	_ZN17DistanceEstimator13setRotateHookEj6float3
.visible .func _ZN17DistanceEstimator13setRotateHookEj6float3(
	.param .b64 _ZN17DistanceEstimator13setRotateHookEj6float3_param_0,
	.param .b32 _ZN17DistanceEstimator13setRotateHookEj6float3_param_1,
	.param .align 4 .b8 _ZN17DistanceEstimator13setRotateHookEj6float3_param_2[12]
)
{
	.reg .f32 	%f<4>;
	.reg .s32 	%r<2>;
	.reg .s64 	%rd<4>;


	ld.param.u64 	%rd1, [_ZN17DistanceEstimator13setRotateHookEj6float3_param_0];
	ld.param.u32 	%r1, [_ZN17DistanceEstimator13setRotateHookEj6float3_param_1];
	ld.param.f32 	%f1, [_ZN17DistanceEstimator13setRotateHookEj6float3_param_2];
	ld.param.f32 	%f2, [_ZN17DistanceEstimator13setRotateHookEj6float3_param_2+4];
	ld.param.f32 	%f3, [_ZN17DistanceEstimator13setRotateHookEj6float3_param_2+8];
	mul.wide.u32 	%rd2, %r1, 12;
	add.s64 	%rd3, %rd1, %rd2;
	st.f32 	[%rd3+60], %f3;
	st.f32 	[%rd3+56], %f2;
	st.f32 	[%rd3+52], %f1;
	ret;
}

	// .globl	_ZN17DistanceEstimator16setTranslateHookEj6float3
.visible .func _ZN17DistanceEstimator16setTranslateHookEj6float3(
	.param .b64 _ZN17DistanceEstimator16setTranslateHookEj6float3_param_0,
	.param .b32 _ZN17DistanceEstimator16setTranslateHookEj6float3_param_1,
	.param .align 4 .b8 _ZN17DistanceEstimator16setTranslateHookEj6float3_param_2[12]
)
{
	.reg .f32 	%f<4>;
	.reg .s32 	%r<2>;
	.reg .s64 	%rd<4>;


	ld.param.u64 	%rd1, [_ZN17DistanceEstimator16setTranslateHookEj6float3_param_0];
	ld.param.u32 	%r1, [_ZN17DistanceEstimator16setTranslateHookEj6float3_param_1];
	ld.param.f32 	%f1, [_ZN17DistanceEstimator16setTranslateHookEj6float3_param_2];
	ld.param.f32 	%f2, [_ZN17DistanceEstimator16setTranslateHookEj6float3_param_2+4];
	ld.param.f32 	%f3, [_ZN17DistanceEstimator16setTranslateHookEj6float3_param_2+8];
	mul.wide.u32 	%rd2, %r1, 12;
	add.s64 	%rd3, %rd1, %rd2;
	st.f32 	[%rd3+96], %f3;
	st.f32 	[%rd3+92], %f2;
	st.f32 	[%rd3+88], %f1;
	ret;
}

	// .globl	_ZN17DistanceEstimatorC2Ej
.visible .func _ZN17DistanceEstimatorC2Ej(
	.param .b64 _ZN17DistanceEstimatorC2Ej_param_0,
	.param .b32 _ZN17DistanceEstimatorC2Ej_param_1
)
{
	.reg .f32 	%f<2>;
	.reg .s32 	%r<4>;
	.reg .s64 	%rd<5>;


	ld.param.u64 	%rd1, [_ZN17DistanceEstimatorC2Ej_param_0];
	ld.param.u32 	%r1, [_ZN17DistanceEstimatorC2Ej_param_1];
	mov.u64 	%rd2, _ZTV17DistanceEstimator;
	add.s64 	%rd3, %rd2, 16;
	cvta.global.u64 	%rd4, %rd3;
	st.u64 	[%rd1], %rd4;
	st.u32 	[%rd1+8], %r1;
	mov.u32 	%r2, 0;
	st.u32 	[%rd1+12], %r2;
	mov.f32 	%f1, 0f3F800000;
	st.v2.f32 	[%rd1+16], {%f1, %f1};
	mov.u32 	%r3, 1065353216;
	st.u32 	[%rd1+24], %r3;
	st.u32 	[%rd1+28], %r3;
	st.u32 	[%rd1+32], %r3;
	st.u32 	[%rd1+36], %r3;
	st.u32 	[%rd1+52], %r2;
	st.u32 	[%rd1+60], %r2;
	st.u32 	[%rd1+56], %r2;
	st.u32 	[%rd1+64], %r2;
	st.u32 	[%rd1+68], %r2;
	st.u32 	[%rd1+72], %r2;
	st.u32 	[%rd1+40], %r3;
	st.u32 	[%rd1+44], %r3;
	st.u32 	[%rd1+48], %r3;
	st.u32 	[%rd1+88], %r2;
	st.u32 	[%rd1+96], %r2;
	st.u32 	[%rd1+92], %r2;
	st.u32 	[%rd1+100], %r2;
	st.u32 	[%rd1+104], %r2;
	st.u32 	[%rd1+108], %r2;
	st.u32 	[%rd1+76], %r2;
	st.u32 	[%rd1+80], %r2;
	st.u32 	[%rd1+84], %r2;
	st.u32 	[%rd1+120], %r2;
	st.u32 	[%rd1+116], %r2;
	st.u32 	[%rd1+112], %r2;
	ret;
}

	// .globl	_ZN17DistanceEstimator9scaleHookEj6float3
.visible .func  (.param .align 4 .b8 func_retval0[12]) _ZN17DistanceEstimator9scaleHookEj6float3(
	.param .b64 _ZN17DistanceEstimator9scaleHookEj6float3_param_0,
	.param .b32 _ZN17DistanceEstimator9scaleHookEj6float3_param_1,
	.param .align 4 .b8 _ZN17DistanceEstimator9scaleHookEj6float3_param_2[12]
)
{
	.reg .pred 	%p<5>;
	.reg .f32 	%f<32>;
	.reg .s32 	%r<2>;
	.reg .s64 	%rd<4>;


	ld.param.u64 	%rd1, [_ZN17DistanceEstimator9scaleHookEj6float3_param_0];
	ld.param.u32 	%r1, [_ZN17DistanceEstimator9scaleHookEj6float3_param_1];
	ld.param.f32 	%f31, [_ZN17DistanceEstimator9scaleHookEj6float3_param_2+8];
	ld.param.f32 	%f11, [_ZN17DistanceEstimator9scaleHookEj6float3_param_2+4];
	ld.param.f32 	%f10, [_ZN17DistanceEstimator9scaleHookEj6float3_param_2];
	setp.gt.u32	%p1, %r1, 2;
	mov.f32 	%f28, %f10;
	mov.f32 	%f30, %f11;
	@%p1 bra 	BB18_5;

	mul.wide.u32 	%rd2, %r1, 12;
	add.s64 	%rd3, %rd1, %rd2;
	ld.f32 	%f1, [%rd3+20];
	ld.f32 	%f2, [%rd3+24];
	ld.f32 	%f3, [%rd3+16];
	add.f32 	%f13, %f3, 0fBF800000;
	abs.f32 	%f14, %f13;
	setp.geu.f32	%p2, %f14, 0f38D1B717;
	@%p2 bra 	BB18_4;

	add.f32 	%f15, %f1, 0fBF800000;
	abs.f32 	%f16, %f15;
	setp.geu.f32	%p3, %f16, 0f38D1B717;
	@%p3 bra 	BB18_4;

	add.f32 	%f17, %f2, 0fBF800000;
	abs.f32 	%f18, %f17;
	setp.lt.f32	%p4, %f18, 0f38D1B717;
	mov.f32 	%f27, %f10;
	mov.f32 	%f28, %f27;
	mov.f32 	%f29, %f11;
	mov.f32 	%f30, %f29;
	@%p4 bra 	BB18_5;

BB18_4:
	fma.rn.f32 	%f19, %f10, %f3, 0f00000000;
	fma.rn.f32 	%f20, %f11, 0f00000000, %f19;
	fma.rn.f32 	%f21, %f31, 0f00000000, %f20;
	add.f32 	%f4, %f21, 0f00000000;
	fma.rn.f32 	%f22, %f10, 0f00000000, 0f00000000;
	fma.rn.f32 	%f23, %f11, %f1, %f22;
	fma.rn.f32 	%f24, %f31, 0f00000000, %f23;
	add.f32 	%f5, %f24, 0f00000000;
	fma.rn.f32 	%f25, %f11, 0f00000000, %f22;
	fma.rn.f32 	%f26, %f31, %f2, %f25;
	add.f32 	%f31, %f26, 0f00000000;
	mov.f32 	%f28, %f4;
	mov.f32 	%f30, %f5;

BB18_5:
	st.param.f32	[func_retval0+0], %f28;
	st.param.f32	[func_retval0+4], %f30;
	st.param.f32	[func_retval0+8], %f31;
	ret;
}

	// .globl	_ZN17DistanceEstimator10rotateHookEj6float3
.visible .func  (.param .align 4 .b8 func_retval0[12]) _ZN17DistanceEstimator10rotateHookEj6float3(
	.param .b64 _ZN17DistanceEstimator10rotateHookEj6float3_param_0,
	.param .b32 _ZN17DistanceEstimator10rotateHookEj6float3_param_1,
	.param .align 4 .b8 _ZN17DistanceEstimator10rotateHookEj6float3_param_2[12]
)
{
	.local .align 4 .b8 	__local_depot19[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<83>;
	.reg .f32 	%f<363>;
	.reg .s32 	%r<550>;
	.reg .s64 	%rd<72>;


	mov.u64 	%rd71, __local_depot19;
	cvta.local.u64 	%SP, %rd71;
	ld.param.u64 	%rd38, [_ZN17DistanceEstimator10rotateHookEj6float3_param_0];
	ld.param.u32 	%r218, [_ZN17DistanceEstimator10rotateHookEj6float3_param_1];
	ld.param.f32 	%f362, [_ZN17DistanceEstimator10rotateHookEj6float3_param_2+8];
	ld.param.f32 	%f361, [_ZN17DistanceEstimator10rotateHookEj6float3_param_2+4];
	ld.param.f32 	%f360, [_ZN17DistanceEstimator10rotateHookEj6float3_param_2];
	add.u64 	%rd39, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd39;
	setp.gt.u32	%p1, %r218, 2;
	@%p1 bra 	BB19_137;

	mul.wide.u32 	%rd40, %r218, 12;
	add.s64 	%rd41, %rd38, %rd40;
	ld.f32 	%f1, [%rd41+56];
	ld.f32 	%f2, [%rd41+60];
	ld.f32 	%f3, [%rd41+52];
	abs.f32 	%f4, %f3;
	setp.geu.f32	%p2, %f4, 0f38D1B717;
	@%p2 bra 	BB19_4;

	abs.f32 	%f118, %f1;
	setp.geu.f32	%p3, %f118, 0f38D1B717;
	@%p3 bra 	BB19_4;

	abs.f32 	%f119, %f2;
	setp.lt.f32	%p4, %f119, 0f38D1B717;
	@%p4 bra 	BB19_137;

BB19_4:
	setp.neu.f32	%p5, %f4, 0f7F800000;
	mov.f32 	%f333, %f3;
	@%p5 bra 	BB19_6;

	mov.f32 	%f120, 0f00000000;
	mul.rn.f32 	%f5, %f3, %f120;
	mov.f32 	%f333, %f5;

BB19_6:
	mov.f32 	%f6, %f333;
	mul.f32 	%f121, %f6, 0f3F22F983;
	cvt.rni.s32.f32	%r499, %f121;
	cvt.rn.f32.s32	%f122, %r499;
	neg.f32 	%f123, %f122;
	mov.f32 	%f124, 0f3FC90FDA;
	fma.rn.f32 	%f125, %f123, %f124, %f6;
	mov.f32 	%f126, 0f33A22168;
	fma.rn.f32 	%f127, %f123, %f126, %f125;
	mov.f32 	%f128, 0f27C234C5;
	fma.rn.f32 	%f327, %f123, %f128, %f127;
	abs.f32 	%f129, %f6;
	add.s64 	%rd2, %rd1, 24;
	setp.leu.f32	%p6, %f129, 0f47CE4780;
	@%p6 bra 	BB19_16;

	mov.b32 	 %r2, %f6;
	shr.u32 	%r3, %r2, 23;
	bfe.u32 	%r221, %r2, 23, 8;
	add.s32 	%r222, %r221, -128;
	shl.b32 	%r223, %r2, 8;
	or.b32  	%r4, %r223, -2147483648;
	shr.u32 	%r5, %r222, 5;
	mov.u32 	%r491, 0;
	mov.u64 	%rd54, __cudart_i2opi_f;
	mov.u32 	%r490, -6;
	mov.u64 	%rd70, %rd1;

BB19_8:
	.pragma "nounroll";
	mov.u64 	%rd5, %rd70;
	ld.const.u32 	%r226, [%rd54];
	// inline asm
	{
	mad.lo.cc.u32   %r224, %r226, %r4, %r491;
	madc.hi.u32     %r225, %r226, %r4,  0;
	}
	// inline asm
	mov.u32 	%r491, %r225;
	st.local.u32 	[%rd5], %r224;
	add.s64 	%rd6, %rd5, 4;
	add.s64 	%rd54, %rd54, 4;
	add.s32 	%r490, %r490, 1;
	setp.ne.s32	%p7, %r490, 0;
	mov.u64 	%rd70, %rd6;
	@%p7 bra 	BB19_8;

	and.b32  	%r10, %r2, -2147483648;
	st.local.u32 	[%rd2], %r225;
	mov.u32 	%r229, 6;
	sub.s32 	%r230, %r229, %r5;
	mul.wide.s32 	%rd43, %r230, 4;
	add.s64 	%rd8, %rd1, %rd43;
	ld.local.u32 	%r492, [%rd8];
	ld.local.u32 	%r493, [%rd8+-4];
	and.b32  	%r13, %r3, 31;
	setp.eq.s32	%p8, %r13, 0;
	@%p8 bra 	BB19_11;

	mov.u32 	%r231, 32;
	sub.s32 	%r232, %r231, %r13;
	shr.u32 	%r233, %r493, %r232;
	shl.b32 	%r234, %r492, %r13;
	add.s32 	%r492, %r233, %r234;
	ld.local.u32 	%r235, [%rd8+-8];
	shr.u32 	%r236, %r235, %r232;
	shl.b32 	%r237, %r493, %r13;
	add.s32 	%r493, %r236, %r237;

BB19_11:
	shr.u32 	%r238, %r493, 30;
	shl.b32 	%r239, %r492, 2;
	add.s32 	%r494, %r238, %r239;
	shl.b32 	%r19, %r493, 2;
	shr.u32 	%r240, %r494, 31;
	shr.u32 	%r241, %r492, 30;
	add.s32 	%r20, %r240, %r241;
	setp.eq.s32	%p9, %r240, 0;
	mov.u32 	%r495, %r10;
	mov.u32 	%r496, %r19;
	@%p9 bra 	BB19_13;

	not.b32 	%r242, %r494;
	neg.s32 	%r21, %r19;
	setp.eq.s32	%p10, %r19, 0;
	selp.u32	%r243, 1, 0, %p10;
	add.s32 	%r494, %r243, %r242;
	xor.b32  	%r23, %r10, -2147483648;
	mov.u32 	%r495, %r23;
	mov.u32 	%r496, %r21;

BB19_13:
	mov.u32 	%r25, %r495;
	neg.s32 	%r244, %r20;
	setp.eq.s32	%p11, %r10, 0;
	selp.b32	%r499, %r20, %r244, %p11;
	clz.b32 	%r498, %r494;
	setp.eq.s32	%p12, %r498, 0;
	shl.b32 	%r245, %r494, %r498;
	mov.u32 	%r246, 32;
	sub.s32 	%r247, %r246, %r498;
	shr.u32 	%r248, %r496, %r247;
	add.s32 	%r249, %r248, %r245;
	selp.b32	%r29, %r494, %r249, %p12;
	mov.u32 	%r250, -921707870;
	mul.hi.u32 	%r497, %r29, %r250;
	setp.lt.s32	%p13, %r497, 1;
	@%p13 bra 	BB19_15;

	mul.lo.s32 	%r251, %r29, -921707870;
	shr.u32 	%r252, %r251, 31;
	shl.b32 	%r253, %r497, 1;
	add.s32 	%r497, %r252, %r253;
	add.s32 	%r498, %r498, 1;

BB19_15:
	mov.u32 	%r254, 126;
	sub.s32 	%r255, %r254, %r498;
	shl.b32 	%r256, %r255, 23;
	add.s32 	%r257, %r497, 1;
	shr.u32 	%r258, %r257, 7;
	add.s32 	%r259, %r258, 1;
	shr.u32 	%r260, %r259, 1;
	add.s32 	%r261, %r260, %r256;
	or.b32  	%r262, %r261, %r25;
	mov.b32 	 %f327, %r262;

BB19_16:
	mul.rn.f32 	%f10, %f327, %f327;
	and.b32  	%r36, %r499, 1;
	setp.eq.s32	%p14, %r36, 0;
	@%p14 bra 	BB19_18;

	mov.f32 	%f130, 0fBAB6061A;
	mov.f32 	%f131, 0f37CCF5CE;
	fma.rn.f32 	%f328, %f131, %f10, %f130;
	bra.uni 	BB19_19;

BB19_18:
	mov.f32 	%f132, 0f3C08839E;
	mov.f32 	%f133, 0fB94CA1F9;
	fma.rn.f32 	%f328, %f133, %f10, %f132;

BB19_19:
	@%p14 bra 	BB19_21;

	mov.f32 	%f134, 0f3D2AAAA5;
	fma.rn.f32 	%f135, %f328, %f10, %f134;
	mov.f32 	%f136, 0fBF000000;
	fma.rn.f32 	%f329, %f135, %f10, %f136;
	bra.uni 	BB19_22;

BB19_21:
	mov.f32 	%f137, 0fBE2AAAA3;
	fma.rn.f32 	%f138, %f328, %f10, %f137;
	mov.f32 	%f139, 0f00000000;
	fma.rn.f32 	%f329, %f138, %f10, %f139;

BB19_22:
	fma.rn.f32 	%f330, %f329, %f327, %f327;
	@%p14 bra 	BB19_24;

	mov.f32 	%f140, 0f3F800000;
	fma.rn.f32 	%f330, %f329, %f10, %f140;

BB19_24:
	and.b32  	%r263, %r499, 2;
	setp.eq.s32	%p17, %r263, 0;
	@%p17 bra 	BB19_26;

	mov.f32 	%f141, 0f00000000;
	mov.f32 	%f142, 0fBF800000;
	fma.rn.f32 	%f330, %f330, %f142, %f141;

BB19_26:
	mov.f32 	%f332, %f3;
	@%p5 bra 	BB19_28;

	mov.f32 	%f143, 0f00000000;
	mul.rn.f32 	%f332, %f3, %f143;

BB19_28:
	mul.f32 	%f144, %f332, 0f3F22F983;
	cvt.rni.s32.f32	%r509, %f144;
	cvt.rn.f32.s32	%f145, %r509;
	neg.f32 	%f146, %f145;
	fma.rn.f32 	%f148, %f146, %f124, %f332;
	fma.rn.f32 	%f150, %f146, %f126, %f148;
	fma.rn.f32 	%f334, %f146, %f128, %f150;
	abs.f32 	%f152, %f332;
	setp.leu.f32	%p19, %f152, 0f47CE4780;
	@%p19 bra 	BB19_38;

	mov.b32 	 %r38, %f332;
	shr.u32 	%r39, %r38, 23;
	bfe.u32 	%r266, %r38, 23, 8;
	add.s32 	%r267, %r266, -128;
	shl.b32 	%r268, %r38, 8;
	or.b32  	%r40, %r268, -2147483648;
	shr.u32 	%r41, %r267, 5;
	mov.u32 	%r501, 0;
	mov.u64 	%rd55, __cudart_i2opi_f;
	mov.u32 	%r500, -6;
	mov.u64 	%rd69, %rd1;

BB19_30:
	.pragma "nounroll";
	ld.const.u32 	%r271, [%rd55];
	// inline asm
	{
	mad.lo.cc.u32   %r269, %r271, %r40, %r501;
	madc.hi.u32     %r270, %r271, %r40,  0;
	}
	// inline asm
	mov.u32 	%r501, %r270;
	st.local.u32 	[%rd69], %r269;
	add.s64 	%rd69, %rd69, 4;
	add.s64 	%rd55, %rd55, 4;
	add.s32 	%r500, %r500, 1;
	setp.ne.s32	%p20, %r500, 0;
	@%p20 bra 	BB19_30;

	and.b32  	%r46, %r38, -2147483648;
	st.local.u32 	[%rd2], %r270;
	mov.u32 	%r274, 6;
	sub.s32 	%r275, %r274, %r41;
	mul.wide.s32 	%rd45, %r275, 4;
	add.s64 	%rd14, %rd1, %rd45;
	ld.local.u32 	%r502, [%rd14];
	ld.local.u32 	%r503, [%rd14+-4];
	and.b32  	%r49, %r39, 31;
	setp.eq.s32	%p21, %r49, 0;
	@%p21 bra 	BB19_33;

	mov.u32 	%r276, 32;
	sub.s32 	%r277, %r276, %r49;
	shr.u32 	%r278, %r503, %r277;
	shl.b32 	%r279, %r502, %r49;
	add.s32 	%r502, %r278, %r279;
	ld.local.u32 	%r280, [%rd14+-8];
	shr.u32 	%r281, %r280, %r277;
	shl.b32 	%r282, %r503, %r49;
	add.s32 	%r503, %r281, %r282;

BB19_33:
	shr.u32 	%r283, %r503, 30;
	shl.b32 	%r284, %r502, 2;
	add.s32 	%r504, %r283, %r284;
	shl.b32 	%r55, %r503, 2;
	shr.u32 	%r285, %r504, 31;
	shr.u32 	%r286, %r502, 30;
	add.s32 	%r56, %r285, %r286;
	setp.eq.s32	%p22, %r285, 0;
	mov.u32 	%r505, %r46;
	mov.u32 	%r506, %r55;
	@%p22 bra 	BB19_35;

	not.b32 	%r287, %r504;
	neg.s32 	%r57, %r55;
	setp.eq.s32	%p23, %r55, 0;
	selp.u32	%r288, 1, 0, %p23;
	add.s32 	%r504, %r288, %r287;
	xor.b32  	%r59, %r46, -2147483648;
	mov.u32 	%r505, %r59;
	mov.u32 	%r506, %r57;

BB19_35:
	mov.u32 	%r61, %r505;
	neg.s32 	%r289, %r56;
	setp.eq.s32	%p24, %r46, 0;
	selp.b32	%r509, %r56, %r289, %p24;
	clz.b32 	%r508, %r504;
	setp.eq.s32	%p25, %r508, 0;
	shl.b32 	%r290, %r504, %r508;
	mov.u32 	%r291, 32;
	sub.s32 	%r292, %r291, %r508;
	shr.u32 	%r293, %r506, %r292;
	add.s32 	%r294, %r293, %r290;
	selp.b32	%r65, %r504, %r294, %p25;
	mov.u32 	%r295, -921707870;
	mul.hi.u32 	%r507, %r65, %r295;
	setp.lt.s32	%p26, %r507, 1;
	@%p26 bra 	BB19_37;

	mul.lo.s32 	%r296, %r65, -921707870;
	shr.u32 	%r297, %r296, 31;
	shl.b32 	%r298, %r507, 1;
	add.s32 	%r507, %r297, %r298;
	add.s32 	%r508, %r508, 1;

BB19_37:
	mov.u32 	%r299, 126;
	sub.s32 	%r300, %r299, %r508;
	shl.b32 	%r301, %r300, 23;
	add.s32 	%r302, %r507, 1;
	shr.u32 	%r303, %r302, 7;
	add.s32 	%r304, %r303, 1;
	shr.u32 	%r305, %r304, 1;
	add.s32 	%r306, %r305, %r301;
	or.b32  	%r307, %r306, %r61;
	mov.b32 	 %f334, %r307;

BB19_38:
	mul.rn.f32 	%f27, %f334, %f334;
	add.s32 	%r72, %r509, 1;
	and.b32  	%r73, %r72, 1;
	setp.eq.s32	%p27, %r73, 0;
	@%p27 bra 	BB19_40;

	mov.f32 	%f153, 0fBAB6061A;
	mov.f32 	%f154, 0f37CCF5CE;
	fma.rn.f32 	%f335, %f154, %f27, %f153;
	bra.uni 	BB19_41;

BB19_40:
	mov.f32 	%f155, 0f3C08839E;
	mov.f32 	%f156, 0fB94CA1F9;
	fma.rn.f32 	%f335, %f156, %f27, %f155;

BB19_41:
	@%p27 bra 	BB19_43;

	mov.f32 	%f157, 0f3D2AAAA5;
	fma.rn.f32 	%f158, %f335, %f27, %f157;
	mov.f32 	%f159, 0fBF000000;
	fma.rn.f32 	%f336, %f158, %f27, %f159;
	bra.uni 	BB19_44;

BB19_43:
	mov.f32 	%f160, 0fBE2AAAA3;
	fma.rn.f32 	%f161, %f335, %f27, %f160;
	mov.f32 	%f162, 0f00000000;
	fma.rn.f32 	%f336, %f161, %f27, %f162;

BB19_44:
	fma.rn.f32 	%f337, %f336, %f334, %f334;
	@%p27 bra 	BB19_46;

	mov.f32 	%f163, 0f3F800000;
	fma.rn.f32 	%f337, %f336, %f27, %f163;

BB19_46:
	and.b32  	%r308, %r72, 2;
	setp.eq.s32	%p30, %r308, 0;
	@%p30 bra 	BB19_48;

	mov.f32 	%f164, 0f00000000;
	mov.f32 	%f165, 0fBF800000;
	fma.rn.f32 	%f337, %f337, %f165, %f164;

BB19_48:
	abs.f32 	%f39, %f1;
	setp.neu.f32	%p31, %f39, 0f7F800000;
	mov.f32 	%f344, %f1;
	@%p31 bra 	BB19_50;

	mov.f32 	%f166, 0f00000000;
	mul.rn.f32 	%f40, %f1, %f166;
	mov.f32 	%f344, %f40;

BB19_50:
	mov.f32 	%f41, %f344;
	mul.f32 	%f167, %f41, 0f3F22F983;
	cvt.rni.s32.f32	%r519, %f167;
	cvt.rn.f32.s32	%f168, %r519;
	neg.f32 	%f169, %f168;
	fma.rn.f32 	%f171, %f169, %f124, %f41;
	fma.rn.f32 	%f173, %f169, %f126, %f171;
	fma.rn.f32 	%f338, %f169, %f128, %f173;
	abs.f32 	%f175, %f41;
	setp.leu.f32	%p32, %f175, 0f47CE4780;
	@%p32 bra 	BB19_60;

	mov.b32 	 %r75, %f41;
	shr.u32 	%r76, %r75, 23;
	bfe.u32 	%r311, %r75, 23, 8;
	add.s32 	%r312, %r311, -128;
	shl.b32 	%r313, %r75, 8;
	or.b32  	%r77, %r313, -2147483648;
	shr.u32 	%r78, %r312, 5;
	mov.u32 	%r511, 0;
	mov.u64 	%rd56, __cudart_i2opi_f;
	mov.u32 	%r510, -6;
	mov.u64 	%rd68, %rd1;

BB19_52:
	.pragma "nounroll";
	ld.const.u32 	%r316, [%rd56];
	// inline asm
	{
	mad.lo.cc.u32   %r314, %r316, %r77, %r511;
	madc.hi.u32     %r315, %r316, %r77,  0;
	}
	// inline asm
	mov.u32 	%r511, %r315;
	st.local.u32 	[%rd68], %r314;
	add.s64 	%rd68, %rd68, 4;
	add.s64 	%rd56, %rd56, 4;
	add.s32 	%r510, %r510, 1;
	setp.ne.s32	%p33, %r510, 0;
	@%p33 bra 	BB19_52;

	and.b32  	%r83, %r75, -2147483648;
	st.local.u32 	[%rd2], %r315;
	mov.u32 	%r319, 6;
	sub.s32 	%r320, %r319, %r78;
	mul.wide.s32 	%rd47, %r320, 4;
	add.s64 	%rd20, %rd1, %rd47;
	ld.local.u32 	%r512, [%rd20];
	ld.local.u32 	%r513, [%rd20+-4];
	and.b32  	%r86, %r76, 31;
	setp.eq.s32	%p34, %r86, 0;
	@%p34 bra 	BB19_55;

	mov.u32 	%r321, 32;
	sub.s32 	%r322, %r321, %r86;
	shr.u32 	%r323, %r513, %r322;
	shl.b32 	%r324, %r512, %r86;
	add.s32 	%r512, %r323, %r324;
	ld.local.u32 	%r325, [%rd20+-8];
	shr.u32 	%r326, %r325, %r322;
	shl.b32 	%r327, %r513, %r86;
	add.s32 	%r513, %r326, %r327;

BB19_55:
	shr.u32 	%r328, %r513, 30;
	shl.b32 	%r329, %r512, 2;
	add.s32 	%r514, %r328, %r329;
	shl.b32 	%r92, %r513, 2;
	shr.u32 	%r330, %r514, 31;
	shr.u32 	%r331, %r512, 30;
	add.s32 	%r93, %r330, %r331;
	setp.eq.s32	%p35, %r330, 0;
	mov.u32 	%r515, %r83;
	mov.u32 	%r516, %r92;
	@%p35 bra 	BB19_57;

	not.b32 	%r332, %r514;
	neg.s32 	%r94, %r92;
	setp.eq.s32	%p36, %r92, 0;
	selp.u32	%r333, 1, 0, %p36;
	add.s32 	%r514, %r333, %r332;
	xor.b32  	%r96, %r83, -2147483648;
	mov.u32 	%r515, %r96;
	mov.u32 	%r516, %r94;

BB19_57:
	mov.u32 	%r98, %r515;
	neg.s32 	%r334, %r93;
	setp.eq.s32	%p37, %r83, 0;
	selp.b32	%r519, %r93, %r334, %p37;
	clz.b32 	%r518, %r514;
	setp.eq.s32	%p38, %r518, 0;
	shl.b32 	%r335, %r514, %r518;
	mov.u32 	%r336, 32;
	sub.s32 	%r337, %r336, %r518;
	shr.u32 	%r338, %r516, %r337;
	add.s32 	%r339, %r338, %r335;
	selp.b32	%r102, %r514, %r339, %p38;
	mov.u32 	%r340, -921707870;
	mul.hi.u32 	%r517, %r102, %r340;
	setp.lt.s32	%p39, %r517, 1;
	@%p39 bra 	BB19_59;

	mul.lo.s32 	%r341, %r102, -921707870;
	shr.u32 	%r342, %r341, 31;
	shl.b32 	%r343, %r517, 1;
	add.s32 	%r517, %r342, %r343;
	add.s32 	%r518, %r518, 1;

BB19_59:
	mov.u32 	%r344, 126;
	sub.s32 	%r345, %r344, %r518;
	shl.b32 	%r346, %r345, 23;
	add.s32 	%r347, %r517, 1;
	shr.u32 	%r348, %r347, 7;
	add.s32 	%r349, %r348, 1;
	shr.u32 	%r350, %r349, 1;
	add.s32 	%r351, %r350, %r346;
	or.b32  	%r352, %r351, %r98;
	mov.b32 	 %f338, %r352;

BB19_60:
	mul.rn.f32 	%f45, %f338, %f338;
	and.b32  	%r109, %r519, 1;
	setp.eq.s32	%p40, %r109, 0;
	@%p40 bra 	BB19_62;

	mov.f32 	%f176, 0fBAB6061A;
	mov.f32 	%f177, 0f37CCF5CE;
	fma.rn.f32 	%f339, %f177, %f45, %f176;
	bra.uni 	BB19_63;

BB19_62:
	mov.f32 	%f178, 0f3C08839E;
	mov.f32 	%f179, 0fB94CA1F9;
	fma.rn.f32 	%f339, %f179, %f45, %f178;

BB19_63:
	@%p40 bra 	BB19_65;

	mov.f32 	%f180, 0f3D2AAAA5;
	fma.rn.f32 	%f181, %f339, %f45, %f180;
	mov.f32 	%f182, 0fBF000000;
	fma.rn.f32 	%f340, %f181, %f45, %f182;
	bra.uni 	BB19_66;

BB19_65:
	mov.f32 	%f183, 0fBE2AAAA3;
	fma.rn.f32 	%f184, %f339, %f45, %f183;
	mov.f32 	%f185, 0f00000000;
	fma.rn.f32 	%f340, %f184, %f45, %f185;

BB19_66:
	fma.rn.f32 	%f341, %f340, %f338, %f338;
	@%p40 bra 	BB19_68;

	mov.f32 	%f186, 0f3F800000;
	fma.rn.f32 	%f341, %f340, %f45, %f186;

BB19_68:
	and.b32  	%r353, %r519, 2;
	setp.eq.s32	%p43, %r353, 0;
	@%p43 bra 	BB19_70;

	mov.f32 	%f187, 0f00000000;
	mov.f32 	%f188, 0fBF800000;
	fma.rn.f32 	%f341, %f341, %f188, %f187;

BB19_70:
	mov.f32 	%f343, %f1;
	@%p31 bra 	BB19_72;

	mov.f32 	%f189, 0f00000000;
	mul.rn.f32 	%f343, %f1, %f189;

BB19_72:
	mul.f32 	%f190, %f343, 0f3F22F983;
	cvt.rni.s32.f32	%r529, %f190;
	cvt.rn.f32.s32	%f191, %r529;
	neg.f32 	%f192, %f191;
	fma.rn.f32 	%f194, %f192, %f124, %f343;
	fma.rn.f32 	%f196, %f192, %f126, %f194;
	fma.rn.f32 	%f345, %f192, %f128, %f196;
	abs.f32 	%f198, %f343;
	setp.leu.f32	%p45, %f198, 0f47CE4780;
	@%p45 bra 	BB19_82;

	mov.b32 	 %r111, %f343;
	shr.u32 	%r112, %r111, 23;
	bfe.u32 	%r356, %r111, 23, 8;
	add.s32 	%r357, %r356, -128;
	shl.b32 	%r358, %r111, 8;
	or.b32  	%r113, %r358, -2147483648;
	shr.u32 	%r114, %r357, 5;
	mov.u32 	%r521, 0;
	mov.u64 	%rd57, __cudart_i2opi_f;
	mov.u32 	%r520, -6;
	mov.u64 	%rd67, %rd1;

BB19_74:
	.pragma "nounroll";
	ld.const.u32 	%r361, [%rd57];
	// inline asm
	{
	mad.lo.cc.u32   %r359, %r361, %r113, %r521;
	madc.hi.u32     %r360, %r361, %r113,  0;
	}
	// inline asm
	mov.u32 	%r521, %r360;
	st.local.u32 	[%rd67], %r359;
	add.s64 	%rd67, %rd67, 4;
	add.s64 	%rd57, %rd57, 4;
	add.s32 	%r520, %r520, 1;
	setp.ne.s32	%p46, %r520, 0;
	@%p46 bra 	BB19_74;

	and.b32  	%r119, %r111, -2147483648;
	st.local.u32 	[%rd2], %r360;
	mov.u32 	%r364, 6;
	sub.s32 	%r365, %r364, %r114;
	mul.wide.s32 	%rd49, %r365, 4;
	add.s64 	%rd26, %rd1, %rd49;
	ld.local.u32 	%r522, [%rd26];
	ld.local.u32 	%r523, [%rd26+-4];
	and.b32  	%r122, %r112, 31;
	setp.eq.s32	%p47, %r122, 0;
	@%p47 bra 	BB19_77;

	mov.u32 	%r366, 32;
	sub.s32 	%r367, %r366, %r122;
	shr.u32 	%r368, %r523, %r367;
	shl.b32 	%r369, %r522, %r122;
	add.s32 	%r522, %r368, %r369;
	ld.local.u32 	%r370, [%rd26+-8];
	shr.u32 	%r371, %r370, %r367;
	shl.b32 	%r372, %r523, %r122;
	add.s32 	%r523, %r371, %r372;

BB19_77:
	shr.u32 	%r373, %r523, 30;
	shl.b32 	%r374, %r522, 2;
	add.s32 	%r524, %r373, %r374;
	shl.b32 	%r128, %r523, 2;
	shr.u32 	%r375, %r524, 31;
	shr.u32 	%r376, %r522, 30;
	add.s32 	%r129, %r375, %r376;
	setp.eq.s32	%p48, %r375, 0;
	mov.u32 	%r525, %r119;
	mov.u32 	%r526, %r128;
	@%p48 bra 	BB19_79;

	not.b32 	%r377, %r524;
	neg.s32 	%r130, %r128;
	setp.eq.s32	%p49, %r128, 0;
	selp.u32	%r378, 1, 0, %p49;
	add.s32 	%r524, %r378, %r377;
	xor.b32  	%r132, %r119, -2147483648;
	mov.u32 	%r525, %r132;
	mov.u32 	%r526, %r130;

BB19_79:
	mov.u32 	%r134, %r525;
	neg.s32 	%r379, %r129;
	setp.eq.s32	%p50, %r119, 0;
	selp.b32	%r529, %r129, %r379, %p50;
	clz.b32 	%r528, %r524;
	setp.eq.s32	%p51, %r528, 0;
	shl.b32 	%r380, %r524, %r528;
	mov.u32 	%r381, 32;
	sub.s32 	%r382, %r381, %r528;
	shr.u32 	%r383, %r526, %r382;
	add.s32 	%r384, %r383, %r380;
	selp.b32	%r138, %r524, %r384, %p51;
	mov.u32 	%r385, -921707870;
	mul.hi.u32 	%r527, %r138, %r385;
	setp.lt.s32	%p52, %r527, 1;
	@%p52 bra 	BB19_81;

	mul.lo.s32 	%r386, %r138, -921707870;
	shr.u32 	%r387, %r386, 31;
	shl.b32 	%r388, %r527, 1;
	add.s32 	%r527, %r387, %r388;
	add.s32 	%r528, %r528, 1;

BB19_81:
	mov.u32 	%r389, 126;
	sub.s32 	%r390, %r389, %r528;
	shl.b32 	%r391, %r390, 23;
	add.s32 	%r392, %r527, 1;
	shr.u32 	%r393, %r392, 7;
	add.s32 	%r394, %r393, 1;
	shr.u32 	%r395, %r394, 1;
	add.s32 	%r396, %r395, %r391;
	or.b32  	%r397, %r396, %r134;
	mov.b32 	 %f345, %r397;

BB19_82:
	mul.rn.f32 	%f62, %f345, %f345;
	add.s32 	%r145, %r529, 1;
	and.b32  	%r146, %r145, 1;
	setp.eq.s32	%p53, %r146, 0;
	@%p53 bra 	BB19_84;

	mov.f32 	%f199, 0fBAB6061A;
	mov.f32 	%f200, 0f37CCF5CE;
	fma.rn.f32 	%f346, %f200, %f62, %f199;
	bra.uni 	BB19_85;

BB19_84:
	mov.f32 	%f201, 0f3C08839E;
	mov.f32 	%f202, 0fB94CA1F9;
	fma.rn.f32 	%f346, %f202, %f62, %f201;

BB19_85:
	@%p53 bra 	BB19_87;

	mov.f32 	%f203, 0f3D2AAAA5;
	fma.rn.f32 	%f204, %f346, %f62, %f203;
	mov.f32 	%f205, 0fBF000000;
	fma.rn.f32 	%f347, %f204, %f62, %f205;
	bra.uni 	BB19_88;

BB19_87:
	mov.f32 	%f206, 0fBE2AAAA3;
	fma.rn.f32 	%f207, %f346, %f62, %f206;
	mov.f32 	%f208, 0f00000000;
	fma.rn.f32 	%f347, %f207, %f62, %f208;

BB19_88:
	fma.rn.f32 	%f348, %f347, %f345, %f345;
	@%p53 bra 	BB19_90;

	mov.f32 	%f209, 0f3F800000;
	fma.rn.f32 	%f348, %f347, %f62, %f209;

BB19_90:
	and.b32  	%r398, %r145, 2;
	setp.eq.s32	%p56, %r398, 0;
	@%p56 bra 	BB19_92;

	mov.f32 	%f210, 0f00000000;
	mov.f32 	%f211, 0fBF800000;
	fma.rn.f32 	%f348, %f348, %f211, %f210;

BB19_92:
	abs.f32 	%f74, %f2;
	setp.neu.f32	%p57, %f74, 0f7F800000;
	mov.f32 	%f355, %f2;
	@%p57 bra 	BB19_94;

	mov.f32 	%f212, 0f00000000;
	mul.rn.f32 	%f75, %f2, %f212;
	mov.f32 	%f355, %f75;

BB19_94:
	mov.f32 	%f76, %f355;
	mul.f32 	%f213, %f76, 0f3F22F983;
	cvt.rni.s32.f32	%r539, %f213;
	cvt.rn.f32.s32	%f214, %r539;
	neg.f32 	%f215, %f214;
	fma.rn.f32 	%f217, %f215, %f124, %f76;
	fma.rn.f32 	%f219, %f215, %f126, %f217;
	fma.rn.f32 	%f349, %f215, %f128, %f219;
	abs.f32 	%f221, %f76;
	setp.leu.f32	%p58, %f221, 0f47CE4780;
	@%p58 bra 	BB19_104;

	mov.b32 	 %r148, %f76;
	shl.b32 	%r401, %r148, 8;
	or.b32  	%r149, %r401, -2147483648;
	mov.u32 	%r531, 0;
	mov.u64 	%rd58, __cudart_i2opi_f;
	mov.u32 	%r530, -6;
	mov.u64 	%rd66, %rd1;

BB19_96:
	.pragma "nounroll";
	ld.const.u32 	%r404, [%rd58];
	// inline asm
	{
	mad.lo.cc.u32   %r402, %r404, %r149, %r531;
	madc.hi.u32     %r403, %r404, %r149,  0;
	}
	// inline asm
	mov.u32 	%r531, %r403;
	st.local.u32 	[%rd66], %r402;
	add.s64 	%rd66, %rd66, 4;
	add.s64 	%rd58, %rd58, 4;
	add.s32 	%r530, %r530, 1;
	setp.ne.s32	%p59, %r530, 0;
	@%p59 bra 	BB19_96;

	and.b32  	%r154, %r148, -2147483648;
	bfe.u32 	%r407, %r148, 23, 8;
	add.s32 	%r408, %r407, -128;
	shr.u32 	%r409, %r408, 5;
	st.local.u32 	[%rd1+24], %r403;
	bfe.u32 	%r155, %r148, 23, 5;
	mov.u32 	%r410, 6;
	sub.s32 	%r411, %r410, %r409;
	mul.wide.s32 	%rd51, %r411, 4;
	add.s64 	%rd31, %rd1, %rd51;
	ld.local.u32 	%r532, [%rd31];
	ld.local.u32 	%r533, [%rd31+-4];
	setp.eq.s32	%p60, %r155, 0;
	@%p60 bra 	BB19_99;

	mov.u32 	%r412, 32;
	sub.s32 	%r413, %r412, %r155;
	shr.u32 	%r414, %r533, %r413;
	shl.b32 	%r415, %r532, %r155;
	add.s32 	%r532, %r414, %r415;
	ld.local.u32 	%r416, [%rd31+-8];
	shr.u32 	%r417, %r416, %r413;
	shl.b32 	%r418, %r533, %r155;
	add.s32 	%r533, %r417, %r418;

BB19_99:
	shr.u32 	%r419, %r533, 30;
	shl.b32 	%r420, %r532, 2;
	add.s32 	%r534, %r419, %r420;
	shl.b32 	%r163, %r533, 2;
	shr.u32 	%r421, %r534, 31;
	shr.u32 	%r422, %r532, 30;
	add.s32 	%r164, %r421, %r422;
	setp.eq.s32	%p61, %r421, 0;
	mov.u32 	%r535, %r154;
	mov.u32 	%r536, %r163;
	@%p61 bra 	BB19_101;

	not.b32 	%r423, %r534;
	neg.s32 	%r165, %r163;
	setp.eq.s32	%p62, %r163, 0;
	selp.u32	%r424, 1, 0, %p62;
	add.s32 	%r534, %r424, %r423;
	xor.b32  	%r167, %r154, -2147483648;
	mov.u32 	%r535, %r167;
	mov.u32 	%r536, %r165;

BB19_101:
	mov.u32 	%r169, %r535;
	neg.s32 	%r425, %r164;
	setp.eq.s32	%p63, %r154, 0;
	selp.b32	%r539, %r164, %r425, %p63;
	clz.b32 	%r538, %r534;
	setp.eq.s32	%p64, %r538, 0;
	shl.b32 	%r426, %r534, %r538;
	mov.u32 	%r427, 32;
	sub.s32 	%r428, %r427, %r538;
	shr.u32 	%r429, %r536, %r428;
	add.s32 	%r430, %r429, %r426;
	selp.b32	%r173, %r534, %r430, %p64;
	mov.u32 	%r431, -921707870;
	mul.hi.u32 	%r537, %r173, %r431;
	setp.lt.s32	%p65, %r537, 1;
	@%p65 bra 	BB19_103;

	mul.lo.s32 	%r432, %r173, -921707870;
	shr.u32 	%r433, %r432, 31;
	shl.b32 	%r434, %r537, 1;
	add.s32 	%r537, %r433, %r434;
	add.s32 	%r538, %r538, 1;

BB19_103:
	mov.u32 	%r435, 126;
	sub.s32 	%r436, %r435, %r538;
	shl.b32 	%r437, %r436, 23;
	add.s32 	%r438, %r537, 1;
	shr.u32 	%r439, %r438, 7;
	add.s32 	%r440, %r439, 1;
	shr.u32 	%r441, %r440, 1;
	add.s32 	%r442, %r441, %r437;
	or.b32  	%r443, %r442, %r169;
	mov.b32 	 %f349, %r443;

BB19_104:
	mul.rn.f32 	%f80, %f349, %f349;
	and.b32  	%r180, %r539, 1;
	setp.eq.s32	%p66, %r180, 0;
	@%p66 bra 	BB19_106;

	mov.f32 	%f222, 0fBAB6061A;
	mov.f32 	%f223, 0f37CCF5CE;
	fma.rn.f32 	%f350, %f223, %f80, %f222;
	bra.uni 	BB19_107;

BB19_106:
	mov.f32 	%f224, 0f3C08839E;
	mov.f32 	%f225, 0fB94CA1F9;
	fma.rn.f32 	%f350, %f225, %f80, %f224;

BB19_107:
	@%p66 bra 	BB19_109;

	mov.f32 	%f226, 0f3D2AAAA5;
	fma.rn.f32 	%f227, %f350, %f80, %f226;
	mov.f32 	%f228, 0fBF000000;
	fma.rn.f32 	%f351, %f227, %f80, %f228;
	bra.uni 	BB19_110;

BB19_109:
	mov.f32 	%f229, 0fBE2AAAA3;
	fma.rn.f32 	%f230, %f350, %f80, %f229;
	mov.f32 	%f231, 0f00000000;
	fma.rn.f32 	%f351, %f230, %f80, %f231;

BB19_110:
	fma.rn.f32 	%f352, %f351, %f349, %f349;
	@%p66 bra 	BB19_112;

	mov.f32 	%f232, 0f3F800000;
	fma.rn.f32 	%f352, %f351, %f80, %f232;

BB19_112:
	and.b32  	%r444, %r539, 2;
	setp.eq.s32	%p69, %r444, 0;
	@%p69 bra 	BB19_114;

	mov.f32 	%f233, 0f00000000;
	mov.f32 	%f234, 0fBF800000;
	fma.rn.f32 	%f352, %f352, %f234, %f233;

BB19_114:
	mov.f32 	%f354, %f2;
	@%p57 bra 	BB19_116;

	mov.f32 	%f235, 0f00000000;
	mul.rn.f32 	%f354, %f2, %f235;

BB19_116:
	mul.f32 	%f236, %f354, 0f3F22F983;
	cvt.rni.s32.f32	%r549, %f236;
	cvt.rn.f32.s32	%f237, %r549;
	neg.f32 	%f238, %f237;
	fma.rn.f32 	%f240, %f238, %f124, %f354;
	fma.rn.f32 	%f242, %f238, %f126, %f240;
	fma.rn.f32 	%f356, %f238, %f128, %f242;
	abs.f32 	%f244, %f354;
	setp.leu.f32	%p71, %f244, 0f47CE4780;
	@%p71 bra 	BB19_126;

	mov.b32 	 %r182, %f354;
	shr.u32 	%r183, %r182, 23;
	bfe.u32 	%r447, %r182, 23, 8;
	add.s32 	%r448, %r447, -128;
	shl.b32 	%r449, %r182, 8;
	or.b32  	%r184, %r449, -2147483648;
	shr.u32 	%r185, %r448, 5;
	mov.u32 	%r541, 0;
	mov.u64 	%rd59, __cudart_i2opi_f;
	mov.u32 	%r540, -6;
	mov.u64 	%rd65, %rd1;

BB19_118:
	.pragma "nounroll";
	ld.const.u32 	%r452, [%rd59];
	// inline asm
	{
	mad.lo.cc.u32   %r450, %r452, %r184, %r541;
	madc.hi.u32     %r451, %r452, %r184,  0;
	}
	// inline asm
	mov.u32 	%r541, %r451;
	st.local.u32 	[%rd65], %r450;
	add.s64 	%rd65, %rd65, 4;
	add.s64 	%rd59, %rd59, 4;
	add.s32 	%r540, %r540, 1;
	setp.ne.s32	%p72, %r540, 0;
	@%p72 bra 	BB19_118;

	and.b32  	%r190, %r182, -2147483648;
	st.local.u32 	[%rd1+24], %r451;
	mov.u32 	%r455, 6;
	sub.s32 	%r456, %r455, %r185;
	mul.wide.s32 	%rd53, %r456, 4;
	add.s64 	%rd37, %rd1, %rd53;
	ld.local.u32 	%r542, [%rd37];
	ld.local.u32 	%r543, [%rd37+-4];
	and.b32  	%r193, %r183, 31;
	setp.eq.s32	%p73, %r193, 0;
	@%p73 bra 	BB19_121;

	mov.u32 	%r457, 32;
	sub.s32 	%r458, %r457, %r193;
	shr.u32 	%r459, %r543, %r458;
	shl.b32 	%r460, %r542, %r193;
	add.s32 	%r542, %r459, %r460;
	ld.local.u32 	%r461, [%rd37+-8];
	shr.u32 	%r462, %r461, %r458;
	shl.b32 	%r463, %r543, %r193;
	add.s32 	%r543, %r462, %r463;

BB19_121:
	shr.u32 	%r464, %r543, 30;
	shl.b32 	%r465, %r542, 2;
	add.s32 	%r544, %r464, %r465;
	shl.b32 	%r199, %r543, 2;
	shr.u32 	%r466, %r544, 31;
	shr.u32 	%r467, %r542, 30;
	add.s32 	%r200, %r466, %r467;
	setp.eq.s32	%p74, %r466, 0;
	mov.u32 	%r545, %r190;
	mov.u32 	%r546, %r199;
	@%p74 bra 	BB19_123;

	not.b32 	%r468, %r544;
	neg.s32 	%r201, %r199;
	setp.eq.s32	%p75, %r199, 0;
	selp.u32	%r469, 1, 0, %p75;
	add.s32 	%r544, %r469, %r468;
	xor.b32  	%r203, %r190, -2147483648;
	mov.u32 	%r545, %r203;
	mov.u32 	%r546, %r201;

BB19_123:
	mov.u32 	%r205, %r545;
	neg.s32 	%r470, %r200;
	setp.eq.s32	%p76, %r190, 0;
	selp.b32	%r549, %r200, %r470, %p76;
	clz.b32 	%r548, %r544;
	setp.eq.s32	%p77, %r548, 0;
	shl.b32 	%r471, %r544, %r548;
	mov.u32 	%r472, 32;
	sub.s32 	%r473, %r472, %r548;
	shr.u32 	%r474, %r546, %r473;
	add.s32 	%r475, %r474, %r471;
	selp.b32	%r209, %r544, %r475, %p77;
	mov.u32 	%r476, -921707870;
	mul.hi.u32 	%r547, %r209, %r476;
	setp.lt.s32	%p78, %r547, 1;
	@%p78 bra 	BB19_125;

	mul.lo.s32 	%r477, %r209, -921707870;
	shr.u32 	%r478, %r477, 31;
	shl.b32 	%r479, %r547, 1;
	add.s32 	%r547, %r478, %r479;
	add.s32 	%r548, %r548, 1;

BB19_125:
	mov.u32 	%r480, 126;
	sub.s32 	%r481, %r480, %r548;
	shl.b32 	%r482, %r481, 23;
	add.s32 	%r483, %r547, 1;
	shr.u32 	%r484, %r483, 7;
	add.s32 	%r485, %r484, 1;
	shr.u32 	%r486, %r485, 1;
	add.s32 	%r487, %r486, %r482;
	or.b32  	%r488, %r487, %r205;
	mov.b32 	 %f356, %r488;

BB19_126:
	mul.rn.f32 	%f97, %f356, %f356;
	add.s32 	%r216, %r549, 1;
	and.b32  	%r217, %r216, 1;
	setp.eq.s32	%p79, %r217, 0;
	@%p79 bra 	BB19_128;

	mov.f32 	%f245, 0fBAB6061A;
	mov.f32 	%f246, 0f37CCF5CE;
	fma.rn.f32 	%f357, %f246, %f97, %f245;
	bra.uni 	BB19_129;

BB19_128:
	mov.f32 	%f247, 0f3C08839E;
	mov.f32 	%f248, 0fB94CA1F9;
	fma.rn.f32 	%f357, %f248, %f97, %f247;

BB19_129:
	@%p79 bra 	BB19_131;

	mov.f32 	%f249, 0f3D2AAAA5;
	fma.rn.f32 	%f250, %f357, %f97, %f249;
	mov.f32 	%f251, 0fBF000000;
	fma.rn.f32 	%f358, %f250, %f97, %f251;
	bra.uni 	BB19_132;

BB19_131:
	mov.f32 	%f252, 0fBE2AAAA3;
	fma.rn.f32 	%f253, %f357, %f97, %f252;
	mov.f32 	%f254, 0f00000000;
	fma.rn.f32 	%f358, %f253, %f97, %f254;

BB19_132:
	fma.rn.f32 	%f359, %f358, %f356, %f356;
	@%p79 bra 	BB19_134;

	mov.f32 	%f255, 0f3F800000;
	fma.rn.f32 	%f359, %f358, %f97, %f255;

BB19_134:
	and.b32  	%r489, %r216, 2;
	setp.eq.s32	%p82, %r489, 0;
	@%p82 bra 	BB19_136;

	mov.f32 	%f256, 0f00000000;
	mov.f32 	%f257, 0fBF800000;
	fma.rn.f32 	%f359, %f359, %f257, %f256;

BB19_136:
	fma.rn.f32 	%f258, %f337, 0f00000000, 0f3F800000;
	mov.f32 	%f259, 0f3F800000;
	sub.f32 	%f260, %f259, %f337;
	mul.f32 	%f261, %f260, 0f00000000;
	mul.f32 	%f262, %f330, 0f00000000;
	sub.f32 	%f263, %f261, %f262;
	add.f32 	%f264, %f262, %f261;
	add.f32 	%f265, %f337, 0f00000000;
	sub.f32 	%f266, %f261, %f330;
	add.f32 	%f267, %f330, %f261;
	add.f32 	%f268, %f348, 0f00000000;
	sub.f32 	%f269, %f259, %f348;
	mul.f32 	%f270, %f269, 0f00000000;
	mul.f32 	%f271, %f341, 0f00000000;
	sub.f32 	%f272, %f270, %f271;
	add.f32 	%f273, %f341, %f270;
	add.f32 	%f274, %f271, %f270;
	fma.rn.f32 	%f275, %f348, 0f00000000, 0f3F800000;
	sub.f32 	%f276, %f270, %f341;
	sub.f32 	%f277, %f259, %f359;
	mul.f32 	%f278, %f277, 0f00000000;
	sub.f32 	%f279, %f278, %f352;
	mul.f32 	%f280, %f352, 0f00000000;
	add.f32 	%f281, %f280, %f278;
	add.f32 	%f282, %f352, %f278;
	sub.f32 	%f283, %f278, %f280;
	fma.rn.f32 	%f284, %f359, 0f00000000, 0f3F800000;
	fma.rn.f32 	%f285, %f360, %f258, 0f00000000;
	fma.rn.f32 	%f286, %f361, %f264, %f285;
	fma.rn.f32 	%f287, %f362, %f263, %f286;
	add.f32 	%f288, %f287, 0f00000000;
	fma.rn.f32 	%f289, %f360, %f263, 0f00000000;
	fma.rn.f32 	%f290, %f361, %f265, %f289;
	fma.rn.f32 	%f291, %f362, %f267, %f290;
	add.f32 	%f292, %f291, 0f00000000;
	fma.rn.f32 	%f293, %f360, %f264, 0f00000000;
	fma.rn.f32 	%f294, %f361, %f266, %f293;
	fma.rn.f32 	%f295, %f362, %f265, %f294;
	add.f32 	%f296, %f295, 0f00000000;
	fma.rn.f32 	%f297, %f360, 0f00000000, 0f00000000;
	fma.rn.f32 	%f298, %f361, 0f00000000, %f297;
	fma.rn.f32 	%f299, %f362, 0f00000000, %f298;
	add.f32 	%f300, %f299, 0f3F800000;
	fma.rn.f32 	%f301, %f288, %f268, 0f00000000;
	fma.rn.f32 	%f302, %f292, %f274, %f301;
	fma.rn.f32 	%f303, %f296, %f276, %f302;
	fma.rn.f32 	%f304, %f300, 0f00000000, %f303;
	fma.rn.f32 	%f305, %f288, %f272, 0f00000000;
	fma.rn.f32 	%f306, %f292, %f275, %f305;
	fma.rn.f32 	%f307, %f296, %f274, %f306;
	fma.rn.f32 	%f308, %f300, 0f00000000, %f307;
	fma.rn.f32 	%f309, %f288, %f273, 0f00000000;
	fma.rn.f32 	%f310, %f292, %f272, %f309;
	fma.rn.f32 	%f311, %f296, %f268, %f310;
	fma.rn.f32 	%f312, %f300, 0f00000000, %f311;
	fma.rn.f32 	%f313, %f288, 0f00000000, 0f00000000;
	fma.rn.f32 	%f314, %f292, 0f00000000, %f313;
	fma.rn.f32 	%f315, %f296, 0f00000000, %f314;
	add.f32 	%f316, %f315, %f300;
	add.f32 	%f317, %f359, 0f00000000;
	fma.rn.f32 	%f318, %f304, %f317, 0f00000000;
	fma.rn.f32 	%f319, %f308, %f282, %f318;
	fma.rn.f32 	%f320, %f312, %f283, %f319;
	fma.rn.f32 	%f360, %f316, 0f00000000, %f320;
	fma.rn.f32 	%f321, %f304, %f279, 0f00000000;
	fma.rn.f32 	%f322, %f308, %f317, %f321;
	fma.rn.f32 	%f323, %f312, %f281, %f322;
	fma.rn.f32 	%f361, %f316, 0f00000000, %f323;
	fma.rn.f32 	%f324, %f304, %f281, 0f00000000;
	fma.rn.f32 	%f325, %f308, %f283, %f324;
	fma.rn.f32 	%f326, %f312, %f284, %f325;
	fma.rn.f32 	%f362, %f316, 0f00000000, %f326;

BB19_137:
	st.param.f32	[func_retval0+0], %f360;
	st.param.f32	[func_retval0+4], %f361;
	st.param.f32	[func_retval0+8], %f362;
	ret;
}

	// .globl	_ZN17DistanceEstimator13translateHookEj6float3
.visible .func  (.param .align 4 .b8 func_retval0[12]) _ZN17DistanceEstimator13translateHookEj6float3(
	.param .b64 _ZN17DistanceEstimator13translateHookEj6float3_param_0,
	.param .b32 _ZN17DistanceEstimator13translateHookEj6float3_param_1,
	.param .align 4 .b8 _ZN17DistanceEstimator13translateHookEj6float3_param_2[12]
)
{
	.reg .pred 	%p<5>;
	.reg .f32 	%f<29>;
	.reg .s32 	%r<2>;
	.reg .s64 	%rd<4>;


	ld.param.u64 	%rd1, [_ZN17DistanceEstimator13translateHookEj6float3_param_0];
	ld.param.u32 	%r1, [_ZN17DistanceEstimator13translateHookEj6float3_param_1];
	ld.param.f32 	%f28, [_ZN17DistanceEstimator13translateHookEj6float3_param_2+8];
	ld.param.f32 	%f11, [_ZN17DistanceEstimator13translateHookEj6float3_param_2+4];
	ld.param.f32 	%f10, [_ZN17DistanceEstimator13translateHookEj6float3_param_2];
	setp.gt.u32	%p1, %r1, 2;
	mov.f32 	%f25, %f10;
	mov.f32 	%f27, %f11;
	@%p1 bra 	BB20_5;

	mul.wide.u32 	%rd2, %r1, 12;
	add.s64 	%rd3, %rd1, %rd2;
	ld.f32 	%f3, [%rd3+96];
	ld.f32 	%f2, [%rd3+92];
	ld.f32 	%f1, [%rd3+88];
	abs.f32 	%f13, %f1;
	setp.geu.f32	%p2, %f13, 0f38D1B717;
	@%p2 bra 	BB20_4;

	abs.f32 	%f14, %f2;
	setp.geu.f32	%p3, %f14, 0f38D1B717;
	@%p3 bra 	BB20_4;

	abs.f32 	%f15, %f3;
	setp.lt.f32	%p4, %f15, 0f38D1B717;
	mov.f32 	%f24, %f10;
	mov.f32 	%f25, %f24;
	mov.f32 	%f26, %f11;
	mov.f32 	%f27, %f26;
	@%p4 bra 	BB20_5;

BB20_4:
	add.f32 	%f16, %f10, 0f00000000;
	fma.rn.f32 	%f17, %f11, 0f00000000, %f16;
	fma.rn.f32 	%f18, %f28, 0f00000000, %f17;
	add.f32 	%f4, %f18, 0f00000000;
	fma.rn.f32 	%f19, %f10, 0f00000000, 0f00000000;
	add.f32 	%f20, %f19, %f11;
	fma.rn.f32 	%f21, %f28, 0f00000000, %f20;
	add.f32 	%f5, %f21, 0f00000000;
	fma.rn.f32 	%f22, %f11, 0f00000000, %f19;
	add.f32 	%f23, %f22, %f28;
	add.f32 	%f28, %f23, 0f00000000;
	mov.f32 	%f25, %f4;
	mov.f32 	%f27, %f5;

BB20_5:
	st.param.f32	[func_retval0+0], %f25;
	st.param.f32	[func_retval0+4], %f27;
	st.param.f32	[func_retval0+8], %f28;
	ret;
}


